{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a lite version of our logistic regression model. You can get 0.7470094610831955 cross validation mean test RMSE using the code below. The prediction file gives 0.73028 score on Kaggle.\n",
    "\n",
    "If you want more detalied, and powerful model, check out [here](https://github.com/xiaohk/stat333_project_2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from pickle import load, dump\n",
    "from os.path import exists\n",
    "import time\n",
    "\n",
    "# Change THREAD to change model and prediction name\n",
    "THREAD = '_1~10'\n",
    "\n",
    "# If you download the full data set, you can use our pre-stored\n",
    "# data files\n",
    "\n",
    "\"\"\"\n",
    "TRAIN_TEXT = '../../data/text_train.csv'\n",
    "TEST_TEXT = '../../data/text_test.csv'\n",
    "VALI_TEXT = '../../data/text_validate.csv'\n",
    "MINI_TEXT = '../../data/text_mini.csv'\n",
    "PREDICTION_CSV = '../../static/prediction.csv'\n",
    "VECTOR = '../../static/tf_vector.pickle'\n",
    "MATRIX = '../../static/tf_matrix.pickle'\n",
    "PREDICTION = './config/prediction{}.csv'.format(THREAD)\n",
    "MODEL = './config/model{}.pickle'.format(THREAD)\n",
    "\"\"\"\n",
    "\n",
    "STOP = set(stopwords.words(\"english\"))\n",
    "STEMMER = SnowballStemmer(\"english\")\n",
    "LOAD_NEW = False\n",
    "\n",
    "# Tunable parameters\n",
    "MAX_DF = 1.0  # We already have stop words, probably don't need this\n",
    "MIN_DF = 2  # Discard words which not show up twice in all document\n",
    "MAX_FEATURE = None  # IF no memory, tune this down\n",
    "MIN_N = 1\n",
    "MAX_N = 1  # Uni-gram\n",
    "\n",
    "DUAL = False  # Feature > sample then true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" Helper function for TFIDF vector from sklearn. We use nltk's tokenize\n",
    "        function here. Also use snowball as stemmer (the middle agressive\n",
    "        one).\n",
    "    \"\"\"\n",
    "    # Filter out stop words, tokenize the text\n",
    "    useful_token = [w.lower() for w in word_tokenize(text) if w not in STOP]\n",
    "\n",
    "    # Stemming the tokens\n",
    "    stemmed_token = [STEMMER.stem(t) for t in useful_token]\n",
    "\n",
    "    return stemmed_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text(train_txt, vali_txt, test_txt, vector, matrix, re_load,\n",
    "                   min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1):\n",
    "    \"\"\" Feature engineering from the raw text input. \"\"\"\n",
    "    # If there is saved model, then just use it\n",
    "    if exists(vector) and exists(matrix) and not re_load:\n",
    "        # Get train length\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "\n",
    "        # Load stored data\n",
    "        all_mat = load(open(matrix, 'rb'))\n",
    "        x_train = all_mat[:table_train.shape[0]]\n",
    "        tf = load(open(vector, 'rb'))\n",
    "\n",
    "    else:\n",
    "        # Read all files\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "        table_test = pd.read_csv(vali_txt)\n",
    "        table_vali = pd.read_csv(test_txt)\n",
    "\n",
    "        text_train = table_train['clean'].tolist()\n",
    "        text_test = table_test['clean'].tolist()\n",
    "        text_vali = table_vali['clean'].tolist()\n",
    "\n",
    "        # We want to have a overall vocabulary bank as `np.py`, so we combine\n",
    "        # all the text first\n",
    "        all_text = text_train + text_test + text_vali\n",
    "\n",
    "        # Record the length so we can recover the training set\n",
    "        train_length = len(text_train)\n",
    "\n",
    "        # Initialize TFID arguments\n",
    "        # Only work for English, discard all Chinese\n",
    "        tf = TfidfVectorizer(min_df=min_df, max_features=max_feature,\n",
    "                             strip_accents='ascii', analyzer='word',\n",
    "                             tokenizer=tokenize, ngram_range=(min_n, max_n))\n",
    "\n",
    "        # Vectorize all, and transform (more efficient than fit + transform)\n",
    "        all_mat = tf.fit_transform(all_text)\n",
    "\n",
    "        # Recover the training data\n",
    "        x_train = all_mat[:train_length]\n",
    "\n",
    "        # Store the fitted matrix and tf_vectorizor\n",
    "        dump(all_mat, open(matrix, 'wb'))\n",
    "        dump(tf, open(vector, 'wb'))\n",
    "\n",
    "    print(\"Successfully load TF-IDF matrix, with shape {}.\".format(\n",
    "        x_train.shape))\n",
    "\n",
    "    return tf, all_mat, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(estimator, x_test, y_test):\n",
    "    \"\"\" Use mean squared error as score for cv.\"\"\"\n",
    "    probs = estimator.predict_proba(x_test)\n",
    "    result = np.zeros(x_test.shape[0])\n",
    "    for i in range(probs.shape[0]):\n",
    "        result[i] = dis_to_conti(probs[i])\n",
    "    y_int = np.array(list(map(int, y_test)))\n",
    "    # We want to minimize the error\n",
    "    score = (-1) * np.sqrt(np.mean(np.square(result - y_int)))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dis_to_conti(probability):\n",
    "    \"\"\" The kaggle grading is unfair, so I want to force bayesian classifier\n",
    "        gives a continuous result.\n",
    "    \"\"\"\n",
    "    return sum(probability * np.arange(1, 6))\n",
    "\n",
    "def score_mlr(estimator, x_test, y_test):\n",
    "    \"\"\" Use mean squared error as score for cv.\"\"\"\n",
    "    result = estimator.predict(x_test)\n",
    "    y_int = np.array(list(map(int, y_test)))\n",
    "\n",
    "    # We want to minimize the error\n",
    "    score = (-1) * np.sqrt(np.mean(np.square(result - y_int)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lr(x_train, y_train, model_name):\n",
    "    \"\"\" Train a logistic regression model.\"\"\"\n",
    "    # Use cross validation to search features\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    # param_grid = {'C': [1, 5]}\n",
    "    best_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=DUAL),\n",
    "                              param_grid, scoring=score, cv=10)\n",
    "\n",
    "    best_model.fit(x_train, y_train)\n",
    "    print(best_model.best_estimator_)\n",
    "\n",
    "    # Save the model\n",
    "    dump(best_model, open(model_name, 'wb'))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(estimator, all_matrix, train_length, output_csv):\n",
    "    \"\"\" Predict the test and validation text, and write to csv.\"\"\"\n",
    "    # Read the text\n",
    "    # `all_matrix` has already contained all the test and vali text\n",
    "    x_predict = all_matrix[train_length:]\n",
    "    print(\"Successfully load predicting text, with shape {}.\".format(\n",
    "        x_predict.shape))\n",
    "\n",
    "    prediction = estimator.predict_proba(x_predict)\n",
    "\n",
    "    # Convert probability to continuous scores\n",
    "    result = np.zeros(x_predict.shape[0])\n",
    "    for i in range(prediction.shape[0]):\n",
    "        result[i] = dis_to_conti(prediction[i])\n",
    "\n",
    "    # Combine ID and write to a file\n",
    "    with open(output_csv, 'w') as output:\n",
    "        output.write('\"Id\",\"Prediction\"\\n')\n",
    "        for i in range(len(result)):\n",
    "            # The id number is 1-indexed\n",
    "            output.write(\"{},{}\\n\".format(i + 1, result[i]))\n",
    "\n",
    "def predict_mlr(estimator, all_matrix, train_length, output_csv):\n",
    "    \"\"\" Predict the test and validation text, and write to csv. The estimator\n",
    "        should be a prediction estimator, instead of a classifier.\n",
    "    \"\"\"\n",
    "    # Read the text\n",
    "    # `all_matrix` has already contained all the test and vali text\n",
    "    x_predict = all_matrix[train_length:]\n",
    "    print(\"Successfully load predicting text, with shape {}.\".format(\n",
    "        x_predict.shape))\n",
    "\n",
    "    prediction = estimator.predict(x_predict)\n",
    "\n",
    "    # Combine ID and write to a file\n",
    "    with open(output_csv, 'w') as output:\n",
    "        output.write('\"Id\",\"Prediction\"\\n')\n",
    "        for i in range(len(prediction)):\n",
    "            output.write(\"{},{}\\n\".format(i, prediction[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TF-IDF matrix\n",
    "Need train: text + label + clean, test: text + clean, validation: text + clean.\n",
    "\n",
    "To generate those files from given yelp data, please use `project/data/parser.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start vectorizing...\n",
      "Successfully load TF-IDF matrix, with shape (36692, 21888).\n",
      "--- Used 163.23979306221008 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(\"Start vectorizing...\")\n",
    "\n",
    "# We disabled the load new feature here, so we make new matrix everytime\n",
    "tf, all_mat, x_train = vectorize_text('./lite/text_train.csv', \n",
    "                                      './lite/text_test.csv', \n",
    "                                      './lite/text_validate.csv',\n",
    "                                      './lite/tf.pickle', \n",
    "                                      './lite/matrix.pickle', \n",
    "                                      True,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=MIN_N, max_n=MAX_N)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))\n",
    "\n",
    "print(\"--- Used %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61153, 21888)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It contains all vectorized train, test, vali data in order\n",
    "all_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Used 8.039577007293701 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = LogisticRegression(C=2.387755102040816, penalty='l1', n_jobs=4)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"--- Used %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21888).\n",
      "--- Used 0.2222599983215332 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "predict(model, all_mat, x_train.shape[0], './lite/prediction.csv')\n",
    "\n",
    "print(\"--- Used %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  13.9s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  14.0s\n",
      "[CV] ................................................. , total=  14.1s\n",
      "[CV] ................................................. , total=  14.2s\n",
      "[CV] ................................................. , total=   6.1s\n",
      "5-CV average accuracy: -0.7470094610831955\n",
      "--- Used 20.465030908584595 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   20.3s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(\"5-CV average accuracy: {}\".format(\n",
    "        np.mean(cross_val_score(model, x_train, y_train, cv=5,\n",
    "                                scoring=score, n_jobs=4, verbose=2))))\n",
    "\n",
    "print(\"--- Used %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you get **0.7470094610831955** cross validation mean test RMSE! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you want more\n",
    "\n",
    "Please check 'project/model/lr/tuning.ipynb', the best model should be unibram + one time ridge + C=6 + less aggressive stop word."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat333_project_2",
   "language": "python",
   "name": "stat333_project_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
