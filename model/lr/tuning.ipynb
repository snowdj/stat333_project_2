{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**This notebook is not for showcasing the final work, just an interactive python environment to tune model parameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from pickle import load, dump\n",
    "from os.path import exists\n",
    "\n",
    "# Change THREAD to change model and prediction name\n",
    "THREAD = '_1~10'\n",
    "\n",
    "TRAIN_TEXT = '../../data/text_train.csv'\n",
    "TEST_TEXT = '../../data/text_test.csv'\n",
    "VALI_TEXT = '../../data/text_validate.csv'\n",
    "MINI_TEXT = '../../data/text_mini.csv'\n",
    "PREDICTION_CSV = '../../static/prediction.csv'\n",
    "VECTOR = '../../static/tf_vector.pickle'\n",
    "MATRIX = '../../static/tf_matrix.pickle'\n",
    "PREDICTION = './config/prediction{}.csv'.format(THREAD)\n",
    "MODEL = './config/model{}.pickle'.format(THREAD)\n",
    "\n",
    "STOP = set(stopwords.words(\"english\"))\n",
    "STEMMER = SnowballStemmer(\"english\")\n",
    "LOAD_NEW = False\n",
    "\n",
    "# Tunable parameters\n",
    "MAX_DF = 1.0  # We already have stop words, probably don't need this\n",
    "MIN_DF = 2  # Discard words which not show up twice in all document\n",
    "MAX_FEATURE = None  # IF no memory, tune this down\n",
    "MIN_N = 1\n",
    "MAX_N = 1  # Uni-gram\n",
    "\n",
    "# Used to specify the norm used in the penalization. The ‘newton-cg’,\n",
    "# ‘sag’ and ‘lbfgs’ solvers support only l2 penalties.\n",
    "PENALTY = 'l2'\n",
    "DUAL = False  # Feature > sample then true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Preparation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" Helper function for TFIDF vector from sklearn. We use nltk's tokenize\n",
    "        function here. Also use snowball as stemmer (the middle agressive\n",
    "        one).\n",
    "    \"\"\"\n",
    "    # Filter out stop words, tokenize the text\n",
    "    useful_token = [w.lower() for w in word_tokenize(text) if w not in STOP]\n",
    "\n",
    "    # Stemming the tokens\n",
    "    stemmed_token = [STEMMER.stem(t) for t in useful_token]\n",
    "\n",
    "    return stemmed_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text(train_txt, vali_txt, test_txt, vector, matrix, re_load,\n",
    "                   min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1):\n",
    "    \"\"\" Feature engineering from the raw text input. \"\"\"\n",
    "    # If there is saved model, then just use it\n",
    "    if exists(vector) and exists(matrix) and not re_load:\n",
    "        # Get train length\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "\n",
    "        # Load stored data\n",
    "        all_mat = load(open(matrix, 'rb'))\n",
    "        x_train = all_mat[:table_train.shape[0]]\n",
    "        tf = load(open(vector, 'rb'))\n",
    "\n",
    "    else:\n",
    "        # Read all files\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "        table_test = pd.read_csv(vali_txt)\n",
    "        table_vali = pd.read_csv(test_txt)\n",
    "\n",
    "        text_train = table_train['clean'].tolist()\n",
    "        text_test = table_test['clean'].tolist()\n",
    "        text_vali = table_vali['clean'].tolist()\n",
    "\n",
    "        # We want to have a overall vocabulary bank as `np.py`, so we combine\n",
    "        # all the text first\n",
    "        all_text = text_train + text_test + text_vali\n",
    "\n",
    "        # Record the length so we can recover the training set\n",
    "        train_length = len(text_train)\n",
    "\n",
    "        # Initialize TFID arguments\n",
    "        # Only work for English, discard all Chinese\n",
    "        tf = TfidfVectorizer(min_df=min_df, max_features=max_feature,\n",
    "                             strip_accents='ascii', analyzer='word',\n",
    "                             tokenizer=tokenize, ngram_range=(min_n, max_n))\n",
    "\n",
    "        # Vectorize all, and transform (more efficient than fit + transform)\n",
    "        all_mat = tf.fit_transform(all_text)\n",
    "\n",
    "        # Recover the training data\n",
    "        x_train = all_mat[:train_length]\n",
    "\n",
    "        # Store the fitted matrix and tf_vectorizor\n",
    "        dump(all_mat, open(matrix, 'wb'))\n",
    "        dump(tf, open(vector, 'wb'))\n",
    "\n",
    "    print(\"Successfully load TF-IDF matrix, with shape {}.\".format(\n",
    "        x_train.shape))\n",
    "\n",
    "    return tf, all_mat, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text_count(train_txt, vali_txt, test_txt, vector, matrix, re_load,\n",
    "                   min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1):\n",
    "    \"\"\" Feature engineering from the raw text input. \"\"\"\n",
    "    # If there is saved model, then just use it\n",
    "    if exists(vector) and exists(matrix) and not re_load:\n",
    "        # Get train length\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "\n",
    "        # Load stored data\n",
    "        all_mat = load(open(matrix, 'rb'))\n",
    "        x_train = all_mat[:table_train.shape[0]]\n",
    "        tf = load(open(vector, 'rb'))\n",
    "\n",
    "    else:\n",
    "        # Read all files\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "        table_test = pd.read_csv(vali_txt)\n",
    "        table_vali = pd.read_csv(test_txt)\n",
    "\n",
    "        text_train = table_train['text'].tolist()\n",
    "        text_test = table_test['text'].tolist()\n",
    "        text_vali = table_vali['text'].tolist()\n",
    "\n",
    "        # We want to have a overall vocabulary bank as `np.py`, so we combine\n",
    "        # all the text first\n",
    "        all_text = text_train + text_test + text_vali\n",
    "\n",
    "        # Record the length so we can recover the training set\n",
    "        train_length = len(text_train)\n",
    "\n",
    "        # Initialize TFID arguments\n",
    "        # Only work for English, discard all Chinese\n",
    "        tf = CountVectorizer(min_df=min_df, max_features=max_feature,\n",
    "                             strip_accents='ascii', analyzer='word',\n",
    "                             tokenizer=tokenize, ngram_range=(min_n, max_n))\n",
    "\n",
    "        # Vectorize all, and transform (more efficient than fit + transform)\n",
    "        all_mat = tf.fit_transform(all_text)\n",
    "\n",
    "        # Recover the training data\n",
    "        x_train = all_mat[:train_length]\n",
    "\n",
    "        # Store the fitted matrix and tf_vectorizor\n",
    "        dump(all_mat, open(matrix, 'wb'))\n",
    "        dump(tf, open(vector, 'wb'))\n",
    "\n",
    "    print(\"Successfully load TF-IDF matrix, with shape {}.\".format(\n",
    "        x_train.shape))\n",
    "\n",
    "    return tf, all_mat, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score(estimator, x_test, y_test):\n",
    "    \"\"\" Use mean squared error as score for cv.\"\"\"\n",
    "    probs = estimator.predict_proba(x_test)\n",
    "    result = np.zeros(x_test.shape[0])\n",
    "    for i in range(probs.shape[0]):\n",
    "        result[i] = dis_to_conti(probs[i])\n",
    "    y_int = np.array(list(map(int, y_test)))\n",
    "    # We want to minimize the error\n",
    "    score = (-1) * np.sqrt(np.mean(np.square(result - y_int)))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dis_to_conti(probability):\n",
    "    \"\"\" The kaggle grading is unfair, so I want to force bayesian classifier\n",
    "        gives a continuous result.\n",
    "    \"\"\"\n",
    "    return sum(probability * np.arange(1, 6))\n",
    "\n",
    "def score_mlr(estimator, x_test, y_test):\n",
    "    \"\"\" Use mean squared error as score for cv.\"\"\"\n",
    "    result = estimator.predict(x_test)\n",
    "    y_int = np.array(list(map(int, y_test)))\n",
    "\n",
    "    # We want to minimize the error\n",
    "    score = (-1) * np.sqrt(np.mean(np.square(result - y_int)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_lr(x_train, y_train, model_name):\n",
    "    \"\"\" Train a logistic regression model.\"\"\"\n",
    "    # Use cross validation to search features\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    # param_grid = {'C': [1, 5]}\n",
    "    best_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=DUAL),\n",
    "                              param_grid, scoring=score, cv=10)\n",
    "\n",
    "    best_model.fit(x_train, y_train)\n",
    "    print(best_model.best_estimator_)\n",
    "\n",
    "    # Save the model\n",
    "    dump(best_model, open(model_name, 'wb'))\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(estimator, all_matrix, train_length, output_csv):\n",
    "    \"\"\" Predict the test and validation text, and write to csv.\"\"\"\n",
    "    # Read the text\n",
    "    # `all_matrix` has already contained all the test and vali text\n",
    "    x_predict = all_matrix[train_length:]\n",
    "    print(\"Successfully load predicting text, with shape {}.\".format(\n",
    "        x_predict.shape))\n",
    "\n",
    "    prediction = estimator.predict_proba(x_predict)\n",
    "\n",
    "    # Convert probability to continuous scores\n",
    "    result = np.zeros(x_predict.shape[0])\n",
    "    for i in range(prediction.shape[0]):\n",
    "        result[i] = dis_to_conti(prediction[i])\n",
    "\n",
    "    # Combine ID and write to a file\n",
    "    with open(output_csv, 'w') as output:\n",
    "        output.write('\"Id\",\"Prediction\"\\n')\n",
    "        for i in range(len(result)):\n",
    "            # The id number is 1-indexed\n",
    "            output.write(\"{},{}\\n\".format(i + 1, result[i]))\n",
    "\n",
    "def predict_mlr(estimator, all_matrix, train_length, output_csv):\n",
    "    \"\"\" Predict the test and validation text, and write to csv. The estimator\n",
    "        should be a prediction estimator, instead of a classifier.\n",
    "    \"\"\"\n",
    "    # Read the text\n",
    "    # `all_matrix` has already contained all the test and vali text\n",
    "    x_predict = all_matrix[train_length:]\n",
    "    print(\"Successfully load predicting text, with shape {}.\".format(\n",
    "        x_predict.shape))\n",
    "\n",
    "    prediction = estimator.predict(x_predict)\n",
    "\n",
    "    # Combine ID and write to a file\n",
    "    with open(output_csv, 'w') as output:\n",
    "        output.write('\"Id\",\"Prediction\"\\n')\n",
    "        for i in range(len(prediction)):\n",
    "            output.write(\"{},{}\\n\".format(i, prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start vectorizing...\n",
      "Successfully load TF-IDF matrix, with shape (36692, 21888).\n"
     ]
    }
   ],
   "source": [
    "print(\"Start vectorizing...\")\n",
    "tf, all_mat, x_train = vectorize_text(TRAIN_TEXT, TEST_TEXT, VALI_TEXT,\n",
    "                                      VECTOR, MATRIX, False,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=MIN_N, max_n=MAX_N)\n",
    "# predict(test_model, all_mat, x_train.shape[0], './config/prediction_lasso_1-6.csv')\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tuning for Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start vectorizing...\n",
      "Successfully load TF-IDF matrix, with shape (36692, 23617).\n"
     ]
    }
   ],
   "source": [
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))\n",
    "\n",
    "# print(\"Start training...\")\n",
    "# lr = train_lr(x_train, y_train, MODEL)\n",
    "\n",
    "# predict(lr.best_estimator_, all_mat, x_train.shape[0], PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.63391</td>\n",
       "      <td>-1.37801</td>\n",
       "      <td>-0.846607</td>\n",
       "      <td>-0.496936</td>\n",
       "      <td>-0.28908</td>\n",
       "      <td>-0.135901</td>\n",
       "      <td>-0.0645506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.63715</td>\n",
       "      <td>-1.39592</td>\n",
       "      <td>-0.904112</td>\n",
       "      <td>-0.625058</td>\n",
       "      <td>-0.590711</td>\n",
       "      <td>-0.7099</td>\n",
       "      <td>-0.927654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.709696</td>\n",
       "      <td>1.02414</td>\n",
       "      <td>1.61381</td>\n",
       "      <td>2.84692</td>\n",
       "      <td>5.74794</td>\n",
       "      <td>13.1925</td>\n",
       "      <td>32.3762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.63433</td>\n",
       "      <td>-1.37618</td>\n",
       "      <td>-0.847281</td>\n",
       "      <td>-0.558943</td>\n",
       "      <td>-0.530479</td>\n",
       "      <td>-0.663934</td>\n",
       "      <td>-0.880629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-1.63443</td>\n",
       "      <td>-1.37924</td>\n",
       "      <td>-0.844654</td>\n",
       "      <td>-0.495111</td>\n",
       "      <td>-0.288394</td>\n",
       "      <td>-0.135352</td>\n",
       "      <td>-0.0632319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00164988</td>\n",
       "      <td>0.00753849</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>0.0210609</td>\n",
       "      <td>0.0247995</td>\n",
       "      <td>0.0324021</td>\n",
       "      <td>0.0385761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-1.63496</td>\n",
       "      <td>-1.38159</td>\n",
       "      <td>-0.849273</td>\n",
       "      <td>-0.499018</td>\n",
       "      <td>-0.290315</td>\n",
       "      <td>-0.135404</td>\n",
       "      <td>-0.0627491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.63528</td>\n",
       "      <td>-1.38569</td>\n",
       "      <td>-0.875304</td>\n",
       "      <td>-0.593716</td>\n",
       "      <td>-0.564088</td>\n",
       "      <td>-0.69626</td>\n",
       "      <td>-0.913187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-1.63488</td>\n",
       "      <td>-1.38901</td>\n",
       "      <td>-0.89233</td>\n",
       "      <td>-0.615577</td>\n",
       "      <td>-0.577727</td>\n",
       "      <td>-0.678939</td>\n",
       "      <td>-0.850457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.0015784</td>\n",
       "      <td>0.0013717</td>\n",
       "      <td>0.000362707</td>\n",
       "      <td>0.000780727</td>\n",
       "      <td>0.00128881</td>\n",
       "      <td>0.00407504</td>\n",
       "      <td>0.00474688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.63452</td>\n",
       "      <td>-1.3822</td>\n",
       "      <td>-0.876013</td>\n",
       "      <td>-0.59983</td>\n",
       "      <td>-0.571172</td>\n",
       "      <td>-0.707007</td>\n",
       "      <td>-0.938232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-1.63495</td>\n",
       "      <td>-1.38517</td>\n",
       "      <td>-0.881862</td>\n",
       "      <td>-0.616591</td>\n",
       "      <td>-0.603156</td>\n",
       "      <td>-0.768782</td>\n",
       "      <td>-0.995119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.63402</td>\n",
       "      <td>-1.37763</td>\n",
       "      <td>-0.843341</td>\n",
       "      <td>-0.494188</td>\n",
       "      <td>-0.286779</td>\n",
       "      <td>-0.134021</td>\n",
       "      <td>-0.0626839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-1.63443</td>\n",
       "      <td>-1.37968</td>\n",
       "      <td>-0.845716</td>\n",
       "      <td>-0.494661</td>\n",
       "      <td>-0.287104</td>\n",
       "      <td>-0.133368</td>\n",
       "      <td>-0.0618336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-1.63182</td>\n",
       "      <td>-1.37427</td>\n",
       "      <td>-0.858288</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.532224</td>\n",
       "      <td>-0.650742</td>\n",
       "      <td>-0.875758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-1.63471</td>\n",
       "      <td>-1.38048</td>\n",
       "      <td>-0.858634</td>\n",
       "      <td>-0.575132</td>\n",
       "      <td>-0.550473</td>\n",
       "      <td>-0.689129</td>\n",
       "      <td>-0.904032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.6346</td>\n",
       "      <td>-1.38147</td>\n",
       "      <td>-0.85048</td>\n",
       "      <td>-0.500156</td>\n",
       "      <td>-0.290508</td>\n",
       "      <td>-0.135911</td>\n",
       "      <td>-0.0633018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.63438</td>\n",
       "      <td>-1.37963</td>\n",
       "      <td>-0.846799</td>\n",
       "      <td>-0.497042</td>\n",
       "      <td>-0.288903</td>\n",
       "      <td>-0.135064</td>\n",
       "      <td>-0.0628707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.63548</td>\n",
       "      <td>-1.38305</td>\n",
       "      <td>-0.868062</td>\n",
       "      <td>-0.573642</td>\n",
       "      <td>-0.536454</td>\n",
       "      <td>-0.670263</td>\n",
       "      <td>-0.900722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.63442</td>\n",
       "      <td>-1.38035</td>\n",
       "      <td>-0.848959</td>\n",
       "      <td>-0.500538</td>\n",
       "      <td>-0.292089</td>\n",
       "      <td>-0.13721</td>\n",
       "      <td>-0.0641275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0212395</td>\n",
       "      <td>0.0202191</td>\n",
       "      <td>0.051291</td>\n",
       "      <td>0.0418466</td>\n",
       "      <td>0.281117</td>\n",
       "      <td>0.956785</td>\n",
       "      <td>3.60982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0178438</td>\n",
       "      <td>0.0174564</td>\n",
       "      <td>0.0170002</td>\n",
       "      <td>0.0175394</td>\n",
       "      <td>0.0181249</td>\n",
       "      <td>0.0192689</td>\n",
       "      <td>0.0205178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.63454</td>\n",
       "      <td>-1.37999</td>\n",
       "      <td>-0.845013</td>\n",
       "      <td>-0.495616</td>\n",
       "      <td>-0.288037</td>\n",
       "      <td>-0.134171</td>\n",
       "      <td>-0.0621349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-1.63399</td>\n",
       "      <td>-1.37784</td>\n",
       "      <td>-0.845264</td>\n",
       "      <td>-0.495623</td>\n",
       "      <td>-0.287237</td>\n",
       "      <td>-0.134315</td>\n",
       "      <td>-0.0620995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000306772</td>\n",
       "      <td>0.00136608</td>\n",
       "      <td>0.00226309</td>\n",
       "      <td>0.00223087</td>\n",
       "      <td>0.00163152</td>\n",
       "      <td>0.00107473</td>\n",
       "      <td>0.00088024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.63761</td>\n",
       "      <td>-1.3946</td>\n",
       "      <td>-0.879774</td>\n",
       "      <td>-0.591861</td>\n",
       "      <td>-0.560486</td>\n",
       "      <td>-0.699629</td>\n",
       "      <td>-0.920638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-1.63732</td>\n",
       "      <td>-1.39598</td>\n",
       "      <td>-0.886677</td>\n",
       "      <td>-0.604917</td>\n",
       "      <td>-0.588002</td>\n",
       "      <td>-0.724262</td>\n",
       "      <td>-0.938564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-1.63453</td>\n",
       "      <td>-1.38053</td>\n",
       "      <td>-0.848688</td>\n",
       "      <td>-0.498572</td>\n",
       "      <td>-0.289482</td>\n",
       "      <td>-0.13499</td>\n",
       "      <td>-0.0619937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0.001        0.010        0.100        1.000     \\\n",
       "split4_train_score      -1.63391     -1.37801    -0.846607    -0.496936   \n",
       "split2_test_score       -1.63715     -1.39592    -0.904112    -0.625058   \n",
       "mean_fit_time           0.709696      1.02414      1.61381      2.84692   \n",
       "split3_test_score       -1.63433     -1.37618    -0.847281    -0.558943   \n",
       "split9_train_score      -1.63443     -1.37924    -0.844654    -0.495111   \n",
       "std_test_score        0.00164988   0.00753849     0.016486    0.0210609   \n",
       "rank_test_score                7            6            4            2   \n",
       "split8_train_score      -1.63496     -1.38159    -0.849273    -0.499018   \n",
       "mean_test_score         -1.63528     -1.38569    -0.875304    -0.593716   \n",
       "split9_test_score       -1.63488     -1.38901     -0.89233    -0.615577   \n",
       "std_score_time         0.0015784    0.0013717  0.000362707  0.000780727   \n",
       "param_C                    0.001         0.01          0.1            1   \n",
       "split1_test_score       -1.63452      -1.3822    -0.876013     -0.59983   \n",
       "split5_test_score       -1.63495     -1.38517    -0.881862    -0.616591   \n",
       "params              {'C': 0.001}  {'C': 0.01}   {'C': 0.1}     {'C': 1}   \n",
       "split2_train_score      -1.63402     -1.37763    -0.843341    -0.494188   \n",
       "split5_train_score      -1.63443     -1.37968    -0.845716    -0.494661   \n",
       "split8_test_score       -1.63182     -1.37427    -0.858288    -0.575606   \n",
       "split7_test_score       -1.63471     -1.38048    -0.858634    -0.575132   \n",
       "split3_train_score       -1.6346     -1.38147     -0.85048    -0.500156   \n",
       "mean_train_score        -1.63438     -1.37963    -0.846799    -0.497042   \n",
       "split0_test_score       -1.63548     -1.38305    -0.868062    -0.573642   \n",
       "split0_train_score      -1.63442     -1.38035    -0.848959    -0.500538   \n",
       "std_fit_time           0.0212395    0.0202191     0.051291    0.0418466   \n",
       "mean_score_time        0.0178438    0.0174564    0.0170002    0.0175394   \n",
       "split1_train_score      -1.63454     -1.37999    -0.845013    -0.495616   \n",
       "split6_train_score      -1.63399     -1.37784    -0.845264    -0.495623   \n",
       "std_train_score      0.000306772   0.00136608   0.00226309   0.00223087   \n",
       "split4_test_score       -1.63761      -1.3946    -0.879774    -0.591861   \n",
       "split6_test_score       -1.63732     -1.39598    -0.886677    -0.604917   \n",
       "split7_train_score      -1.63453     -1.38053    -0.848688    -0.498572   \n",
       "\n",
       "                      10.000      100.000      1000.000  \n",
       "split4_train_score    -0.28908   -0.135901   -0.0645506  \n",
       "split2_test_score    -0.590711     -0.7099    -0.927654  \n",
       "mean_fit_time          5.74794     13.1925      32.3762  \n",
       "split3_test_score    -0.530479   -0.663934    -0.880629  \n",
       "split9_train_score   -0.288394   -0.135352   -0.0632319  \n",
       "std_test_score       0.0247995   0.0324021    0.0385761  \n",
       "rank_test_score              1           3            5  \n",
       "split8_train_score   -0.290315   -0.135404   -0.0627491  \n",
       "mean_test_score      -0.564088    -0.69626    -0.913187  \n",
       "split9_test_score    -0.577727   -0.678939    -0.850457  \n",
       "std_score_time      0.00128881  0.00407504   0.00474688  \n",
       "param_C                     10         100         1000  \n",
       "split1_test_score    -0.571172   -0.707007    -0.938232  \n",
       "split5_test_score    -0.603156   -0.768782    -0.995119  \n",
       "params               {'C': 10}  {'C': 100}  {'C': 1000}  \n",
       "split2_train_score   -0.286779   -0.134021   -0.0626839  \n",
       "split5_train_score   -0.287104   -0.133368   -0.0618336  \n",
       "split8_test_score    -0.532224   -0.650742    -0.875758  \n",
       "split7_test_score    -0.550473   -0.689129    -0.904032  \n",
       "split3_train_score   -0.290508   -0.135911   -0.0633018  \n",
       "mean_train_score     -0.288903   -0.135064   -0.0628707  \n",
       "split0_test_score    -0.536454   -0.670263    -0.900722  \n",
       "split0_train_score   -0.292089    -0.13721   -0.0641275  \n",
       "std_fit_time          0.281117    0.956785      3.60982  \n",
       "mean_score_time      0.0181249   0.0192689    0.0205178  \n",
       "split1_train_score   -0.288037   -0.134171   -0.0621349  \n",
       "split6_train_score   -0.287237   -0.134315   -0.0620995  \n",
       "std_train_score     0.00163152  0.00107473   0.00088024  \n",
       "split4_test_score    -0.560486   -0.699629    -0.920638  \n",
       "split6_test_score    -0.588002   -0.724262    -0.938564  \n",
       "split7_train_score   -0.289482    -0.13499   -0.0619937  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result = pd.DataFrame.from_dict(lr.cv_results_, orient='index')\n",
    "cv_result.columns = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We got 0.56 mean squared error on the training data. Let's see how it works for the test and vali data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n",
      "Wrote to the output prediction.csv\n"
     ]
    }
   ],
   "source": [
    "predict(lr.best_estimator_, all_mat, x_train.shape[0], \"prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Maybe we can get better result by keep tuning the regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4934f5107ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                           param_grid, scoring=score, cv=5, n_jobs=4)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbetter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetter_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.2_2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.2_2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.2_2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.2_2/Frameworks/Python.framework/Versions/3.5/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': range(3,6)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=DUAL),\n",
    "                          param_grid, scoring=score, cv=5, n_jobs=4)\n",
    "\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open(MODEL, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.74867</td>\n",
       "      <td>-0.746095</td>\n",
       "      <td>-0.745346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.624197</td>\n",
       "      <td>-0.602078</td>\n",
       "      <td>-0.584653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.74921</td>\n",
       "      <td>-0.747209</td>\n",
       "      <td>-0.74692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00131852</td>\n",
       "      <td>0.00133528</td>\n",
       "      <td>0.00134358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.624658</td>\n",
       "      <td>-0.602595</td>\n",
       "      <td>-0.585216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.749274</td>\n",
       "      <td>-0.747912</td>\n",
       "      <td>-0.748137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.382927</td>\n",
       "      <td>0.31633</td>\n",
       "      <td>0.978515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00864954</td>\n",
       "      <td>0.0149153</td>\n",
       "      <td>0.0140285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.622973</td>\n",
       "      <td>-0.601061</td>\n",
       "      <td>-0.583795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.748417</td>\n",
       "      <td>-0.746274</td>\n",
       "      <td>-0.745803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0774592</td>\n",
       "      <td>0.0960582</td>\n",
       "      <td>0.0615812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.627027</td>\n",
       "      <td>-0.605102</td>\n",
       "      <td>-0.587802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.624759</td>\n",
       "      <td>-0.602765</td>\n",
       "      <td>-0.585435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>8.82112</td>\n",
       "      <td>8.70701</td>\n",
       "      <td>8.23926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.624938</td>\n",
       "      <td>-0.602991</td>\n",
       "      <td>-0.585709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00491389</td>\n",
       "      <td>0.0053086</td>\n",
       "      <td>0.00562589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>{'C': 4}</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.757558</td>\n",
       "      <td>-0.756171</td>\n",
       "      <td>-0.756374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.742132</td>\n",
       "      <td>-0.739596</td>\n",
       "      <td>-0.738942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             3           4           5\n",
       "split4_test_score     -0.74867   -0.746095   -0.745346\n",
       "split3_train_score   -0.624197   -0.602078   -0.584653\n",
       "mean_test_score       -0.74921   -0.747209    -0.74692\n",
       "std_train_score     0.00131852  0.00133528  0.00134358\n",
       "split1_train_score   -0.624658   -0.602595   -0.585216\n",
       "split3_test_score    -0.749274   -0.747912   -0.748137\n",
       "std_fit_time          0.382927     0.31633    0.978515\n",
       "std_score_time      0.00864954   0.0149153   0.0140285\n",
       "rank_test_score              3           2           1\n",
       "param_C                      3           4           5\n",
       "split2_train_score   -0.622973   -0.601061   -0.583795\n",
       "split1_test_score    -0.748417   -0.746274   -0.745803\n",
       "mean_score_time      0.0774592   0.0960582   0.0615812\n",
       "split0_train_score   -0.627027   -0.605102   -0.587802\n",
       "mean_train_score     -0.624759   -0.602765   -0.585435\n",
       "mean_fit_time          8.82112     8.70701     8.23926\n",
       "split4_train_score   -0.624938   -0.602991   -0.585709\n",
       "std_test_score      0.00491389   0.0053086  0.00562589\n",
       "params                {'C': 3}    {'C': 4}    {'C': 5}\n",
       "split2_test_score    -0.757558   -0.756171   -0.756374\n",
       "split0_test_score    -0.742132   -0.739596   -0.738942"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = range(3,6)\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=2, penalty='l1')\n",
    "test.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenomen\n",
      "exceed\n",
      "mmmmmmm\n",
      "hue\n",
      "superb\n",
      "best\n",
      "amaz\n",
      "banzo\n",
      "favorit\n",
      "sophia\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-529106a67f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#tf.vocabulary_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 12 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "coef = test.coef_[4]\n",
    "index = np.argpartition(coef, -10)[-10:]\n",
    "#index = [7067, 868, 3652, 19508, 12097, 12503, 7884, 2618, 13874, 23389]\n",
    "for i in index:\n",
    "    for k, v in tf.vocabulary_.items():\n",
    "        if i == v:\n",
    "            print(k)\n",
    "print(coef[index[12]])\n",
    "coef[1:10]\n",
    "#tf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Therefore, for now, we just keep using c = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    }
   ],
   "source": [
    "predict(better_model.best_estimator_, all_mat, x_train.shape[0], PREDICTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "See how TF-IDF matrix look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 19615)\t0.13538616739\n",
      "  (0, 0)\t0.177035528504\n",
      "  (0, 14368)\t0.086454396434\n",
      "  (0, 23394)\t0.0903257044619\n",
      "  (0, 18)\t0.0914622594844\n",
      "  (0, 8022)\t0.173126772941\n",
      "  (0, 6995)\t0.154364864126\n",
      "  (0, 173)\t0.230221927247\n",
      "  (0, 2994)\t0.0588120425056\n",
      "  (0, 6518)\t0.13580411238\n",
      "  (0, 3620)\t0.125624228969\n",
      "  (0, 8023)\t0.13624184676\n",
      "  (0, 3512)\t0.0751911573647\n",
      "  (0, 6070)\t0.243957007807\n",
      "  (0, 4878)\t0.244542232848\n",
      "  (0, 11102)\t0.110095344717\n",
      "  (0, 9004)\t0.0769081056065\n",
      "  (0, 17618)\t0.222637529068\n",
      "  (0, 16639)\t0.175006803316\n",
      "  (0, 344)\t0.0734072607975\n",
      "  (0, 19039)\t0.162969581364\n",
      "  (0, 19893)\t0.0980655529045\n",
      "  (0, 16998)\t0.0884625970817\n",
      "  (0, 15264)\t0.119170684178\n",
      "  (0, 8657)\t0.18721852126\n",
      "  :\t:\n",
      "  (0, 9816)\t0.10271633557\n",
      "  (0, 18111)\t0.0789800307954\n",
      "  (0, 12413)\t0.10062393388\n",
      "  (0, 15900)\t0.0803202194759\n",
      "  (0, 7380)\t0.113373984273\n",
      "  (0, 18142)\t0.119594933902\n",
      "  (0, 3065)\t0.117136202154\n",
      "  (0, 16485)\t0.089357874059\n",
      "  (0, 17866)\t0.0969360665738\n",
      "  (0, 13366)\t0.124077938702\n",
      "  (0, 13977)\t0.122649925816\n",
      "  (0, 9613)\t0.0431519861959\n",
      "  (0, 6830)\t0.0984601200877\n",
      "  (0, 20146)\t0.188713123193\n",
      "  (0, 17199)\t0.132245831948\n",
      "  (0, 17673)\t0.0826853631383\n",
      "  (0, 17997)\t0.172728332976\n",
      "  (0, 17125)\t0.187583503075\n",
      "  (0, 4127)\t0.171197836374\n",
      "  (0, 4041)\t0.0875100015233\n",
      "  (0, 16896)\t0.154351196417\n",
      "  (0, 18501)\t0.0867830227958\n",
      "  (0, 19453)\t0.112089277887\n",
      "  (0, 19830)\t0.210425811125\n",
      "  (0, 10734)\t0.0997217194665\n"
     ]
    }
   ],
   "source": [
    "print(all_mat[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try 2-gram feature, with regularizaiton term = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 1046524).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat, x_train = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_2_gram.pickle', \n",
    "                                      matrix='../../static/tf_matrix_2_gram.pickle', re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=2, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [4]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=True),\n",
    "                          param_grid, scoring=score, cv=10)\n",
    "\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_2_gram_4'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.669253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000896907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0184079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>3.55656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.722854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.24184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.689041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.242652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.714668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.682211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.242651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.672894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.242982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.241493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.244338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.695122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.243465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.242903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.6901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.72226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000607552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.131886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.241521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.696478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.706383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.243394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.241921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0241437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0\n",
       "rank_test_score               1\n",
       "split3_test_score     -0.669253\n",
       "std_train_score     0.000896907\n",
       "param_C                       4\n",
       "std_test_score        0.0184079\n",
       "mean_fit_time           3.55656\n",
       "params                 {'C': 4}\n",
       "split9_test_score     -0.722854\n",
       "split2_train_score     -0.24184\n",
       "split4_test_score     -0.689041\n",
       "split6_train_score    -0.242652\n",
       "split5_test_score     -0.714668\n",
       "split8_test_score     -0.682211\n",
       "mean_train_score      -0.242651\n",
       "split0_test_score     -0.672894\n",
       "split7_train_score    -0.242982\n",
       "split1_train_score    -0.241493\n",
       "split0_train_score    -0.244338\n",
       "split6_test_score     -0.695122\n",
       "split3_train_score    -0.243465\n",
       "split4_train_score    -0.242903\n",
       "split7_test_score       -0.6901\n",
       "split2_test_score      -0.72226\n",
       "std_score_time      0.000607552\n",
       "std_fit_time           0.131886\n",
       "split9_train_score    -0.241521\n",
       "mean_test_score       -0.696478\n",
       "split1_test_score     -0.706383\n",
       "split8_train_score    -0.243394\n",
       "split5_train_score    -0.241921\n",
       "mean_score_time       0.0241437"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Well, looks not that good, lets try to tune the parameter again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=True),\n",
    "                          param_grid, scoring=score, cv=10)\n",
    "\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_2_gram_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.6703</td>\n",
       "      <td>-1.60476</td>\n",
       "      <td>-1.39568</td>\n",
       "      <td>-0.877016</td>\n",
       "      <td>-0.601214</td>\n",
       "      <td>-0.57516</td>\n",
       "      <td>-0.618154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>8.25316e-05</td>\n",
       "      <td>0.000265205</td>\n",
       "      <td>0.00117758</td>\n",
       "      <td>0.00174121</td>\n",
       "      <td>0.00037835</td>\n",
       "      <td>1.88318e-05</td>\n",
       "      <td>5.25198e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000545649</td>\n",
       "      <td>0.00138635</td>\n",
       "      <td>0.00623148</td>\n",
       "      <td>0.0151184</td>\n",
       "      <td>0.01978</td>\n",
       "      <td>0.0230089</td>\n",
       "      <td>0.0254126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>2.31468</td>\n",
       "      <td>1.99449</td>\n",
       "      <td>1.96908</td>\n",
       "      <td>2.6542</td>\n",
       "      <td>6.10179</td>\n",
       "      <td>14.7557</td>\n",
       "      <td>15.3552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-1.66933</td>\n",
       "      <td>-1.60404</td>\n",
       "      <td>-1.40243</td>\n",
       "      <td>-0.916154</td>\n",
       "      <td>-0.659143</td>\n",
       "      <td>-0.637862</td>\n",
       "      <td>-0.684875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.66937</td>\n",
       "      <td>-1.59941</td>\n",
       "      <td>-1.3559</td>\n",
       "      <td>-0.650916</td>\n",
       "      <td>-0.0907433</td>\n",
       "      <td>-0.00375308</td>\n",
       "      <td>-9.26273e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.67027</td>\n",
       "      <td>-1.60561</td>\n",
       "      <td>-1.40474</td>\n",
       "      <td>-0.898603</td>\n",
       "      <td>-0.618091</td>\n",
       "      <td>-0.587724</td>\n",
       "      <td>-0.631872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-1.66937</td>\n",
       "      <td>-1.59942</td>\n",
       "      <td>-1.35602</td>\n",
       "      <td>-0.652477</td>\n",
       "      <td>-0.0911098</td>\n",
       "      <td>-0.00377946</td>\n",
       "      <td>-9.35378e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-1.67026</td>\n",
       "      <td>-1.60556</td>\n",
       "      <td>-1.40498</td>\n",
       "      <td>-0.911223</td>\n",
       "      <td>-0.652189</td>\n",
       "      <td>-0.635585</td>\n",
       "      <td>-0.681562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-1.66906</td>\n",
       "      <td>-1.60216</td>\n",
       "      <td>-1.39174</td>\n",
       "      <td>-0.883189</td>\n",
       "      <td>-0.616502</td>\n",
       "      <td>-0.587201</td>\n",
       "      <td>-0.623416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.66947</td>\n",
       "      <td>-1.5998</td>\n",
       "      <td>-1.35758</td>\n",
       "      <td>-0.65305</td>\n",
       "      <td>-0.0910337</td>\n",
       "      <td>-0.00376962</td>\n",
       "      <td>-9.32066e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.66998</td>\n",
       "      <td>-1.60362</td>\n",
       "      <td>-1.39315</td>\n",
       "      <td>-0.876164</td>\n",
       "      <td>-0.608134</td>\n",
       "      <td>-0.584066</td>\n",
       "      <td>-0.624863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-1.66957</td>\n",
       "      <td>-1.59998</td>\n",
       "      <td>-1.35818</td>\n",
       "      <td>-0.653686</td>\n",
       "      <td>-0.0911531</td>\n",
       "      <td>-0.00377512</td>\n",
       "      <td>-9.34001e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.66946</td>\n",
       "      <td>-1.59982</td>\n",
       "      <td>-1.3574</td>\n",
       "      <td>-0.651171</td>\n",
       "      <td>-0.0905459</td>\n",
       "      <td>-0.0037469</td>\n",
       "      <td>-9.26167e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.66948</td>\n",
       "      <td>-1.60007</td>\n",
       "      <td>-1.35909</td>\n",
       "      <td>-0.655924</td>\n",
       "      <td>-0.091775</td>\n",
       "      <td>-0.00380526</td>\n",
       "      <td>-9.41562e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-1.67073</td>\n",
       "      <td>-1.60673</td>\n",
       "      <td>-1.41012</td>\n",
       "      <td>-0.905234</td>\n",
       "      <td>-0.623688</td>\n",
       "      <td>-0.588577</td>\n",
       "      <td>-0.626216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.66942</td>\n",
       "      <td>-1.59985</td>\n",
       "      <td>-1.35873</td>\n",
       "      <td>-0.655075</td>\n",
       "      <td>-0.0913035</td>\n",
       "      <td>-0.00377636</td>\n",
       "      <td>-9.32792e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.66942</td>\n",
       "      <td>-1.59961</td>\n",
       "      <td>-1.35683</td>\n",
       "      <td>-0.653012</td>\n",
       "      <td>-0.0912151</td>\n",
       "      <td>-0.00378616</td>\n",
       "      <td>-9.37274e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-1.66937</td>\n",
       "      <td>-1.60348</td>\n",
       "      <td>-1.39711</td>\n",
       "      <td>-0.890273</td>\n",
       "      <td>-0.624518</td>\n",
       "      <td>-0.598256</td>\n",
       "      <td>-0.639619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.67067</td>\n",
       "      <td>-1.6067</td>\n",
       "      <td>-1.40994</td>\n",
       "      <td>-0.920574</td>\n",
       "      <td>-0.657215</td>\n",
       "      <td>-0.635164</td>\n",
       "      <td>-0.68088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00190881</td>\n",
       "      <td>0.0036648</td>\n",
       "      <td>0.00289284</td>\n",
       "      <td>0.00198088</td>\n",
       "      <td>0.00191841</td>\n",
       "      <td>0.00141428</td>\n",
       "      <td>0.000956611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.120993</td>\n",
       "      <td>0.140022</td>\n",
       "      <td>0.0731578</td>\n",
       "      <td>0.0514999</td>\n",
       "      <td>0.216591</td>\n",
       "      <td>0.531717</td>\n",
       "      <td>0.51412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-1.66957</td>\n",
       "      <td>-1.59991</td>\n",
       "      <td>-1.35761</td>\n",
       "      <td>-0.651333</td>\n",
       "      <td>-0.090519</td>\n",
       "      <td>-0.00374209</td>\n",
       "      <td>-9.24361e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.67001</td>\n",
       "      <td>-1.60472</td>\n",
       "      <td>-1.40093</td>\n",
       "      <td>-0.898117</td>\n",
       "      <td>-0.630207</td>\n",
       "      <td>-0.604518</td>\n",
       "      <td>-0.646785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.6701</td>\n",
       "      <td>-1.60459</td>\n",
       "      <td>-1.39941</td>\n",
       "      <td>-0.902752</td>\n",
       "      <td>-0.641383</td>\n",
       "      <td>-0.615584</td>\n",
       "      <td>-0.656392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-1.66962</td>\n",
       "      <td>-1.60027</td>\n",
       "      <td>-1.35938</td>\n",
       "      <td>-0.655164</td>\n",
       "      <td>-0.0912729</td>\n",
       "      <td>-0.00377715</td>\n",
       "      <td>-9.34143e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-1.66942</td>\n",
       "      <td>-1.59962</td>\n",
       "      <td>-1.35668</td>\n",
       "      <td>-0.651738</td>\n",
       "      <td>-0.0906993</td>\n",
       "      <td>-0.00375462</td>\n",
       "      <td>-9.28711e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.025683</td>\n",
       "      <td>0.0263712</td>\n",
       "      <td>0.0251598</td>\n",
       "      <td>0.0255081</td>\n",
       "      <td>0.0257353</td>\n",
       "      <td>0.0254278</td>\n",
       "      <td>0.0251389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0            1           2           3  \\\n",
       "rank_test_score                7            6           5           4   \n",
       "split3_test_score        -1.6703     -1.60476    -1.39568   -0.877016   \n",
       "std_train_score      8.25316e-05  0.000265205  0.00117758  0.00174121   \n",
       "param_C                    0.001         0.01         0.1           1   \n",
       "std_test_score       0.000545649   0.00138635  0.00623148   0.0151184   \n",
       "mean_fit_time            2.31468      1.99449     1.96908      2.6542   \n",
       "params              {'C': 0.001}  {'C': 0.01}  {'C': 0.1}    {'C': 1}   \n",
       "split9_test_score       -1.66933     -1.60404    -1.40243   -0.916154   \n",
       "split2_train_score      -1.66937     -1.59941     -1.3559   -0.650916   \n",
       "split4_test_score       -1.67027     -1.60561    -1.40474   -0.898603   \n",
       "split6_train_score      -1.66937     -1.59942    -1.35602   -0.652477   \n",
       "split5_test_score       -1.67026     -1.60556    -1.40498   -0.911223   \n",
       "split8_test_score       -1.66906     -1.60216    -1.39174   -0.883189   \n",
       "mean_train_score        -1.66947      -1.5998    -1.35758    -0.65305   \n",
       "split0_test_score       -1.66998     -1.60362    -1.39315   -0.876164   \n",
       "split7_train_score      -1.66957     -1.59998    -1.35818   -0.653686   \n",
       "split1_train_score      -1.66946     -1.59982     -1.3574   -0.651171   \n",
       "split0_train_score      -1.66948     -1.60007    -1.35909   -0.655924   \n",
       "split6_test_score       -1.67073     -1.60673    -1.41012   -0.905234   \n",
       "split3_train_score      -1.66942     -1.59985    -1.35873   -0.655075   \n",
       "split4_train_score      -1.66942     -1.59961    -1.35683   -0.653012   \n",
       "split7_test_score       -1.66937     -1.60348    -1.39711   -0.890273   \n",
       "split2_test_score       -1.67067      -1.6067    -1.40994   -0.920574   \n",
       "std_score_time        0.00190881    0.0036648  0.00289284  0.00198088   \n",
       "std_fit_time            0.120993     0.140022   0.0731578   0.0514999   \n",
       "split9_train_score      -1.66957     -1.59991    -1.35761   -0.651333   \n",
       "mean_test_score         -1.67001     -1.60472    -1.40093   -0.898117   \n",
       "split1_test_score        -1.6701     -1.60459    -1.39941   -0.902752   \n",
       "split8_train_score      -1.66962     -1.60027    -1.35938   -0.655164   \n",
       "split5_train_score      -1.66942     -1.59962    -1.35668   -0.651738   \n",
       "mean_score_time         0.025683    0.0263712   0.0251598   0.0255081   \n",
       "\n",
       "                             4            5            6  \n",
       "rank_test_score              2            1            3  \n",
       "split3_test_score    -0.601214     -0.57516    -0.618154  \n",
       "std_train_score     0.00037835  1.88318e-05  5.25198e-07  \n",
       "param_C                     10          100         1000  \n",
       "std_test_score         0.01978    0.0230089    0.0254126  \n",
       "mean_fit_time          6.10179      14.7557      15.3552  \n",
       "params               {'C': 10}   {'C': 100}  {'C': 1000}  \n",
       "split9_test_score    -0.659143    -0.637862    -0.684875  \n",
       "split2_train_score  -0.0907433  -0.00375308 -9.26273e-05  \n",
       "split4_test_score    -0.618091    -0.587724    -0.631872  \n",
       "split6_train_score  -0.0911098  -0.00377946 -9.35378e-05  \n",
       "split5_test_score    -0.652189    -0.635585    -0.681562  \n",
       "split8_test_score    -0.616502    -0.587201    -0.623416  \n",
       "mean_train_score    -0.0910337  -0.00376962 -9.32066e-05  \n",
       "split0_test_score    -0.608134    -0.584066    -0.624863  \n",
       "split7_train_score  -0.0911531  -0.00377512 -9.34001e-05  \n",
       "split1_train_score  -0.0905459   -0.0037469 -9.26167e-05  \n",
       "split0_train_score   -0.091775  -0.00380526 -9.41562e-05  \n",
       "split6_test_score    -0.623688    -0.588577    -0.626216  \n",
       "split3_train_score  -0.0913035  -0.00377636 -9.32792e-05  \n",
       "split4_train_score  -0.0912151  -0.00378616 -9.37274e-05  \n",
       "split7_test_score    -0.624518    -0.598256    -0.639619  \n",
       "split2_test_score    -0.657215    -0.635164     -0.68088  \n",
       "std_score_time      0.00191841   0.00141428  0.000956611  \n",
       "std_fit_time          0.216591     0.531717      0.51412  \n",
       "split9_train_score   -0.090519  -0.00374209 -9.24361e-05  \n",
       "mean_test_score      -0.630207    -0.604518    -0.646785  \n",
       "split1_test_score    -0.641383    -0.615584    -0.656392  \n",
       "split8_train_score  -0.0912729  -0.00377715 -9.34143e-05  \n",
       "split5_train_score  -0.0906993  -0.00375462 -9.28711e-05  \n",
       "mean_score_time      0.0257353    0.0254278    0.0251389  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems 2-gram itself is not good as unigram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make a bad model to achieve about 0.9 error, to troll other students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 23617).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat, x_train = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector=VECTOR, \n",
    "                                      matrix=MATRIX, re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    }
   ],
   "source": [
    "bad_model = LogisticRegression(C=0.0685, class_weight=None, dual=True, fit_intercept=True,\n",
    "              intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "              penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "              verbose=0, warm_start=False)\n",
    "bad_model.fit(x_train, y_train)\n",
    "predict(bad_model, all_mat, x_train.shape[0], './config/bad_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    }
   ],
   "source": [
    "predict(bad_model, all_mat, x_train.shape[0], './config/bad_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Anyway, let's keep tuning the parameters for 2-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 1046524).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat, x_train_2 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_2_gram.pickle', \n",
    "                                      matrix='../../static/tf_matrix_2_gram.pickle', re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=2, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_2 = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': range(10, 101, 10)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty=PENALTY, dual=True),\n",
    "                          param_grid, scoring=score, cv=10, n_jobs=4)\n",
    "\n",
    "better_model.fit(x_train_2, y_train_2)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_2_gram_10-100'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "      <th>70</th>\n",
       "      <th>80</th>\n",
       "      <th>90</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.601214</td>\n",
       "      <td>-0.577178</td>\n",
       "      <td>-0.571133</td>\n",
       "      <td>-0.569575</td>\n",
       "      <td>-0.569641</td>\n",
       "      <td>-0.570394</td>\n",
       "      <td>-0.571457</td>\n",
       "      <td>-0.572656</td>\n",
       "      <td>-0.573905</td>\n",
       "      <td>-0.57516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000378354</td>\n",
       "      <td>0.000168336</td>\n",
       "      <td>0.000100351</td>\n",
       "      <td>6.8438e-05</td>\n",
       "      <td>5.04541e-05</td>\n",
       "      <td>3.91411e-05</td>\n",
       "      <td>3.15028e-05</td>\n",
       "      <td>2.6015e-05</td>\n",
       "      <td>2.19471e-05</td>\n",
       "      <td>1.88304e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0197799</td>\n",
       "      <td>0.0207712</td>\n",
       "      <td>0.0213524</td>\n",
       "      <td>0.0217616</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>0.0223272</td>\n",
       "      <td>0.0225374</td>\n",
       "      <td>0.0227162</td>\n",
       "      <td>0.0228718</td>\n",
       "      <td>0.0230088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>15.5164</td>\n",
       "      <td>24.4675</td>\n",
       "      <td>30.8799</td>\n",
       "      <td>39.0863</td>\n",
       "      <td>50.2598</td>\n",
       "      <td>42.4631</td>\n",
       "      <td>48.1809</td>\n",
       "      <td>48.753</td>\n",
       "      <td>41.4988</td>\n",
       "      <td>41.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 20}</td>\n",
       "      <td>{'C': 30}</td>\n",
       "      <td>{'C': 40}</td>\n",
       "      <td>{'C': 50}</td>\n",
       "      <td>{'C': 60}</td>\n",
       "      <td>{'C': 70}</td>\n",
       "      <td>{'C': 80}</td>\n",
       "      <td>{'C': 90}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.659143</td>\n",
       "      <td>-0.636951</td>\n",
       "      <td>-0.631718</td>\n",
       "      <td>-0.630683</td>\n",
       "      <td>-0.631139</td>\n",
       "      <td>-0.632208</td>\n",
       "      <td>-0.633537</td>\n",
       "      <td>-0.634968</td>\n",
       "      <td>-0.636422</td>\n",
       "      <td>-0.637862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.0907433</td>\n",
       "      <td>-0.0378583</td>\n",
       "      <td>-0.0218276</td>\n",
       "      <td>-0.0145561</td>\n",
       "      <td>-0.0105533</td>\n",
       "      <td>-0.0080798</td>\n",
       "      <td>-0.00642843</td>\n",
       "      <td>-0.00526299</td>\n",
       "      <td>-0.0044053</td>\n",
       "      <td>-0.00375307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.618091</td>\n",
       "      <td>-0.592079</td>\n",
       "      <td>-0.585128</td>\n",
       "      <td>-0.583058</td>\n",
       "      <td>-0.582802</td>\n",
       "      <td>-0.583341</td>\n",
       "      <td>-0.584255</td>\n",
       "      <td>-0.585349</td>\n",
       "      <td>-0.586523</td>\n",
       "      <td>-0.587724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.0911098</td>\n",
       "      <td>-0.0380399</td>\n",
       "      <td>-0.0219438</td>\n",
       "      <td>-0.0146394</td>\n",
       "      <td>-0.0106171</td>\n",
       "      <td>-0.00813071</td>\n",
       "      <td>-0.00647037</td>\n",
       "      <td>-0.00529831</td>\n",
       "      <td>-0.0044356</td>\n",
       "      <td>-0.00377946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.652189</td>\n",
       "      <td>-0.631706</td>\n",
       "      <td>-0.627464</td>\n",
       "      <td>-0.627057</td>\n",
       "      <td>-0.627941</td>\n",
       "      <td>-0.629313</td>\n",
       "      <td>-0.630866</td>\n",
       "      <td>-0.632465</td>\n",
       "      <td>-0.634047</td>\n",
       "      <td>-0.635586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.616502</td>\n",
       "      <td>-0.592571</td>\n",
       "      <td>-0.586041</td>\n",
       "      <td>-0.583953</td>\n",
       "      <td>-0.583526</td>\n",
       "      <td>-0.583832</td>\n",
       "      <td>-0.584493</td>\n",
       "      <td>-0.585328</td>\n",
       "      <td>-0.586248</td>\n",
       "      <td>-0.587201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.0910337</td>\n",
       "      <td>-0.0379847</td>\n",
       "      <td>-0.0219047</td>\n",
       "      <td>-0.0146102</td>\n",
       "      <td>-0.0105942</td>\n",
       "      <td>-0.00811217</td>\n",
       "      <td>-0.00645496</td>\n",
       "      <td>-0.00528525</td>\n",
       "      <td>-0.00442435</td>\n",
       "      <td>-0.00376962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.608134</td>\n",
       "      <td>-0.585663</td>\n",
       "      <td>-0.580092</td>\n",
       "      <td>-0.578695</td>\n",
       "      <td>-0.578798</td>\n",
       "      <td>-0.579533</td>\n",
       "      <td>-0.580549</td>\n",
       "      <td>-0.581692</td>\n",
       "      <td>-0.582878</td>\n",
       "      <td>-0.584067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.0911531</td>\n",
       "      <td>-0.038032</td>\n",
       "      <td>-0.0219322</td>\n",
       "      <td>-0.014629</td>\n",
       "      <td>-0.0106081</td>\n",
       "      <td>-0.00812315</td>\n",
       "      <td>-0.00646387</td>\n",
       "      <td>-0.00529272</td>\n",
       "      <td>-0.0044307</td>\n",
       "      <td>-0.00377513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.0905459</td>\n",
       "      <td>-0.0377718</td>\n",
       "      <td>-0.0217793</td>\n",
       "      <td>-0.0145254</td>\n",
       "      <td>-0.010532</td>\n",
       "      <td>-0.00806424</td>\n",
       "      <td>-0.00641656</td>\n",
       "      <td>-0.00525366</td>\n",
       "      <td>-0.00439779</td>\n",
       "      <td>-0.00374692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.091775</td>\n",
       "      <td>-0.0383149</td>\n",
       "      <td>-0.0221003</td>\n",
       "      <td>-0.0147427</td>\n",
       "      <td>-0.0106914</td>\n",
       "      <td>-0.00818723</td>\n",
       "      <td>-0.00651518</td>\n",
       "      <td>-0.00533477</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>-0.00380529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.623688</td>\n",
       "      <td>-0.596725</td>\n",
       "      <td>-0.58898</td>\n",
       "      <td>-0.586264</td>\n",
       "      <td>-0.585469</td>\n",
       "      <td>-0.585548</td>\n",
       "      <td>-0.586062</td>\n",
       "      <td>-0.586803</td>\n",
       "      <td>-0.587661</td>\n",
       "      <td>-0.588578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.0913035</td>\n",
       "      <td>-0.0380843</td>\n",
       "      <td>-0.0219577</td>\n",
       "      <td>-0.0146434</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>-0.00812886</td>\n",
       "      <td>-0.0064677</td>\n",
       "      <td>-0.00529531</td>\n",
       "      <td>-0.0044325</td>\n",
       "      <td>-0.00377635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.0912151</td>\n",
       "      <td>-0.0380907</td>\n",
       "      <td>-0.0219758</td>\n",
       "      <td>-0.0146621</td>\n",
       "      <td>-0.0106342</td>\n",
       "      <td>-0.00814419</td>\n",
       "      <td>-0.00648133</td>\n",
       "      <td>-0.00530747</td>\n",
       "      <td>-0.00444337</td>\n",
       "      <td>-0.00378615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.624518</td>\n",
       "      <td>-0.601095</td>\n",
       "      <td>-0.595045</td>\n",
       "      <td>-0.593371</td>\n",
       "      <td>-0.5933</td>\n",
       "      <td>-0.59392</td>\n",
       "      <td>-0.59486</td>\n",
       "      <td>-0.595947</td>\n",
       "      <td>-0.597094</td>\n",
       "      <td>-0.598256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.657215</td>\n",
       "      <td>-0.634711</td>\n",
       "      <td>-0.629394</td>\n",
       "      <td>-0.628301</td>\n",
       "      <td>-0.628702</td>\n",
       "      <td>-0.629717</td>\n",
       "      <td>-0.630992</td>\n",
       "      <td>-0.63237</td>\n",
       "      <td>-0.633774</td>\n",
       "      <td>-0.635164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00428859</td>\n",
       "      <td>0.00403837</td>\n",
       "      <td>0.0141798</td>\n",
       "      <td>0.0382629</td>\n",
       "      <td>0.0431937</td>\n",
       "      <td>0.0216173</td>\n",
       "      <td>0.0254086</td>\n",
       "      <td>0.0289943</td>\n",
       "      <td>0.0132765</td>\n",
       "      <td>0.0308454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.365779</td>\n",
       "      <td>0.989111</td>\n",
       "      <td>1.24323</td>\n",
       "      <td>2.54593</td>\n",
       "      <td>9.40318</td>\n",
       "      <td>3.62655</td>\n",
       "      <td>7.21056</td>\n",
       "      <td>6.13166</td>\n",
       "      <td>3.6268</td>\n",
       "      <td>6.47077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.090519</td>\n",
       "      <td>-0.0377474</td>\n",
       "      <td>-0.0217612</td>\n",
       "      <td>-0.0145115</td>\n",
       "      <td>-0.0105211</td>\n",
       "      <td>-0.00805529</td>\n",
       "      <td>-0.00640909</td>\n",
       "      <td>-0.0052473</td>\n",
       "      <td>-0.00439229</td>\n",
       "      <td>-0.00374209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.630207</td>\n",
       "      <td>-0.606681</td>\n",
       "      <td>-0.600716</td>\n",
       "      <td>-0.599152</td>\n",
       "      <td>-0.599185</td>\n",
       "      <td>-0.599899</td>\n",
       "      <td>-0.600922</td>\n",
       "      <td>-0.602083</td>\n",
       "      <td>-0.603296</td>\n",
       "      <td>-0.604518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.641383</td>\n",
       "      <td>-0.618133</td>\n",
       "      <td>-0.612173</td>\n",
       "      <td>-0.610561</td>\n",
       "      <td>-0.610535</td>\n",
       "      <td>-0.611188</td>\n",
       "      <td>-0.612151</td>\n",
       "      <td>-0.613254</td>\n",
       "      <td>-0.614413</td>\n",
       "      <td>-0.615584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.0912729</td>\n",
       "      <td>-0.038073</td>\n",
       "      <td>-0.0219527</td>\n",
       "      <td>-0.0146411</td>\n",
       "      <td>-0.0106161</td>\n",
       "      <td>-0.00812871</td>\n",
       "      <td>-0.00646799</td>\n",
       "      <td>-0.00529587</td>\n",
       "      <td>-0.00443321</td>\n",
       "      <td>-0.00377715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.0906993</td>\n",
       "      <td>-0.0378346</td>\n",
       "      <td>-0.0218168</td>\n",
       "      <td>-0.0145513</td>\n",
       "      <td>-0.0105515</td>\n",
       "      <td>-0.00807956</td>\n",
       "      <td>-0.00642905</td>\n",
       "      <td>-0.00526412</td>\n",
       "      <td>-0.0044067</td>\n",
       "      <td>-0.00375463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0538414</td>\n",
       "      <td>0.0561098</td>\n",
       "      <td>0.0677853</td>\n",
       "      <td>0.0873345</td>\n",
       "      <td>0.0917052</td>\n",
       "      <td>0.0741814</td>\n",
       "      <td>0.0801013</td>\n",
       "      <td>0.0751191</td>\n",
       "      <td>0.0676807</td>\n",
       "      <td>0.0675108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            10           20           30          40   \\\n",
       "rank_test_score              10            9            4           1   \n",
       "split3_test_score     -0.601214    -0.577178    -0.571133   -0.569575   \n",
       "std_train_score     0.000378354  0.000168336  0.000100351  6.8438e-05   \n",
       "param_C                      10           20           30          40   \n",
       "std_test_score        0.0197799    0.0207712    0.0213524   0.0217616   \n",
       "mean_fit_time           15.5164      24.4675      30.8799     39.0863   \n",
       "params                {'C': 10}    {'C': 20}    {'C': 30}   {'C': 40}   \n",
       "split9_test_score     -0.659143    -0.636951    -0.631718   -0.630683   \n",
       "split2_train_score   -0.0907433   -0.0378583   -0.0218276  -0.0145561   \n",
       "split4_test_score     -0.618091    -0.592079    -0.585128   -0.583058   \n",
       "split6_train_score   -0.0911098   -0.0380399   -0.0219438  -0.0146394   \n",
       "split5_test_score     -0.652189    -0.631706    -0.627464   -0.627057   \n",
       "split8_test_score     -0.616502    -0.592571    -0.586041   -0.583953   \n",
       "mean_train_score     -0.0910337   -0.0379847   -0.0219047  -0.0146102   \n",
       "split0_test_score     -0.608134    -0.585663    -0.580092   -0.578695   \n",
       "split7_train_score   -0.0911531    -0.038032   -0.0219322   -0.014629   \n",
       "split1_train_score   -0.0905459   -0.0377718   -0.0217793  -0.0145254   \n",
       "split0_train_score    -0.091775   -0.0383149   -0.0221003  -0.0147427   \n",
       "split6_test_score     -0.623688    -0.596725     -0.58898   -0.586264   \n",
       "split3_train_score   -0.0913035   -0.0380843   -0.0219577  -0.0146434   \n",
       "split4_train_score   -0.0912151   -0.0380907   -0.0219758  -0.0146621   \n",
       "split7_test_score     -0.624518    -0.601095    -0.595045   -0.593371   \n",
       "split2_test_score     -0.657215    -0.634711    -0.629394   -0.628301   \n",
       "std_score_time       0.00428859   0.00403837    0.0141798   0.0382629   \n",
       "std_fit_time           0.365779     0.989111      1.24323     2.54593   \n",
       "split9_train_score    -0.090519   -0.0377474   -0.0217612  -0.0145115   \n",
       "mean_test_score       -0.630207    -0.606681    -0.600716   -0.599152   \n",
       "split1_test_score     -0.641383    -0.618133    -0.612173   -0.610561   \n",
       "split8_train_score   -0.0912729    -0.038073   -0.0219527  -0.0146411   \n",
       "split5_train_score   -0.0906993   -0.0378346   -0.0218168  -0.0145513   \n",
       "mean_score_time       0.0538414    0.0561098    0.0677853   0.0873345   \n",
       "\n",
       "                            50           60           70          80   \\\n",
       "rank_test_score               2            3            5           6   \n",
       "split3_test_score     -0.569641    -0.570394    -0.571457   -0.572656   \n",
       "std_train_score     5.04541e-05  3.91411e-05  3.15028e-05  2.6015e-05   \n",
       "param_C                      50           60           70          80   \n",
       "std_test_score         0.022075    0.0223272    0.0225374   0.0227162   \n",
       "mean_fit_time           50.2598      42.4631      48.1809      48.753   \n",
       "params                {'C': 50}    {'C': 60}    {'C': 70}   {'C': 80}   \n",
       "split9_test_score     -0.631139    -0.632208    -0.633537   -0.634968   \n",
       "split2_train_score   -0.0105533   -0.0080798  -0.00642843 -0.00526299   \n",
       "split4_test_score     -0.582802    -0.583341    -0.584255   -0.585349   \n",
       "split6_train_score   -0.0106171  -0.00813071  -0.00647037 -0.00529831   \n",
       "split5_test_score     -0.627941    -0.629313    -0.630866   -0.632465   \n",
       "split8_test_score     -0.583526    -0.583832    -0.584493   -0.585328   \n",
       "mean_train_score     -0.0105942  -0.00811217  -0.00645496 -0.00528525   \n",
       "split0_test_score     -0.578798    -0.579533    -0.580549   -0.581692   \n",
       "split7_train_score   -0.0106081  -0.00812315  -0.00646387 -0.00529272   \n",
       "split1_train_score    -0.010532  -0.00806424  -0.00641656 -0.00525366   \n",
       "split0_train_score   -0.0106914  -0.00818723  -0.00651518 -0.00533477   \n",
       "split6_test_score     -0.585469    -0.585548    -0.586062   -0.586803   \n",
       "split3_train_score    -0.010617  -0.00812886   -0.0064677 -0.00529531   \n",
       "split4_train_score   -0.0106342  -0.00814419  -0.00648133 -0.00530747   \n",
       "split7_test_score       -0.5933     -0.59392     -0.59486   -0.595947   \n",
       "split2_test_score     -0.628702    -0.629717    -0.630992    -0.63237   \n",
       "std_score_time        0.0431937    0.0216173    0.0254086   0.0289943   \n",
       "std_fit_time            9.40318      3.62655      7.21056     6.13166   \n",
       "split9_train_score   -0.0105211  -0.00805529  -0.00640909  -0.0052473   \n",
       "mean_test_score       -0.599185    -0.599899    -0.600922   -0.602083   \n",
       "split1_test_score     -0.610535    -0.611188    -0.612151   -0.613254   \n",
       "split8_train_score   -0.0106161  -0.00812871  -0.00646799 -0.00529587   \n",
       "split5_train_score   -0.0105515  -0.00807956  -0.00642905 -0.00526412   \n",
       "mean_score_time       0.0917052    0.0741814    0.0801013   0.0751191   \n",
       "\n",
       "                            90           100  \n",
       "rank_test_score               7            8  \n",
       "split3_test_score     -0.573905     -0.57516  \n",
       "std_train_score     2.19471e-05  1.88304e-05  \n",
       "param_C                      90          100  \n",
       "std_test_score        0.0228718    0.0230088  \n",
       "mean_fit_time           41.4988       41.353  \n",
       "params                {'C': 90}   {'C': 100}  \n",
       "split9_test_score     -0.636422    -0.637862  \n",
       "split2_train_score   -0.0044053  -0.00375307  \n",
       "split4_test_score     -0.586523    -0.587724  \n",
       "split6_train_score   -0.0044356  -0.00377946  \n",
       "split5_test_score     -0.634047    -0.635586  \n",
       "split8_test_score     -0.586248    -0.587201  \n",
       "mean_train_score    -0.00442435  -0.00376962  \n",
       "split0_test_score     -0.582878    -0.584067  \n",
       "split7_train_score   -0.0044307  -0.00377513  \n",
       "split1_train_score  -0.00439779  -0.00374692  \n",
       "split0_train_score    -0.004466  -0.00380529  \n",
       "split6_test_score     -0.587661    -0.588578  \n",
       "split3_train_score   -0.0044325  -0.00377635  \n",
       "split4_train_score  -0.00444337  -0.00378615  \n",
       "split7_test_score     -0.597094    -0.598256  \n",
       "split2_test_score     -0.633774    -0.635164  \n",
       "std_score_time        0.0132765    0.0308454  \n",
       "std_fit_time             3.6268      6.47077  \n",
       "split9_train_score  -0.00439229  -0.00374209  \n",
       "mean_test_score       -0.603296    -0.604518  \n",
       "split1_test_score     -0.614413    -0.615584  \n",
       "split8_train_score  -0.00443321  -0.00377715  \n",
       "split5_train_score   -0.0044067  -0.00375463  \n",
       "mean_score_time       0.0676807    0.0675108  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = range(10, 101, 10)\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It looks for real, 2-gram has no chance to beat uni-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "Try Ridge multiple regression, it should have similar result as logistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We should make label to numerical type, since it is no longer a classification problem.\n",
    "y_train_int = [int(s) for s in y_train]\n",
    "\n",
    "# We also need another score function, since the prediction is already continious\n",
    "def score_mlr(estimator, x_test, y_test):\n",
    "    \"\"\" Use mean squared error as score for cv.\"\"\"\n",
    "    result = estimator.predict(x_test)\n",
    "\n",
    "    # We want to minimize the error\n",
    "    score = (-1) * np.mean(np.square(result - y_test))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "mlr_model = GridSearchCV(Ridge(), param_grid, scoring=score_mlr, cv=10, n_jobs=2)\n",
    "\n",
    "mlr_model.fit(x_train, y_train_int)\n",
    "\n",
    "dump(mlr_model, open('./config/model{}.pickle'.format('_mlr_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.33876</td>\n",
       "      <td>-1.01547</td>\n",
       "      <td>-0.704769</td>\n",
       "      <td>-0.593375</td>\n",
       "      <td>-0.614216</td>\n",
       "      <td>-0.862613</td>\n",
       "      <td>-1.31602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00248097</td>\n",
       "      <td>0.00239791</td>\n",
       "      <td>0.00250049</td>\n",
       "      <td>0.00293594</td>\n",
       "      <td>0.00349059</td>\n",
       "      <td>0.00514954</td>\n",
       "      <td>0.0103343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.111436</td>\n",
       "      <td>0.0588012</td>\n",
       "      <td>0.0438434</td>\n",
       "      <td>0.0365427</td>\n",
       "      <td>0.0393496</td>\n",
       "      <td>0.0676957</td>\n",
       "      <td>0.103129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>19.8895</td>\n",
       "      <td>11.4697</td>\n",
       "      <td>3.36054</td>\n",
       "      <td>1.28342</td>\n",
       "      <td>0.774843</td>\n",
       "      <td>0.731335</td>\n",
       "      <td>0.646691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>{'alpha': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-1.60715</td>\n",
       "      <td>-1.12001</td>\n",
       "      <td>-0.756447</td>\n",
       "      <td>-0.645174</td>\n",
       "      <td>-0.674778</td>\n",
       "      <td>-0.931913</td>\n",
       "      <td>-1.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.215532</td>\n",
       "      <td>-0.233199</td>\n",
       "      <td>-0.302274</td>\n",
       "      <td>-0.432931</td>\n",
       "      <td>-0.594798</td>\n",
       "      <td>-0.926149</td>\n",
       "      <td>-1.42906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.71516</td>\n",
       "      <td>-1.16813</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.621375</td>\n",
       "      <td>-0.651085</td>\n",
       "      <td>-0.938643</td>\n",
       "      <td>-1.41088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.214748</td>\n",
       "      <td>-0.232194</td>\n",
       "      <td>-0.300111</td>\n",
       "      <td>-0.428918</td>\n",
       "      <td>-0.591186</td>\n",
       "      <td>-0.920214</td>\n",
       "      <td>-1.41159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-1.65858</td>\n",
       "      <td>-1.21034</td>\n",
       "      <td>-0.82388</td>\n",
       "      <td>-0.673496</td>\n",
       "      <td>-0.680594</td>\n",
       "      <td>-0.937385</td>\n",
       "      <td>-1.39924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-1.53047</td>\n",
       "      <td>-1.08612</td>\n",
       "      <td>-0.732506</td>\n",
       "      <td>-0.613667</td>\n",
       "      <td>-0.638789</td>\n",
       "      <td>-0.899641</td>\n",
       "      <td>-1.37785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.217332</td>\n",
       "      <td>-0.234958</td>\n",
       "      <td>-0.303473</td>\n",
       "      <td>-0.433361</td>\n",
       "      <td>-0.596071</td>\n",
       "      <td>-0.929148</td>\n",
       "      <td>-1.4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.76065</td>\n",
       "      <td>-1.19187</td>\n",
       "      <td>-0.721363</td>\n",
       "      <td>-0.586004</td>\n",
       "      <td>-0.61305</td>\n",
       "      <td>-0.873434</td>\n",
       "      <td>-1.32424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.217589</td>\n",
       "      <td>-0.236574</td>\n",
       "      <td>-0.304412</td>\n",
       "      <td>-0.433324</td>\n",
       "      <td>-0.596574</td>\n",
       "      <td>-0.930118</td>\n",
       "      <td>-1.43066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.214238</td>\n",
       "      <td>-0.231328</td>\n",
       "      <td>-0.29957</td>\n",
       "      <td>-0.429046</td>\n",
       "      <td>-0.590448</td>\n",
       "      <td>-0.921199</td>\n",
       "      <td>-1.41847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.219756</td>\n",
       "      <td>-0.237508</td>\n",
       "      <td>-0.306831</td>\n",
       "      <td>-0.438146</td>\n",
       "      <td>-0.601631</td>\n",
       "      <td>-0.935803</td>\n",
       "      <td>-1.44456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-1.69735</td>\n",
       "      <td>-1.20123</td>\n",
       "      <td>-0.834153</td>\n",
       "      <td>-0.699189</td>\n",
       "      <td>-0.731883</td>\n",
       "      <td>-1.08632</td>\n",
       "      <td>-1.65141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.222585</td>\n",
       "      <td>-0.238743</td>\n",
       "      <td>-0.305396</td>\n",
       "      <td>-0.43605</td>\n",
       "      <td>-0.600267</td>\n",
       "      <td>-0.936145</td>\n",
       "      <td>-1.44567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.218274</td>\n",
       "      <td>-0.236386</td>\n",
       "      <td>-0.306354</td>\n",
       "      <td>-0.436107</td>\n",
       "      <td>-0.598532</td>\n",
       "      <td>-0.930567</td>\n",
       "      <td>-1.43523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-1.61491</td>\n",
       "      <td>-1.12763</td>\n",
       "      <td>-0.780354</td>\n",
       "      <td>-0.647778</td>\n",
       "      <td>-0.663101</td>\n",
       "      <td>-0.955131</td>\n",
       "      <td>-1.46644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.63272</td>\n",
       "      <td>-1.1656</td>\n",
       "      <td>-0.772622</td>\n",
       "      <td>-0.645922</td>\n",
       "      <td>-0.684712</td>\n",
       "      <td>-0.983084</td>\n",
       "      <td>-1.46976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000703427</td>\n",
       "      <td>0.000126935</td>\n",
       "      <td>0.000413248</td>\n",
       "      <td>0.000498007</td>\n",
       "      <td>0.00122809</td>\n",
       "      <td>0.00035615</td>\n",
       "      <td>0.000529985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>3.05438</td>\n",
       "      <td>1.48408</td>\n",
       "      <td>0.513343</td>\n",
       "      <td>0.248405</td>\n",
       "      <td>0.122001</td>\n",
       "      <td>0.0553725</td>\n",
       "      <td>0.0701959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.21833</td>\n",
       "      <td>-0.23602</td>\n",
       "      <td>-0.304794</td>\n",
       "      <td>-0.433897</td>\n",
       "      <td>-0.595269</td>\n",
       "      <td>-0.929039</td>\n",
       "      <td>-1.43769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.61502</td>\n",
       "      <td>-1.14857</td>\n",
       "      <td>-0.769593</td>\n",
       "      <td>-0.641599</td>\n",
       "      <td>-0.66822</td>\n",
       "      <td>-0.951562</td>\n",
       "      <td>-1.43902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.59439</td>\n",
       "      <td>-1.19926</td>\n",
       "      <td>-0.826365</td>\n",
       "      <td>-0.690011</td>\n",
       "      <td>-0.729991</td>\n",
       "      <td>-1.04745</td>\n",
       "      <td>-1.58839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.21751</td>\n",
       "      <td>-0.235289</td>\n",
       "      <td>-0.304332</td>\n",
       "      <td>-0.434661</td>\n",
       "      <td>-0.598156</td>\n",
       "      <td>-0.933264</td>\n",
       "      <td>-1.43971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.214762</td>\n",
       "      <td>-0.232335</td>\n",
       "      <td>-0.300661</td>\n",
       "      <td>-0.43053</td>\n",
       "      <td>-0.59385</td>\n",
       "      <td>-0.928975</td>\n",
       "      <td>-1.43634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00134449</td>\n",
       "      <td>0.00101261</td>\n",
       "      <td>0.0012038</td>\n",
       "      <td>0.00129611</td>\n",
       "      <td>0.00139825</td>\n",
       "      <td>0.00105462</td>\n",
       "      <td>0.00123649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.001            0.010           0.100     \\\n",
       "rank_test_score                    7                5               3   \n",
       "split3_test_score           -1.33876         -1.01547       -0.704769   \n",
       "std_train_score           0.00248097       0.00239791      0.00250049   \n",
       "std_test_score              0.111436        0.0588012       0.0438434   \n",
       "param_alpha                    0.001             0.01             0.1   \n",
       "mean_fit_time                19.8895          11.4697         3.36054   \n",
       "params              {'alpha': 0.001}  {'alpha': 0.01}  {'alpha': 0.1}   \n",
       "split9_test_score           -1.60715         -1.12001       -0.756447   \n",
       "split2_train_score         -0.215532        -0.233199       -0.302274   \n",
       "split4_test_score           -1.71516         -1.16813       -0.743469   \n",
       "split6_train_score         -0.214748        -0.232194       -0.300111   \n",
       "split5_test_score           -1.65858         -1.21034        -0.82388   \n",
       "split8_test_score           -1.53047         -1.08612       -0.732506   \n",
       "mean_train_score           -0.217332        -0.234958       -0.303473   \n",
       "split0_test_score           -1.76065         -1.19187       -0.721363   \n",
       "split7_train_score         -0.217589        -0.236574       -0.304412   \n",
       "split1_train_score         -0.214238        -0.231328        -0.29957   \n",
       "split0_train_score         -0.219756        -0.237508       -0.306831   \n",
       "split6_test_score           -1.69735         -1.20123       -0.834153   \n",
       "split3_train_score         -0.222585        -0.238743       -0.305396   \n",
       "split4_train_score         -0.218274        -0.236386       -0.306354   \n",
       "split7_test_score           -1.61491         -1.12763       -0.780354   \n",
       "split2_test_score           -1.63272          -1.1656       -0.772622   \n",
       "std_score_time           0.000703427      0.000126935     0.000413248   \n",
       "std_fit_time                 3.05438          1.48408        0.513343   \n",
       "split9_train_score          -0.21833         -0.23602       -0.304794   \n",
       "mean_test_score             -1.61502         -1.14857       -0.769593   \n",
       "split1_test_score           -1.59439         -1.19926       -0.826365   \n",
       "split8_train_score          -0.21751        -0.235289       -0.304332   \n",
       "split5_train_score         -0.214762        -0.232335       -0.300661   \n",
       "mean_score_time           0.00134449       0.00101261       0.0012038   \n",
       "\n",
       "                        1.000          10.000          100.000   \\\n",
       "rank_test_score                1              2               4   \n",
       "split3_test_score      -0.593375      -0.614216       -0.862613   \n",
       "std_train_score       0.00293594     0.00349059      0.00514954   \n",
       "std_test_score         0.0365427      0.0393496       0.0676957   \n",
       "param_alpha                    1             10             100   \n",
       "mean_fit_time            1.28342       0.774843        0.731335   \n",
       "params              {'alpha': 1}  {'alpha': 10}  {'alpha': 100}   \n",
       "split9_test_score      -0.645174      -0.674778       -0.931913   \n",
       "split2_train_score     -0.432931      -0.594798       -0.926149   \n",
       "split4_test_score      -0.621375      -0.651085       -0.938643   \n",
       "split6_train_score     -0.428918      -0.591186       -0.920214   \n",
       "split5_test_score      -0.673496      -0.680594       -0.937385   \n",
       "split8_test_score      -0.613667      -0.638789       -0.899641   \n",
       "mean_train_score       -0.433361      -0.596071       -0.929148   \n",
       "split0_test_score      -0.586004       -0.61305       -0.873434   \n",
       "split7_train_score     -0.433324      -0.596574       -0.930118   \n",
       "split1_train_score     -0.429046      -0.590448       -0.921199   \n",
       "split0_train_score     -0.438146      -0.601631       -0.935803   \n",
       "split6_test_score      -0.699189      -0.731883        -1.08632   \n",
       "split3_train_score      -0.43605      -0.600267       -0.936145   \n",
       "split4_train_score     -0.436107      -0.598532       -0.930567   \n",
       "split7_test_score      -0.647778      -0.663101       -0.955131   \n",
       "split2_test_score      -0.645922      -0.684712       -0.983084   \n",
       "std_score_time       0.000498007     0.00122809      0.00035615   \n",
       "std_fit_time            0.248405       0.122001       0.0553725   \n",
       "split9_train_score     -0.433897      -0.595269       -0.929039   \n",
       "mean_test_score        -0.641599       -0.66822       -0.951562   \n",
       "split1_test_score      -0.690011      -0.729991        -1.04745   \n",
       "split8_train_score     -0.434661      -0.598156       -0.933264   \n",
       "split5_train_score      -0.43053       -0.59385       -0.928975   \n",
       "mean_score_time       0.00129611     0.00139825      0.00105462   \n",
       "\n",
       "                           1000.000  \n",
       "rank_test_score                   6  \n",
       "split3_test_score          -1.31602  \n",
       "std_train_score           0.0103343  \n",
       "std_test_score             0.103129  \n",
       "param_alpha                    1000  \n",
       "mean_fit_time              0.646691  \n",
       "params              {'alpha': 1000}  \n",
       "split9_test_score            -1.386  \n",
       "split2_train_score         -1.42906  \n",
       "split4_test_score          -1.41088  \n",
       "split6_train_score         -1.41159  \n",
       "split5_test_score          -1.39924  \n",
       "split8_test_score          -1.37785  \n",
       "mean_train_score            -1.4329  \n",
       "split0_test_score          -1.32424  \n",
       "split7_train_score         -1.43066  \n",
       "split1_train_score         -1.41847  \n",
       "split0_train_score         -1.44456  \n",
       "split6_test_score          -1.65141  \n",
       "split3_train_score         -1.44567  \n",
       "split4_train_score         -1.43523  \n",
       "split7_test_score          -1.46644  \n",
       "split2_test_score          -1.46976  \n",
       "std_score_time          0.000529985  \n",
       "std_fit_time              0.0701959  \n",
       "split9_train_score         -1.43769  \n",
       "mean_test_score            -1.43902  \n",
       "split1_test_score          -1.58839  \n",
       "split8_train_score         -1.43971  \n",
       "split5_train_score         -1.43634  \n",
       "mean_score_time          0.00123649  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_mlr = pd.DataFrame.from_dict(mlr_model.cv_results_, orient='index')\n",
    "cv_result_mlr.columns = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_result_mlr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Result is not good.\n",
    "\n",
    "---\n",
    "\n",
    "Let's see if using Lasso for logistic makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JayWong/Programs/python_program/stat333_project2/lib/python3.5/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1', dual=False),\n",
    "                          param_grid, scoring=score, cv=10, n_jobs=2)\n",
    "\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_lasso_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.64475</td>\n",
       "      <td>-1.56519</td>\n",
       "      <td>-0.866995</td>\n",
       "      <td>-0.536916</td>\n",
       "      <td>-0.608402</td>\n",
       "      <td>-0.934373</td>\n",
       "      <td>-1.15862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>6.86732e-05</td>\n",
       "      <td>0.00186462</td>\n",
       "      <td>0.0025427</td>\n",
       "      <td>0.00275322</td>\n",
       "      <td>0.00134815</td>\n",
       "      <td>0.000924955</td>\n",
       "      <td>0.000869635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000545968</td>\n",
       "      <td>0.00539667</td>\n",
       "      <td>0.0187534</td>\n",
       "      <td>0.0229495</td>\n",
       "      <td>0.0324003</td>\n",
       "      <td>0.0487166</td>\n",
       "      <td>0.0541151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.795065</td>\n",
       "      <td>1.23988</td>\n",
       "      <td>2.65692</td>\n",
       "      <td>5.07088</td>\n",
       "      <td>14.3769</td>\n",
       "      <td>36.0649</td>\n",
       "      <td>76.3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>{'C': 1000}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-1.64347</td>\n",
       "      <td>-1.57142</td>\n",
       "      <td>-0.908074</td>\n",
       "      <td>-0.59889</td>\n",
       "      <td>-0.654409</td>\n",
       "      <td>-0.927198</td>\n",
       "      <td>-1.12349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.6442</td>\n",
       "      <td>-1.56784</td>\n",
       "      <td>-0.888253</td>\n",
       "      <td>-0.520704</td>\n",
       "      <td>-0.196459</td>\n",
       "      <td>-0.050127</td>\n",
       "      <td>-0.0252982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.6445</td>\n",
       "      <td>-1.5758</td>\n",
       "      <td>-0.912467</td>\n",
       "      <td>-0.583474</td>\n",
       "      <td>-0.645644</td>\n",
       "      <td>-0.98101</td>\n",
       "      <td>-1.21354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-1.6442</td>\n",
       "      <td>-1.56416</td>\n",
       "      <td>-0.889607</td>\n",
       "      <td>-0.523431</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>-0.0493632</td>\n",
       "      <td>-0.0247034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-1.6445</td>\n",
       "      <td>-1.56708</td>\n",
       "      <td>-0.904511</td>\n",
       "      <td>-0.606581</td>\n",
       "      <td>-0.716668</td>\n",
       "      <td>-1.07594</td>\n",
       "      <td>-1.29732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-1.64347</td>\n",
       "      <td>-1.55971</td>\n",
       "      <td>-0.86925</td>\n",
       "      <td>-0.561325</td>\n",
       "      <td>-0.614235</td>\n",
       "      <td>-0.91999</td>\n",
       "      <td>-1.14663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.64427</td>\n",
       "      <td>-1.56785</td>\n",
       "      <td>-0.891707</td>\n",
       "      <td>-0.524119</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.0500488</td>\n",
       "      <td>-0.0252983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.64443</td>\n",
       "      <td>-1.56644</td>\n",
       "      <td>-0.889495</td>\n",
       "      <td>-0.560882</td>\n",
       "      <td>-0.61829</td>\n",
       "      <td>-0.976123</td>\n",
       "      <td>-1.17669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-1.64437</td>\n",
       "      <td>-1.57018</td>\n",
       "      <td>-0.891465</td>\n",
       "      <td>-0.525023</td>\n",
       "      <td>-0.198027</td>\n",
       "      <td>-0.0487789</td>\n",
       "      <td>-0.0246759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.64425</td>\n",
       "      <td>-1.56962</td>\n",
       "      <td>-0.889661</td>\n",
       "      <td>-0.522836</td>\n",
       "      <td>-0.197273</td>\n",
       "      <td>-0.0495616</td>\n",
       "      <td>-0.0252144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.64425</td>\n",
       "      <td>-1.56745</td>\n",
       "      <td>-0.893129</td>\n",
       "      <td>-0.528302</td>\n",
       "      <td>-0.200873</td>\n",
       "      <td>-0.0507917</td>\n",
       "      <td>-0.0254879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-1.64485</td>\n",
       "      <td>-1.57847</td>\n",
       "      <td>-0.912348</td>\n",
       "      <td>-0.584076</td>\n",
       "      <td>-0.682012</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>-1.18686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.6442</td>\n",
       "      <td>-1.56834</td>\n",
       "      <td>-0.896847</td>\n",
       "      <td>-0.528454</td>\n",
       "      <td>-0.198864</td>\n",
       "      <td>-0.0503331</td>\n",
       "      <td>-0.0252584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.64424</td>\n",
       "      <td>-1.5648</td>\n",
       "      <td>-0.892318</td>\n",
       "      <td>-0.523323</td>\n",
       "      <td>-0.198214</td>\n",
       "      <td>-0.0521008</td>\n",
       "      <td>-0.0273115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-1.64347</td>\n",
       "      <td>-1.56486</td>\n",
       "      <td>-0.885758</td>\n",
       "      <td>-0.557879</td>\n",
       "      <td>-0.629508</td>\n",
       "      <td>-0.961697</td>\n",
       "      <td>-1.14653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.64484</td>\n",
       "      <td>-1.5678</td>\n",
       "      <td>-0.928705</td>\n",
       "      <td>-0.61091</td>\n",
       "      <td>-0.669374</td>\n",
       "      <td>-0.984945</td>\n",
       "      <td>-1.19424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00401465</td>\n",
       "      <td>0.00769042</td>\n",
       "      <td>0.00788243</td>\n",
       "      <td>0.00204645</td>\n",
       "      <td>0.00152791</td>\n",
       "      <td>0.0034956</td>\n",
       "      <td>0.00528708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0929316</td>\n",
       "      <td>0.253804</td>\n",
       "      <td>0.737692</td>\n",
       "      <td>0.17084</td>\n",
       "      <td>0.327302</td>\n",
       "      <td>1.50852</td>\n",
       "      <td>8.70947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-1.64437</td>\n",
       "      <td>-1.56841</td>\n",
       "      <td>-0.889187</td>\n",
       "      <td>-0.521114</td>\n",
       "      <td>-0.19829</td>\n",
       "      <td>-0.0502309</td>\n",
       "      <td>-0.0260142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.64427</td>\n",
       "      <td>-1.56804</td>\n",
       "      <td>-0.897795</td>\n",
       "      <td>-0.579371</td>\n",
       "      <td>-0.650197</td>\n",
       "      <td>-0.980184</td>\n",
       "      <td>-1.19228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.64443</td>\n",
       "      <td>-1.56361</td>\n",
       "      <td>-0.900328</td>\n",
       "      <td>-0.592762</td>\n",
       "      <td>-0.663422</td>\n",
       "      <td>-1.0552</td>\n",
       "      <td>-1.27877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-1.64437</td>\n",
       "      <td>-1.56937</td>\n",
       "      <td>-0.894683</td>\n",
       "      <td>-0.526763</td>\n",
       "      <td>-0.198903</td>\n",
       "      <td>-0.0502901</td>\n",
       "      <td>-0.0252042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-1.64424</td>\n",
       "      <td>-1.56838</td>\n",
       "      <td>-0.891916</td>\n",
       "      <td>-0.521245</td>\n",
       "      <td>-0.195801</td>\n",
       "      <td>-0.0489111</td>\n",
       "      <td>-0.0238143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0263407</td>\n",
       "      <td>0.0247047</td>\n",
       "      <td>0.0197162</td>\n",
       "      <td>0.0186441</td>\n",
       "      <td>0.0200111</td>\n",
       "      <td>0.0235941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0.001        0.010       0.100       1.000     \\\n",
       "rank_test_score                7            6           3           1   \n",
       "split3_test_score       -1.64475     -1.56519   -0.866995   -0.536916   \n",
       "std_train_score      6.86732e-05   0.00186462   0.0025427  0.00275322   \n",
       "param_C                    0.001         0.01         0.1           1   \n",
       "std_test_score       0.000545968   0.00539667   0.0187534   0.0229495   \n",
       "mean_fit_time           0.795065      1.23988     2.65692     5.07088   \n",
       "params              {'C': 0.001}  {'C': 0.01}  {'C': 0.1}    {'C': 1}   \n",
       "split9_test_score       -1.64347     -1.57142   -0.908074    -0.59889   \n",
       "split2_train_score       -1.6442     -1.56784   -0.888253   -0.520704   \n",
       "split4_test_score        -1.6445      -1.5758   -0.912467   -0.583474   \n",
       "split6_train_score       -1.6442     -1.56416   -0.889607   -0.523431   \n",
       "split5_test_score        -1.6445     -1.56708   -0.904511   -0.606581   \n",
       "split8_test_score       -1.64347     -1.55971    -0.86925   -0.561325   \n",
       "mean_train_score        -1.64427     -1.56785   -0.891707   -0.524119   \n",
       "split0_test_score       -1.64443     -1.56644   -0.889495   -0.560882   \n",
       "split7_train_score      -1.64437     -1.57018   -0.891465   -0.525023   \n",
       "split1_train_score      -1.64425     -1.56962   -0.889661   -0.522836   \n",
       "split0_train_score      -1.64425     -1.56745   -0.893129   -0.528302   \n",
       "split6_test_score       -1.64485     -1.57847   -0.912348   -0.584076   \n",
       "split3_train_score       -1.6442     -1.56834   -0.896847   -0.528454   \n",
       "split4_train_score      -1.64424      -1.5648   -0.892318   -0.523323   \n",
       "split7_test_score       -1.64347     -1.56486   -0.885758   -0.557879   \n",
       "split2_test_score       -1.64484      -1.5678   -0.928705    -0.61091   \n",
       "std_score_time        0.00401465   0.00769042  0.00788243  0.00204645   \n",
       "std_fit_time           0.0929316     0.253804    0.737692     0.17084   \n",
       "split9_train_score      -1.64437     -1.56841   -0.889187   -0.521114   \n",
       "mean_test_score         -1.64427     -1.56804   -0.897795   -0.579371   \n",
       "split1_test_score       -1.64443     -1.56361   -0.900328   -0.592762   \n",
       "split8_train_score      -1.64437     -1.56937   -0.894683   -0.526763   \n",
       "split5_train_score      -1.64424     -1.56838   -0.891916   -0.521245   \n",
       "mean_score_time         0.020833    0.0263407   0.0247047   0.0197162   \n",
       "\n",
       "                      10.000       100.000      1000.000  \n",
       "rank_test_score              2            4            5  \n",
       "split3_test_score    -0.608402    -0.934373     -1.15862  \n",
       "std_train_score     0.00134815  0.000924955  0.000869635  \n",
       "param_C                     10          100         1000  \n",
       "std_test_score       0.0324003    0.0487166    0.0541151  \n",
       "mean_fit_time          14.3769      36.0649      76.3136  \n",
       "params               {'C': 10}   {'C': 100}  {'C': 1000}  \n",
       "split9_test_score    -0.654409    -0.927198     -1.12349  \n",
       "split2_train_score   -0.196459    -0.050127   -0.0252982  \n",
       "split4_test_score    -0.645644     -0.98101     -1.21354  \n",
       "split6_train_score   -0.197295   -0.0493632   -0.0247034  \n",
       "split5_test_score    -0.716668     -1.07594     -1.29732  \n",
       "split8_test_score    -0.614235     -0.91999     -1.14663  \n",
       "mean_train_score        -0.198   -0.0500488   -0.0252983  \n",
       "split0_test_score     -0.61829    -0.976123     -1.17669  \n",
       "split7_train_score   -0.198027   -0.0487789   -0.0246759  \n",
       "split1_train_score   -0.197273   -0.0495616   -0.0252144  \n",
       "split0_train_score   -0.200873   -0.0507917   -0.0254879  \n",
       "split6_test_score    -0.682012    -0.985252     -1.18686  \n",
       "split3_train_score   -0.198864   -0.0503331   -0.0252584  \n",
       "split4_train_score   -0.198214   -0.0521008   -0.0273115  \n",
       "split7_test_score    -0.629508    -0.961697     -1.14653  \n",
       "split2_test_score    -0.669374    -0.984945     -1.19424  \n",
       "std_score_time      0.00152791    0.0034956   0.00528708  \n",
       "std_fit_time          0.327302      1.50852      8.70947  \n",
       "split9_train_score    -0.19829   -0.0502309   -0.0260142  \n",
       "mean_test_score      -0.650197    -0.980184     -1.19228  \n",
       "split1_test_score    -0.663422      -1.0552     -1.27877  \n",
       "split8_train_score   -0.198903   -0.0502901   -0.0252042  \n",
       "split5_train_score   -0.195801   -0.0489111   -0.0238143  \n",
       "mean_score_time      0.0186441    0.0200111    0.0235941  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It tooks longer time to train, compared to Ridge. Lets do more tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': range(1,6)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1', dual=True),\n",
    "                          param_grid, scoring=score, cv=10)\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_lasso_1-6'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.536911</td>\n",
       "      <td>-0.513766</td>\n",
       "      <td>-0.517652</td>\n",
       "      <td>-0.527231</td>\n",
       "      <td>-0.539552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00275375</td>\n",
       "      <td>0.00224318</td>\n",
       "      <td>0.00187899</td>\n",
       "      <td>0.00167299</td>\n",
       "      <td>0.00167686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0229509</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.0250274</td>\n",
       "      <td>0.02691</td>\n",
       "      <td>0.0280847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>5.11507</td>\n",
       "      <td>6.85693</td>\n",
       "      <td>8.4079</td>\n",
       "      <td>9.42838</td>\n",
       "      <td>9.87513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 2}</td>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>{'C': 4}</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.598892</td>\n",
       "      <td>-0.577002</td>\n",
       "      <td>-0.580612</td>\n",
       "      <td>-0.586538</td>\n",
       "      <td>-0.593931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.520705</td>\n",
       "      <td>-0.441204</td>\n",
       "      <td>-0.38603</td>\n",
       "      <td>-0.340178</td>\n",
       "      <td>-0.302664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.583484</td>\n",
       "      <td>-0.555803</td>\n",
       "      <td>-0.554015</td>\n",
       "      <td>-0.560513</td>\n",
       "      <td>-0.572735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.523432</td>\n",
       "      <td>-0.443528</td>\n",
       "      <td>-0.387511</td>\n",
       "      <td>-0.341721</td>\n",
       "      <td>-0.3038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.606582</td>\n",
       "      <td>-0.583147</td>\n",
       "      <td>-0.59191</td>\n",
       "      <td>-0.609369</td>\n",
       "      <td>-0.627671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.561317</td>\n",
       "      <td>-0.532625</td>\n",
       "      <td>-0.53154</td>\n",
       "      <td>-0.537918</td>\n",
       "      <td>-0.549024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.524119</td>\n",
       "      <td>-0.444819</td>\n",
       "      <td>-0.388563</td>\n",
       "      <td>-0.342462</td>\n",
       "      <td>-0.304744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.560885</td>\n",
       "      <td>-0.532302</td>\n",
       "      <td>-0.5316</td>\n",
       "      <td>-0.539214</td>\n",
       "      <td>-0.550731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.525024</td>\n",
       "      <td>-0.444875</td>\n",
       "      <td>-0.387885</td>\n",
       "      <td>-0.341774</td>\n",
       "      <td>-0.304007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.522834</td>\n",
       "      <td>-0.444663</td>\n",
       "      <td>-0.3881</td>\n",
       "      <td>-0.34164</td>\n",
       "      <td>-0.304008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.528304</td>\n",
       "      <td>-0.44884</td>\n",
       "      <td>-0.392322</td>\n",
       "      <td>-0.345727</td>\n",
       "      <td>-0.308139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.584076</td>\n",
       "      <td>-0.566341</td>\n",
       "      <td>-0.574574</td>\n",
       "      <td>-0.588196</td>\n",
       "      <td>-0.603283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.528454</td>\n",
       "      <td>-0.447958</td>\n",
       "      <td>-0.391089</td>\n",
       "      <td>-0.344425</td>\n",
       "      <td>-0.306454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.523323</td>\n",
       "      <td>-0.444507</td>\n",
       "      <td>-0.3887</td>\n",
       "      <td>-0.342797</td>\n",
       "      <td>-0.305083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.557881</td>\n",
       "      <td>-0.538371</td>\n",
       "      <td>-0.542322</td>\n",
       "      <td>-0.551365</td>\n",
       "      <td>-0.562907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.610911</td>\n",
       "      <td>-0.587793</td>\n",
       "      <td>-0.589476</td>\n",
       "      <td>-0.599075</td>\n",
       "      <td>-0.610835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00383132</td>\n",
       "      <td>0.00467636</td>\n",
       "      <td>0.00188145</td>\n",
       "      <td>0.00261203</td>\n",
       "      <td>0.00156883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.363755</td>\n",
       "      <td>0.443907</td>\n",
       "      <td>0.610878</td>\n",
       "      <td>1.16494</td>\n",
       "      <td>0.220092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.521114</td>\n",
       "      <td>-0.442962</td>\n",
       "      <td>-0.387558</td>\n",
       "      <td>-0.342066</td>\n",
       "      <td>-0.304631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.579371</td>\n",
       "      <td>-0.555066</td>\n",
       "      <td>-0.557878</td>\n",
       "      <td>-0.567665</td>\n",
       "      <td>-0.580211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.59276</td>\n",
       "      <td>-0.563512</td>\n",
       "      <td>-0.565081</td>\n",
       "      <td>-0.577227</td>\n",
       "      <td>-0.591439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.526763</td>\n",
       "      <td>-0.446559</td>\n",
       "      <td>-0.389853</td>\n",
       "      <td>-0.343891</td>\n",
       "      <td>-0.306185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.521242</td>\n",
       "      <td>-0.443096</td>\n",
       "      <td>-0.386586</td>\n",
       "      <td>-0.340401</td>\n",
       "      <td>-0.302472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.019793</td>\n",
       "      <td>0.0195214</td>\n",
       "      <td>0.0193869</td>\n",
       "      <td>0.0200351</td>\n",
       "      <td>0.0184656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1           2           3           4           5\n",
       "rank_test_score              4           1           2           3           5\n",
       "split3_test_score    -0.536911   -0.513766   -0.517652   -0.527231   -0.539552\n",
       "std_train_score     0.00275375  0.00224318  0.00187899  0.00167299  0.00167686\n",
       "param_C                      1           2           3           4           5\n",
       "std_test_score       0.0229509    0.023551   0.0250274     0.02691   0.0280847\n",
       "mean_fit_time          5.11507     6.85693      8.4079     9.42838     9.87513\n",
       "params                {'C': 1}    {'C': 2}    {'C': 3}    {'C': 4}    {'C': 5}\n",
       "split9_test_score    -0.598892   -0.577002   -0.580612   -0.586538   -0.593931\n",
       "split2_train_score   -0.520705   -0.441204    -0.38603   -0.340178   -0.302664\n",
       "split4_test_score    -0.583484   -0.555803   -0.554015   -0.560513   -0.572735\n",
       "split6_train_score   -0.523432   -0.443528   -0.387511   -0.341721     -0.3038\n",
       "split5_test_score    -0.606582   -0.583147    -0.59191   -0.609369   -0.627671\n",
       "split8_test_score    -0.561317   -0.532625    -0.53154   -0.537918   -0.549024\n",
       "mean_train_score     -0.524119   -0.444819   -0.388563   -0.342462   -0.304744\n",
       "split0_test_score    -0.560885   -0.532302     -0.5316   -0.539214   -0.550731\n",
       "split7_train_score   -0.525024   -0.444875   -0.387885   -0.341774   -0.304007\n",
       "split1_train_score   -0.522834   -0.444663     -0.3881    -0.34164   -0.304008\n",
       "split0_train_score   -0.528304    -0.44884   -0.392322   -0.345727   -0.308139\n",
       "split6_test_score    -0.584076   -0.566341   -0.574574   -0.588196   -0.603283\n",
       "split3_train_score   -0.528454   -0.447958   -0.391089   -0.344425   -0.306454\n",
       "split4_train_score   -0.523323   -0.444507     -0.3887   -0.342797   -0.305083\n",
       "split7_test_score    -0.557881   -0.538371   -0.542322   -0.551365   -0.562907\n",
       "split2_test_score    -0.610911   -0.587793   -0.589476   -0.599075   -0.610835\n",
       "std_score_time      0.00383132  0.00467636  0.00188145  0.00261203  0.00156883\n",
       "std_fit_time          0.363755    0.443907    0.610878     1.16494    0.220092\n",
       "split9_train_score   -0.521114   -0.442962   -0.387558   -0.342066   -0.304631\n",
       "mean_test_score      -0.579371   -0.555066   -0.557878   -0.567665   -0.580211\n",
       "split1_test_score     -0.59276   -0.563512   -0.565081   -0.577227   -0.591439\n",
       "split8_train_score   -0.526763   -0.446559   -0.389853   -0.343891   -0.306185\n",
       "split5_train_score   -0.521242   -0.443096   -0.386586   -0.340401   -0.302472\n",
       "mean_score_time       0.019793   0.0195214   0.0193869   0.0200351   0.0184656"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = range(1,6)\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It gives pretty similar results as ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems using mix of unigram and 2-gram worthes trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 1102302).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat_12, x_train_12 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_12_gram.pickle', \n",
    "                                      matrix='../../static/tf_matrix_12_gram.pickle', re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_12 = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': range(1,6)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1', dual=False),\n",
    "                          param_grid, scoring=score, cv=10, n_jobs=2)\n",
    "\n",
    "better_model.fit(x_train_12, y_train_12)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_lasso_12g_1-6'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 1102302).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.56439</td>\n",
       "      <td>-0.498354</td>\n",
       "      <td>-0.475051</td>\n",
       "      <td>-0.4704</td>\n",
       "      <td>-0.473764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00290893</td>\n",
       "      <td>0.00262595</td>\n",
       "      <td>0.00199585</td>\n",
       "      <td>0.00161875</td>\n",
       "      <td>0.00121604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0216182</td>\n",
       "      <td>0.0231702</td>\n",
       "      <td>0.0230523</td>\n",
       "      <td>0.0227805</td>\n",
       "      <td>0.0226089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>26.9464</td>\n",
       "      <td>28.5363</td>\n",
       "      <td>31.7408</td>\n",
       "      <td>29.3357</td>\n",
       "      <td>31.7178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 2}</td>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>{'C': 4}</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.628982</td>\n",
       "      <td>-0.563537</td>\n",
       "      <td>-0.541856</td>\n",
       "      <td>-0.53482</td>\n",
       "      <td>-0.535049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.573579</td>\n",
       "      <td>-0.463864</td>\n",
       "      <td>-0.380284</td>\n",
       "      <td>-0.304122</td>\n",
       "      <td>-0.238092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.615587</td>\n",
       "      <td>-0.54322</td>\n",
       "      <td>-0.519174</td>\n",
       "      <td>-0.515468</td>\n",
       "      <td>-0.518963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.577311</td>\n",
       "      <td>-0.467105</td>\n",
       "      <td>-0.382677</td>\n",
       "      <td>-0.305625</td>\n",
       "      <td>-0.23904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.631176</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.550655</td>\n",
       "      <td>-0.547228</td>\n",
       "      <td>-0.54921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.59494</td>\n",
       "      <td>-0.533321</td>\n",
       "      <td>-0.509981</td>\n",
       "      <td>-0.504278</td>\n",
       "      <td>-0.50519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.577173</td>\n",
       "      <td>-0.466998</td>\n",
       "      <td>-0.382893</td>\n",
       "      <td>-0.306222</td>\n",
       "      <td>-0.239757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.590846</td>\n",
       "      <td>-0.526307</td>\n",
       "      <td>-0.505401</td>\n",
       "      <td>-0.498234</td>\n",
       "      <td>-0.50006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.579046</td>\n",
       "      <td>-0.467176</td>\n",
       "      <td>-0.382296</td>\n",
       "      <td>-0.305486</td>\n",
       "      <td>-0.239225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.574875</td>\n",
       "      <td>-0.465157</td>\n",
       "      <td>-0.382104</td>\n",
       "      <td>-0.305461</td>\n",
       "      <td>-0.239055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.580741</td>\n",
       "      <td>-0.470863</td>\n",
       "      <td>-0.385952</td>\n",
       "      <td>-0.308691</td>\n",
       "      <td>-0.241085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.612934</td>\n",
       "      <td>-0.543042</td>\n",
       "      <td>-0.517633</td>\n",
       "      <td>-0.512057</td>\n",
       "      <td>-0.514665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.582196</td>\n",
       "      <td>-0.472033</td>\n",
       "      <td>-0.386613</td>\n",
       "      <td>-0.308833</td>\n",
       "      <td>-0.241366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.577534</td>\n",
       "      <td>-0.467305</td>\n",
       "      <td>-0.383498</td>\n",
       "      <td>-0.307235</td>\n",
       "      <td>-0.240874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.592841</td>\n",
       "      <td>-0.526122</td>\n",
       "      <td>-0.510373</td>\n",
       "      <td>-0.508325</td>\n",
       "      <td>-0.51087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.638584</td>\n",
       "      <td>-0.577297</td>\n",
       "      <td>-0.554343</td>\n",
       "      <td>-0.547855</td>\n",
       "      <td>-0.551185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.02428</td>\n",
       "      <td>0.00848531</td>\n",
       "      <td>0.0107154</td>\n",
       "      <td>0.00703073</td>\n",
       "      <td>0.00710205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>3.06316</td>\n",
       "      <td>0.630842</td>\n",
       "      <td>2.66922</td>\n",
       "      <td>1.97712</td>\n",
       "      <td>0.850244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.574251</td>\n",
       "      <td>-0.464299</td>\n",
       "      <td>-0.380844</td>\n",
       "      <td>-0.305151</td>\n",
       "      <td>-0.239509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.608764</td>\n",
       "      <td>-0.544342</td>\n",
       "      <td>-0.522278</td>\n",
       "      <td>-0.517042</td>\n",
       "      <td>-0.519295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.617358</td>\n",
       "      <td>-0.560208</td>\n",
       "      <td>-0.538309</td>\n",
       "      <td>-0.531752</td>\n",
       "      <td>-0.533992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.578736</td>\n",
       "      <td>-0.467876</td>\n",
       "      <td>-0.383676</td>\n",
       "      <td>-0.307375</td>\n",
       "      <td>-0.241252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.573455</td>\n",
       "      <td>-0.464301</td>\n",
       "      <td>-0.380988</td>\n",
       "      <td>-0.304247</td>\n",
       "      <td>-0.238075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0543545</td>\n",
       "      <td>0.0396164</td>\n",
       "      <td>0.0408425</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>0.0360585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             1           2           3           4           5\n",
       "rank_test_score              5           4           3           1           2\n",
       "split3_test_score     -0.56439   -0.498354   -0.475051     -0.4704   -0.473764\n",
       "std_train_score     0.00290893  0.00262595  0.00199585  0.00161875  0.00121604\n",
       "param_C                      1           2           3           4           5\n",
       "std_test_score       0.0216182   0.0231702   0.0230523   0.0227805   0.0226089\n",
       "mean_fit_time          26.9464     28.5363     31.7408     29.3357     31.7178\n",
       "params                {'C': 1}    {'C': 2}    {'C': 3}    {'C': 4}    {'C': 5}\n",
       "split9_test_score    -0.628982   -0.563537   -0.541856    -0.53482   -0.535049\n",
       "split2_train_score   -0.573579   -0.463864   -0.380284   -0.304122   -0.238092\n",
       "split4_test_score    -0.615587    -0.54322   -0.519174   -0.515468   -0.518963\n",
       "split6_train_score   -0.577311   -0.467105   -0.382677   -0.305625    -0.23904\n",
       "split5_test_score    -0.631176      -0.572   -0.550655   -0.547228    -0.54921\n",
       "split8_test_score     -0.59494   -0.533321   -0.509981   -0.504278    -0.50519\n",
       "mean_train_score     -0.577173   -0.466998   -0.382893   -0.306222   -0.239757\n",
       "split0_test_score    -0.590846   -0.526307   -0.505401   -0.498234    -0.50006\n",
       "split7_train_score   -0.579046   -0.467176   -0.382296   -0.305486   -0.239225\n",
       "split1_train_score   -0.574875   -0.465157   -0.382104   -0.305461   -0.239055\n",
       "split0_train_score   -0.580741   -0.470863   -0.385952   -0.308691   -0.241085\n",
       "split6_test_score    -0.612934   -0.543042   -0.517633   -0.512057   -0.514665\n",
       "split3_train_score   -0.582196   -0.472033   -0.386613   -0.308833   -0.241366\n",
       "split4_train_score   -0.577534   -0.467305   -0.383498   -0.307235   -0.240874\n",
       "split7_test_score    -0.592841   -0.526122   -0.510373   -0.508325    -0.51087\n",
       "split2_test_score    -0.638584   -0.577297   -0.554343   -0.547855   -0.551185\n",
       "std_score_time         0.02428  0.00848531   0.0107154  0.00703073  0.00710205\n",
       "std_fit_time           3.06316    0.630842     2.66922     1.97712    0.850244\n",
       "split9_train_score   -0.574251   -0.464299   -0.380844   -0.305151   -0.239509\n",
       "mean_test_score      -0.608764   -0.544342   -0.522278   -0.517042   -0.519295\n",
       "split1_test_score    -0.617358   -0.560208   -0.538309   -0.531752   -0.533992\n",
       "split8_train_score   -0.578736   -0.467876   -0.383676   -0.307375   -0.241252\n",
       "split5_train_score   -0.573455   -0.464301   -0.380988   -0.304247   -0.238075\n",
       "mean_score_time      0.0543545   0.0396164   0.0408425    0.036149   0.0360585"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = range(1,6)\n",
    "cv_result_better\n",
    "predict(better_model, all_mat_12, x_train_12.shape[0], './config/prediction_lasso_12g_4.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 23617).\n",
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat, x_train = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector=VECTOR, \n",
    "                                      matrix=MATRIX, re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1)\n",
    "# predict(test_model, all_mat, x_train.shape[0], './config/prediction_lasso_1-6.csv')\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))\n",
    "\n",
    "test_model = load(open('./config/model_lasso_1-6.pickle', 'rb'))\n",
    "predict(test_model, all_mat, x_train.shape[0], \"prediction_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=True),\n",
    "                          param_grid, scoring=score, cv=10)\n",
    "\n",
    "better_model.fit(x_train_12, y_train_12)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_12g_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 1102302).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.66192</td>\n",
       "      <td>-1.58475</td>\n",
       "      <td>-1.53524</td>\n",
       "      <td>-1.28599</td>\n",
       "      <td>-1.1168</td>\n",
       "      <td>-0.631089</td>\n",
       "      <td>-0.468398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00012744</td>\n",
       "      <td>0.000400221</td>\n",
       "      <td>0.00066364</td>\n",
       "      <td>0.00149398</td>\n",
       "      <td>0.00175368</td>\n",
       "      <td>0.00187261</td>\n",
       "      <td>0.000420668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000740404</td>\n",
       "      <td>0.00196227</td>\n",
       "      <td>0.00327081</td>\n",
       "      <td>0.00875086</td>\n",
       "      <td>0.0113472</td>\n",
       "      <td>0.0182597</td>\n",
       "      <td>0.0207703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>2.83087</td>\n",
       "      <td>2.358</td>\n",
       "      <td>2.38209</td>\n",
       "      <td>2.53351</td>\n",
       "      <td>2.66484</td>\n",
       "      <td>3.3849</td>\n",
       "      <td>7.56048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.005}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.05}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-1.6613</td>\n",
       "      <td>-1.58582</td>\n",
       "      <td>-1.53859</td>\n",
       "      <td>-1.30226</td>\n",
       "      <td>-1.14279</td>\n",
       "      <td>-0.686624</td>\n",
       "      <td>-0.527697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.66109</td>\n",
       "      <td>-1.58268</td>\n",
       "      <td>-1.53196</td>\n",
       "      <td>-1.27348</td>\n",
       "      <td>-1.09325</td>\n",
       "      <td>-0.487579</td>\n",
       "      <td>-0.0810096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.66255</td>\n",
       "      <td>-1.58814</td>\n",
       "      <td>-1.54167</td>\n",
       "      <td>-1.30539</td>\n",
       "      <td>-1.14157</td>\n",
       "      <td>-0.659285</td>\n",
       "      <td>-0.499567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-1.66108</td>\n",
       "      <td>-1.58258</td>\n",
       "      <td>-1.5318</td>\n",
       "      <td>-1.27376</td>\n",
       "      <td>-1.09411</td>\n",
       "      <td>-0.489059</td>\n",
       "      <td>-0.0812914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-1.66206</td>\n",
       "      <td>-1.58623</td>\n",
       "      <td>-1.53847</td>\n",
       "      <td>-1.29948</td>\n",
       "      <td>-1.13771</td>\n",
       "      <td>-0.680086</td>\n",
       "      <td>-0.535384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-1.66037</td>\n",
       "      <td>-1.5825</td>\n",
       "      <td>-1.5329</td>\n",
       "      <td>-1.28643</td>\n",
       "      <td>-1.12074</td>\n",
       "      <td>-0.651967</td>\n",
       "      <td>-0.495042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.66126</td>\n",
       "      <td>-1.58321</td>\n",
       "      <td>-1.53284</td>\n",
       "      <td>-1.27576</td>\n",
       "      <td>-1.09596</td>\n",
       "      <td>-0.489657</td>\n",
       "      <td>-0.0813885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.66183</td>\n",
       "      <td>-1.585</td>\n",
       "      <td>-1.53611</td>\n",
       "      <td>-1.29203</td>\n",
       "      <td>-1.12681</td>\n",
       "      <td>-0.647784</td>\n",
       "      <td>-0.48714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-1.66137</td>\n",
       "      <td>-1.5835</td>\n",
       "      <td>-1.5333</td>\n",
       "      <td>-1.27678</td>\n",
       "      <td>-1.09718</td>\n",
       "      <td>-0.490809</td>\n",
       "      <td>-0.0815173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.66128</td>\n",
       "      <td>-1.58335</td>\n",
       "      <td>-1.53306</td>\n",
       "      <td>-1.27567</td>\n",
       "      <td>-1.09517</td>\n",
       "      <td>-0.487596</td>\n",
       "      <td>-0.0810068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.66129</td>\n",
       "      <td>-1.58349</td>\n",
       "      <td>-1.53335</td>\n",
       "      <td>-1.27695</td>\n",
       "      <td>-1.09752</td>\n",
       "      <td>-0.49237</td>\n",
       "      <td>-0.0822044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-1.66292</td>\n",
       "      <td>-1.58907</td>\n",
       "      <td>-1.54341</td>\n",
       "      <td>-1.31035</td>\n",
       "      <td>-1.14745</td>\n",
       "      <td>-0.669984</td>\n",
       "      <td>-0.511071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.66127</td>\n",
       "      <td>-1.58353</td>\n",
       "      <td>-1.5335</td>\n",
       "      <td>-1.27791</td>\n",
       "      <td>-1.09873</td>\n",
       "      <td>-0.492529</td>\n",
       "      <td>-0.0818492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.66112</td>\n",
       "      <td>-1.58274</td>\n",
       "      <td>-1.53209</td>\n",
       "      <td>-1.27453</td>\n",
       "      <td>-1.09506</td>\n",
       "      <td>-0.489909</td>\n",
       "      <td>-0.081511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-1.66124</td>\n",
       "      <td>-1.58438</td>\n",
       "      <td>-1.53565</td>\n",
       "      <td>-1.29092</td>\n",
       "      <td>-1.12446</td>\n",
       "      <td>-0.649585</td>\n",
       "      <td>-0.495276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.66282</td>\n",
       "      <td>-1.58857</td>\n",
       "      <td>-1.54246</td>\n",
       "      <td>-1.31086</td>\n",
       "      <td>-1.15248</td>\n",
       "      <td>-0.690892</td>\n",
       "      <td>-0.533838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00236193</td>\n",
       "      <td>0.00151286</td>\n",
       "      <td>0.00173385</td>\n",
       "      <td>0.000594295</td>\n",
       "      <td>0.0011702</td>\n",
       "      <td>0.00105346</td>\n",
       "      <td>0.000883059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.0404682</td>\n",
       "      <td>0.0998649</td>\n",
       "      <td>0.075873</td>\n",
       "      <td>0.0655879</td>\n",
       "      <td>0.108678</td>\n",
       "      <td>0.133269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-1.66134</td>\n",
       "      <td>-1.58322</td>\n",
       "      <td>-1.53279</td>\n",
       "      <td>-1.27531</td>\n",
       "      <td>-1.09494</td>\n",
       "      <td>-0.487628</td>\n",
       "      <td>-0.0809474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.66188</td>\n",
       "      <td>-1.58598</td>\n",
       "      <td>-1.53814</td>\n",
       "      <td>-1.29787</td>\n",
       "      <td>-1.1343</td>\n",
       "      <td>-0.664043</td>\n",
       "      <td>-0.507148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.66181</td>\n",
       "      <td>-1.58534</td>\n",
       "      <td>-1.5369</td>\n",
       "      <td>-1.29495</td>\n",
       "      <td>-1.13218</td>\n",
       "      <td>-0.673132</td>\n",
       "      <td>-0.51807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-1.66151</td>\n",
       "      <td>-1.58386</td>\n",
       "      <td>-1.53384</td>\n",
       "      <td>-1.27781</td>\n",
       "      <td>-1.09832</td>\n",
       "      <td>-0.491128</td>\n",
       "      <td>-0.0816866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-1.66123</td>\n",
       "      <td>-1.58315</td>\n",
       "      <td>-1.53275</td>\n",
       "      <td>-1.2754</td>\n",
       "      <td>-1.09536</td>\n",
       "      <td>-0.487963</td>\n",
       "      <td>-0.0808612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0279251</td>\n",
       "      <td>0.0276928</td>\n",
       "      <td>0.0273095</td>\n",
       "      <td>0.0273726</td>\n",
       "      <td>0.0281239</td>\n",
       "      <td>0.0275383</td>\n",
       "      <td>0.0272945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0.001         0.005        0.010        0.050   \\\n",
       "rank_test_score                7             6            5            4   \n",
       "split3_test_score       -1.66192      -1.58475     -1.53524     -1.28599   \n",
       "std_train_score       0.00012744   0.000400221   0.00066364   0.00149398   \n",
       "param_C                    0.001         0.005         0.01         0.05   \n",
       "std_test_score       0.000740404    0.00196227   0.00327081   0.00875086   \n",
       "mean_fit_time            2.83087         2.358      2.38209      2.53351   \n",
       "params              {'C': 0.001}  {'C': 0.005}  {'C': 0.01}  {'C': 0.05}   \n",
       "split9_test_score        -1.6613      -1.58582     -1.53859     -1.30226   \n",
       "split2_train_score      -1.66109      -1.58268     -1.53196     -1.27348   \n",
       "split4_test_score       -1.66255      -1.58814     -1.54167     -1.30539   \n",
       "split6_train_score      -1.66108      -1.58258      -1.5318     -1.27376   \n",
       "split5_test_score       -1.66206      -1.58623     -1.53847     -1.29948   \n",
       "split8_test_score       -1.66037       -1.5825      -1.5329     -1.28643   \n",
       "mean_train_score        -1.66126      -1.58321     -1.53284     -1.27576   \n",
       "split0_test_score       -1.66183        -1.585     -1.53611     -1.29203   \n",
       "split7_train_score      -1.66137       -1.5835      -1.5333     -1.27678   \n",
       "split1_train_score      -1.66128      -1.58335     -1.53306     -1.27567   \n",
       "split0_train_score      -1.66129      -1.58349     -1.53335     -1.27695   \n",
       "split6_test_score       -1.66292      -1.58907     -1.54341     -1.31035   \n",
       "split3_train_score      -1.66127      -1.58353      -1.5335     -1.27791   \n",
       "split4_train_score      -1.66112      -1.58274     -1.53209     -1.27453   \n",
       "split7_test_score       -1.66124      -1.58438     -1.53565     -1.29092   \n",
       "split2_test_score       -1.66282      -1.58857     -1.54246     -1.31086   \n",
       "std_score_time        0.00236193    0.00151286   0.00173385  0.000594295   \n",
       "std_fit_time            0.131009     0.0404682    0.0998649     0.075873   \n",
       "split9_train_score      -1.66134      -1.58322     -1.53279     -1.27531   \n",
       "mean_test_score         -1.66188      -1.58598     -1.53814     -1.29787   \n",
       "split1_test_score       -1.66181      -1.58534      -1.5369     -1.29495   \n",
       "split8_train_score      -1.66151      -1.58386     -1.53384     -1.27781   \n",
       "split5_train_score      -1.66123      -1.58315     -1.53275      -1.2754   \n",
       "mean_score_time        0.0279251     0.0276928    0.0273095    0.0273726   \n",
       "\n",
       "                        0.100       1.000        10.000  \n",
       "rank_test_score              3           2            1  \n",
       "split3_test_score      -1.1168   -0.631089    -0.468398  \n",
       "std_train_score     0.00175368  0.00187261  0.000420668  \n",
       "param_C                    0.1           1           10  \n",
       "std_test_score       0.0113472   0.0182597    0.0207703  \n",
       "mean_fit_time          2.66484      3.3849      7.56048  \n",
       "params              {'C': 0.1}    {'C': 1}    {'C': 10}  \n",
       "split9_test_score     -1.14279   -0.686624    -0.527697  \n",
       "split2_train_score    -1.09325   -0.487579   -0.0810096  \n",
       "split4_test_score     -1.14157   -0.659285    -0.499567  \n",
       "split6_train_score    -1.09411   -0.489059   -0.0812914  \n",
       "split5_test_score     -1.13771   -0.680086    -0.535384  \n",
       "split8_test_score     -1.12074   -0.651967    -0.495042  \n",
       "mean_train_score      -1.09596   -0.489657   -0.0813885  \n",
       "split0_test_score     -1.12681   -0.647784     -0.48714  \n",
       "split7_train_score    -1.09718   -0.490809   -0.0815173  \n",
       "split1_train_score    -1.09517   -0.487596   -0.0810068  \n",
       "split0_train_score    -1.09752    -0.49237   -0.0822044  \n",
       "split6_test_score     -1.14745   -0.669984    -0.511071  \n",
       "split3_train_score    -1.09873   -0.492529   -0.0818492  \n",
       "split4_train_score    -1.09506   -0.489909    -0.081511  \n",
       "split7_test_score     -1.12446   -0.649585    -0.495276  \n",
       "split2_test_score     -1.15248   -0.690892    -0.533838  \n",
       "std_score_time       0.0011702  0.00105346  0.000883059  \n",
       "std_fit_time         0.0655879    0.108678     0.133269  \n",
       "split9_train_score    -1.09494   -0.487628   -0.0809474  \n",
       "mean_test_score        -1.1343   -0.664043    -0.507148  \n",
       "split1_test_score     -1.13218   -0.673132     -0.51807  \n",
       "split8_train_score    -1.09832   -0.491128   -0.0816866  \n",
       "split5_train_score    -1.09536   -0.487963   -0.0808612  \n",
       "mean_score_time      0.0281239   0.0275383    0.0272945  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10]\n",
    "predict(better_model, all_mat_12, x_train_12.shape[0], './config/prediction_ridge_12g_init.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Although the score here is high, the score on Kaggle is horrible! I am thinking even in the cv stage, overfitting occurs, since we have tooooo many features. Therefore I want to split more data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=True),\n",
    "                          param_grid, scoring=score, cv=3)\n",
    "\n",
    "better_model.fit(x_train_12, y_train_12)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_12g_init_adjust'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 1102302).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.68223</td>\n",
       "      <td>-1.60113</td>\n",
       "      <td>-1.56212</td>\n",
       "      <td>-1.36052</td>\n",
       "      <td>-1.20959</td>\n",
       "      <td>-0.705481</td>\n",
       "      <td>-0.518315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.6816</td>\n",
       "      <td>-1.59846</td>\n",
       "      <td>-1.55698</td>\n",
       "      <td>-1.33755</td>\n",
       "      <td>-1.16909</td>\n",
       "      <td>-0.52316</td>\n",
       "      <td>-0.0828302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>4.742e-05</td>\n",
       "      <td>0.000180722</td>\n",
       "      <td>0.000360079</td>\n",
       "      <td>0.00122794</td>\n",
       "      <td>0.00142298</td>\n",
       "      <td>0.0036222</td>\n",
       "      <td>0.00382068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>7.70084e-05</td>\n",
       "      <td>0.000361023</td>\n",
       "      <td>0.000626658</td>\n",
       "      <td>0.00110557</td>\n",
       "      <td>0.000786117</td>\n",
       "      <td>0.000722566</td>\n",
       "      <td>0.000338782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.68143</td>\n",
       "      <td>-1.59762</td>\n",
       "      <td>-1.55551</td>\n",
       "      <td>-1.33501</td>\n",
       "      <td>-1.16728</td>\n",
       "      <td>-0.522336</td>\n",
       "      <td>-0.082143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>2.57027</td>\n",
       "      <td>1.91304</td>\n",
       "      <td>1.86488</td>\n",
       "      <td>1.9152</td>\n",
       "      <td>1.98768</td>\n",
       "      <td>2.62257</td>\n",
       "      <td>5.50454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.005}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.05}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.68218</td>\n",
       "      <td>-1.60092</td>\n",
       "      <td>-1.56177</td>\n",
       "      <td>-1.35983</td>\n",
       "      <td>-1.2096</td>\n",
       "      <td>-0.71431</td>\n",
       "      <td>-0.527674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00673483</td>\n",
       "      <td>0.0040049</td>\n",
       "      <td>0.00199757</td>\n",
       "      <td>0.00338793</td>\n",
       "      <td>0.00282201</td>\n",
       "      <td>0.00442615</td>\n",
       "      <td>0.00372729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.68159</td>\n",
       "      <td>-1.59829</td>\n",
       "      <td>-1.55666</td>\n",
       "      <td>-1.3371</td>\n",
       "      <td>-1.16874</td>\n",
       "      <td>-0.521392</td>\n",
       "      <td>-0.0820838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.147431</td>\n",
       "      <td>0.076785</td>\n",
       "      <td>0.042354</td>\n",
       "      <td>0.0308333</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.0788096</td>\n",
       "      <td>0.141395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0962177</td>\n",
       "      <td>0.0938481</td>\n",
       "      <td>0.094963</td>\n",
       "      <td>0.0939476</td>\n",
       "      <td>0.0940927</td>\n",
       "      <td>0.0996024</td>\n",
       "      <td>0.096571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.68218</td>\n",
       "      <td>-1.60091</td>\n",
       "      <td>-1.56171</td>\n",
       "      <td>-1.35933</td>\n",
       "      <td>-1.20859</td>\n",
       "      <td>-0.709643</td>\n",
       "      <td>-0.523023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.68154</td>\n",
       "      <td>-1.59812</td>\n",
       "      <td>-1.55638</td>\n",
       "      <td>-1.33655</td>\n",
       "      <td>-1.16837</td>\n",
       "      <td>-0.522296</td>\n",
       "      <td>-0.0823523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.68211</td>\n",
       "      <td>-1.60068</td>\n",
       "      <td>-1.56125</td>\n",
       "      <td>-1.35764</td>\n",
       "      <td>-1.20658</td>\n",
       "      <td>-0.709139</td>\n",
       "      <td>-0.523079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0.001         0.005        0.010        0.050   \\\n",
       "rank_test_score                7             6            5            4   \n",
       "split1_test_score       -1.68223      -1.60113     -1.56212     -1.36052   \n",
       "split0_train_score       -1.6816      -1.59846     -1.55698     -1.33755   \n",
       "std_test_score         4.742e-05   0.000180722  0.000360079   0.00122794   \n",
       "std_train_score      7.70084e-05   0.000361023  0.000626658   0.00110557   \n",
       "split1_train_score      -1.68143      -1.59762     -1.55551     -1.33501   \n",
       "mean_fit_time            2.57027       1.91304      1.86488       1.9152   \n",
       "params              {'C': 0.001}  {'C': 0.005}  {'C': 0.01}  {'C': 0.05}   \n",
       "split2_test_score       -1.68218      -1.60092     -1.56177     -1.35983   \n",
       "std_score_time        0.00673483     0.0040049   0.00199757   0.00338793   \n",
       "split2_train_score      -1.68159      -1.59829     -1.55666      -1.3371   \n",
       "std_fit_time            0.147431      0.076785     0.042354    0.0308333   \n",
       "mean_score_time        0.0962177     0.0938481     0.094963    0.0939476   \n",
       "mean_test_score         -1.68218      -1.60091     -1.56171     -1.35933   \n",
       "mean_train_score        -1.68154      -1.59812     -1.55638     -1.33655   \n",
       "split0_test_score       -1.68211      -1.60068     -1.56125     -1.35764   \n",
       "param_C                    0.001         0.005         0.01         0.05   \n",
       "\n",
       "                         0.100        1.000        10.000  \n",
       "rank_test_score               3            2            1  \n",
       "split1_test_score      -1.20959    -0.705481    -0.518315  \n",
       "split0_train_score     -1.16909     -0.52316   -0.0828302  \n",
       "std_test_score       0.00142298    0.0036222   0.00382068  \n",
       "std_train_score     0.000786117  0.000722566  0.000338782  \n",
       "split1_train_score     -1.16728    -0.522336    -0.082143  \n",
       "mean_fit_time           1.98768      2.62257      5.50454  \n",
       "params               {'C': 0.1}     {'C': 1}    {'C': 10}  \n",
       "split2_test_score       -1.2096     -0.71431    -0.527674  \n",
       "std_score_time       0.00282201   0.00442615   0.00372729  \n",
       "split2_train_score     -1.16874    -0.521392   -0.0820838  \n",
       "std_fit_time           0.015341    0.0788096     0.141395  \n",
       "mean_score_time       0.0940927    0.0996024     0.096571  \n",
       "mean_test_score        -1.20859    -0.709643    -0.523023  \n",
       "mean_train_score       -1.16837    -0.522296   -0.0823523  \n",
       "split0_test_score      -1.20658    -0.709139    -0.523079  \n",
       "param_C                     0.1            1           10  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.001, 0.005, 0.01, 0.05, 0.1, 1, 10]\n",
    "predict(better_model, all_mat_12, x_train_12.shape[0], './config/prediction_ridge_12g_init_adjust.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 125747).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat_12, x_train_12 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_2_gram_5.pickle', \n",
    "                                      matrix='../../static/tf_matrix_2_gram_5.pickle', re_load=False,\n",
    "                                      min_df=5, max_feature=None, min_n=1, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_12 = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False),\n",
    "                          param_grid, scoring=score, cv=5)\n",
    "\n",
    "better_model.fit(x_train_12, y_train_12)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_12g_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 125747).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.29026</td>\n",
       "      <td>-1.22918</td>\n",
       "      <td>-1.02738</td>\n",
       "      <td>-0.785218</td>\n",
       "      <td>-0.705601</td>\n",
       "      <td>-0.730213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>5.92271e-05</td>\n",
       "      <td>0.000327405</td>\n",
       "      <td>0.000326161</td>\n",
       "      <td>0.000800671</td>\n",
       "      <td>0.00071194</td>\n",
       "      <td>0.000159059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.160326</td>\n",
       "      <td>0.115314</td>\n",
       "      <td>0.0914808</td>\n",
       "      <td>0.803662</td>\n",
       "      <td>0.506879</td>\n",
       "      <td>0.468087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00013009</td>\n",
       "      <td>0.000566741</td>\n",
       "      <td>0.00133877</td>\n",
       "      <td>0.00273181</td>\n",
       "      <td>0.00396793</td>\n",
       "      <td>0.00665831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.29004</td>\n",
       "      <td>-1.22799</td>\n",
       "      <td>-1.01217</td>\n",
       "      <td>-0.685955</td>\n",
       "      <td>-0.319211</td>\n",
       "      <td>-0.077775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.28997</td>\n",
       "      <td>-1.22726</td>\n",
       "      <td>-1.01146</td>\n",
       "      <td>-0.685403</td>\n",
       "      <td>-0.317998</td>\n",
       "      <td>-0.0776524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.29035</td>\n",
       "      <td>-1.23055</td>\n",
       "      <td>-1.03045</td>\n",
       "      <td>-0.786153</td>\n",
       "      <td>-0.708286</td>\n",
       "      <td>-0.734369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.2903</td>\n",
       "      <td>-1.22993</td>\n",
       "      <td>-1.02993</td>\n",
       "      <td>-0.788049</td>\n",
       "      <td>-0.708935</td>\n",
       "      <td>-0.73409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>1.46489</td>\n",
       "      <td>2.15448</td>\n",
       "      <td>3.05309</td>\n",
       "      <td>5.68989</td>\n",
       "      <td>9.56212</td>\n",
       "      <td>11.8287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.29001</td>\n",
       "      <td>-1.22759</td>\n",
       "      <td>-1.01175</td>\n",
       "      <td>-0.685064</td>\n",
       "      <td>-0.318094</td>\n",
       "      <td>-0.0776069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.29046</td>\n",
       "      <td>-1.23019</td>\n",
       "      <td>-1.0303</td>\n",
       "      <td>-0.786296</td>\n",
       "      <td>-0.704766</td>\n",
       "      <td>-0.72705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00705029</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.00612164</td>\n",
       "      <td>0.00158453</td>\n",
       "      <td>0.00915091</td>\n",
       "      <td>0.00228271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.29034</td>\n",
       "      <td>-1.2304</td>\n",
       "      <td>-1.03134</td>\n",
       "      <td>-0.790389</td>\n",
       "      <td>-0.715888</td>\n",
       "      <td>-0.746495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.28997</td>\n",
       "      <td>-1.22727</td>\n",
       "      <td>-1.01131</td>\n",
       "      <td>-0.683833</td>\n",
       "      <td>-0.316976</td>\n",
       "      <td>-0.0773081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.29007</td>\n",
       "      <td>-1.22932</td>\n",
       "      <td>-1.03019</td>\n",
       "      <td>-0.792191</td>\n",
       "      <td>-0.710139</td>\n",
       "      <td>-0.732328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.29011</td>\n",
       "      <td>-1.22797</td>\n",
       "      <td>-1.01203</td>\n",
       "      <td>-0.684439</td>\n",
       "      <td>-0.318037</td>\n",
       "      <td>-0.0776899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.28995</td>\n",
       "      <td>-1.22747</td>\n",
       "      <td>-1.01177</td>\n",
       "      <td>-0.685689</td>\n",
       "      <td>-0.318246</td>\n",
       "      <td>-0.0776089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0445558</td>\n",
       "      <td>0.0500005</td>\n",
       "      <td>0.0472573</td>\n",
       "      <td>0.0426936</td>\n",
       "      <td>0.0470781</td>\n",
       "      <td>0.0432498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0.001        0.010        0.100        1.000    \\\n",
       "split0_test_score       -1.29026     -1.22918     -1.02738    -0.785218   \n",
       "std_train_score      5.92271e-05  0.000327405  0.000326161  0.000800671   \n",
       "std_fit_time            0.160326     0.115314    0.0914808     0.803662   \n",
       "param_C                    0.001         0.01          0.1            1   \n",
       "std_test_score        0.00013009  0.000566741   0.00133877   0.00273181   \n",
       "split0_train_score      -1.29004     -1.22799     -1.01217    -0.685955   \n",
       "split3_train_score      -1.28997     -1.22726     -1.01146    -0.685403   \n",
       "params              {'C': 0.001}  {'C': 0.01}   {'C': 0.1}     {'C': 1}   \n",
       "split3_test_score       -1.29035     -1.23055     -1.03045    -0.786153   \n",
       "mean_test_score          -1.2903     -1.22993     -1.02993    -0.788049   \n",
       "mean_fit_time            1.46489      2.15448      3.05309      5.68989   \n",
       "mean_train_score        -1.29001     -1.22759     -1.01175    -0.685064   \n",
       "split1_test_score       -1.29046     -1.23019      -1.0303    -0.786296   \n",
       "std_score_time        0.00705029      0.01092   0.00612164   0.00158453   \n",
       "split2_test_score       -1.29034      -1.2304     -1.03134    -0.790389   \n",
       "split2_train_score      -1.28997     -1.22727     -1.01131    -0.683833   \n",
       "split4_test_score       -1.29007     -1.22932     -1.03019    -0.792191   \n",
       "split4_train_score      -1.29011     -1.22797     -1.01203    -0.684439   \n",
       "split1_train_score      -1.28995     -1.22747     -1.01177    -0.685689   \n",
       "rank_test_score                6            5            4            3   \n",
       "mean_score_time        0.0445558    0.0500005    0.0472573    0.0426936   \n",
       "\n",
       "                       10.000       100.000  \n",
       "split0_test_score    -0.705601    -0.730213  \n",
       "std_train_score     0.00071194  0.000159059  \n",
       "std_fit_time          0.506879     0.468087  \n",
       "param_C                     10          100  \n",
       "std_test_score      0.00396793   0.00665831  \n",
       "split0_train_score   -0.319211    -0.077775  \n",
       "split3_train_score   -0.317998   -0.0776524  \n",
       "params               {'C': 10}   {'C': 100}  \n",
       "split3_test_score    -0.708286    -0.734369  \n",
       "mean_test_score      -0.708935     -0.73409  \n",
       "mean_fit_time          9.56212      11.8287  \n",
       "mean_train_score     -0.318094   -0.0776069  \n",
       "split1_test_score    -0.704766     -0.72705  \n",
       "std_score_time      0.00915091   0.00228271  \n",
       "split2_test_score    -0.715888    -0.746495  \n",
       "split2_train_score   -0.316976   -0.0773081  \n",
       "split4_test_score    -0.710139    -0.732328  \n",
       "split4_train_score   -0.318037   -0.0776899  \n",
       "split1_train_score   -0.318246   -0.0776089  \n",
       "rank_test_score              1            2  \n",
       "mean_score_time      0.0470781    0.0432498  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns =  [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "predict(better_model, all_mat_12, x_train_12.shape[0], './config/prediction_ridge_12g_init.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf, all_mat_12, x_train_12 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_2_gram_5.pickle', \n",
    "                                      matrix='../../static/tf_matrix_2_gram_5.pickle', re_load=False,\n",
    "                                      min_df=5, max_feature=None, min_n=1, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_12 = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "test.fit(x_train_12, y_train_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-CV average accuracy: -0.5114551695002019\n"
     ]
    }
   ],
   "source": [
    "print(\"10-CV average accuracy: {}\".format(\n",
    "        np.mean(cross_val_score(test, x_train_12, y_train_12, cv=10,\n",
    "                                scoring=score))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 30000).\n"
     ]
    }
   ],
   "source": [
    "predict(test, all_mat_12, x_train_12.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Selection for Bigram\n",
    "Let's try chi2 feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 215461).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "tf, all_mat_12, x_train_12 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_2_gram_min3.pickle', \n",
    "                                      matrix='../../static/tf_matrix_2_gram_min3.pickle', re_load=False,\n",
    "                                      min_df=5, max_feature=None, min_n=1, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_12 = list(map(str, table_train['stars']))\n",
    "\n",
    "chi2, pval = chi2(x_train_12, y_train_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "index = np.argpartition(chi2, -30000)[-30000:]\n",
    "x_train_chi2 = x_train_12.tocsc()[:, index]\n",
    "all_mat_chi2 = all_mat_12.tocsc()[:, index]\n",
    "x_train_test = all_mat_chi2[:36692,:]\n",
    "y_train_chi2 = y_train_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False),\n",
    "                          param_grid, scoring=score, cv=2)\n",
    "\n",
    "better_model.fit(x_train_test, y_train_chi2)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_12g_init'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 30000).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.29069</td>\n",
       "      <td>-1.2332</td>\n",
       "      <td>-1.03556</td>\n",
       "      <td>-0.751064</td>\n",
       "      <td>-0.521778</td>\n",
       "      <td>-0.302486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.29075</td>\n",
       "      <td>-1.23332</td>\n",
       "      <td>-1.03555</td>\n",
       "      <td>-0.750291</td>\n",
       "      <td>-0.521243</td>\n",
       "      <td>-0.301279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.29106</td>\n",
       "      <td>-1.23477</td>\n",
       "      <td>-1.04504</td>\n",
       "      <td>-0.79365</td>\n",
       "      <td>-0.690329</td>\n",
       "      <td>-0.712036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.29095</td>\n",
       "      <td>-1.23511</td>\n",
       "      <td>-1.04525</td>\n",
       "      <td>-0.791466</td>\n",
       "      <td>-0.687781</td>\n",
       "      <td>-0.707991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.29068</td>\n",
       "      <td>-1.23388</td>\n",
       "      <td>-1.04425</td>\n",
       "      <td>-0.799259</td>\n",
       "      <td>-0.698895</td>\n",
       "      <td>-0.718173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.29072</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-1.03523</td>\n",
       "      <td>-0.751028</td>\n",
       "      <td>-0.521446</td>\n",
       "      <td>-0.30127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.29095</td>\n",
       "      <td>-1.23504</td>\n",
       "      <td>-1.0465</td>\n",
       "      <td>-0.798567</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>-0.725382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00351059</td>\n",
       "      <td>0.00467468</td>\n",
       "      <td>0.00393094</td>\n",
       "      <td>0.00207386</td>\n",
       "      <td>0.00087495</td>\n",
       "      <td>0.00876359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0384626</td>\n",
       "      <td>0.0423463</td>\n",
       "      <td>0.0401888</td>\n",
       "      <td>0.0370089</td>\n",
       "      <td>0.0339904</td>\n",
       "      <td>0.0386178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.29085</td>\n",
       "      <td>-1.23372</td>\n",
       "      <td>-1.03609</td>\n",
       "      <td>-0.74957</td>\n",
       "      <td>-0.5207</td>\n",
       "      <td>-0.300153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.29088</td>\n",
       "      <td>-1.23391</td>\n",
       "      <td>-1.04253</td>\n",
       "      <td>-0.793047</td>\n",
       "      <td>-0.689254</td>\n",
       "      <td>-0.707295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.127533</td>\n",
       "      <td>0.0467646</td>\n",
       "      <td>0.113096</td>\n",
       "      <td>0.0785488</td>\n",
       "      <td>0.359976</td>\n",
       "      <td>0.834226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.2909</td>\n",
       "      <td>-1.23454</td>\n",
       "      <td>-1.04471</td>\n",
       "      <td>-0.795197</td>\n",
       "      <td>-0.693585</td>\n",
       "      <td>-0.714175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>5.70811e-05</td>\n",
       "      <td>0.000321698</td>\n",
       "      <td>0.000422051</td>\n",
       "      <td>0.000983269</td>\n",
       "      <td>0.00103208</td>\n",
       "      <td>0.000741338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.000127819</td>\n",
       "      <td>0.000541813</td>\n",
       "      <td>0.0013085</td>\n",
       "      <td>0.00312354</td>\n",
       "      <td>0.00559623</td>\n",
       "      <td>0.0068078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.29071</td>\n",
       "      <td>-1.23299</td>\n",
       "      <td>-1.03496</td>\n",
       "      <td>-0.7487</td>\n",
       "      <td>-0.519615</td>\n",
       "      <td>-0.301147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.29078</td>\n",
       "      <td>-1.23368</td>\n",
       "      <td>-1.03593</td>\n",
       "      <td>-0.751092</td>\n",
       "      <td>-0.522676</td>\n",
       "      <td>-0.301341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.790422</td>\n",
       "      <td>1.05342</td>\n",
       "      <td>1.69691</td>\n",
       "      <td>2.56112</td>\n",
       "      <td>4.45119</td>\n",
       "      <td>8.28723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0.001        0.010        0.100        1.000    \\\n",
       "split1_train_score      -1.29069      -1.2332     -1.03556    -0.751064   \n",
       "mean_train_score        -1.29075     -1.23332     -1.03555    -0.750291   \n",
       "split1_test_score       -1.29106     -1.23477     -1.04504     -0.79365   \n",
       "split3_test_score       -1.29095     -1.23511     -1.04525    -0.791466   \n",
       "params              {'C': 0.001}  {'C': 0.01}   {'C': 0.1}     {'C': 1}   \n",
       "split4_test_score       -1.29068     -1.23388     -1.04425    -0.799259   \n",
       "split3_train_score      -1.29072       -1.233     -1.03523    -0.751028   \n",
       "split2_test_score       -1.29095     -1.23504      -1.0465    -0.798567   \n",
       "std_score_time        0.00351059   0.00467468   0.00393094   0.00207386   \n",
       "mean_score_time        0.0384626    0.0423463    0.0401888    0.0370089   \n",
       "split4_train_score      -1.29085     -1.23372     -1.03609     -0.74957   \n",
       "split0_test_score       -1.29088     -1.23391     -1.04253    -0.793047   \n",
       "std_fit_time            0.127533    0.0467646     0.113096    0.0785488   \n",
       "mean_test_score          -1.2909     -1.23454     -1.04471    -0.795197   \n",
       "std_train_score      5.70811e-05  0.000321698  0.000422051  0.000983269   \n",
       "std_test_score       0.000127819  0.000541813    0.0013085   0.00312354   \n",
       "split2_train_score      -1.29071     -1.23299     -1.03496      -0.7487   \n",
       "param_C                    0.001         0.01          0.1            1   \n",
       "split0_train_score      -1.29078     -1.23368     -1.03593    -0.751092   \n",
       "mean_fit_time           0.790422      1.05342      1.69691      2.56112   \n",
       "rank_test_score                6            5            4            3   \n",
       "\n",
       "                       10.000       100.000  \n",
       "split1_train_score   -0.521778    -0.302486  \n",
       "mean_train_score     -0.521243    -0.301279  \n",
       "split1_test_score    -0.690329    -0.712036  \n",
       "split3_test_score    -0.687781    -0.707991  \n",
       "params               {'C': 10}   {'C': 100}  \n",
       "split4_test_score    -0.698895    -0.718173  \n",
       "split3_train_score   -0.521446     -0.30127  \n",
       "split2_test_score    -0.701669    -0.725382  \n",
       "std_score_time      0.00087495   0.00876359  \n",
       "mean_score_time      0.0339904    0.0386178  \n",
       "split4_train_score     -0.5207    -0.300153  \n",
       "split0_test_score    -0.689254    -0.707295  \n",
       "std_fit_time          0.359976     0.834226  \n",
       "mean_test_score      -0.693585    -0.714175  \n",
       "std_train_score     0.00103208  0.000741338  \n",
       "std_test_score      0.00559623    0.0068078  \n",
       "split2_train_score   -0.519615    -0.301147  \n",
       "param_C                     10          100  \n",
       "split0_train_score   -0.522676    -0.301341  \n",
       "mean_fit_time          4.45119      8.28723  \n",
       "rank_test_score              1            2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns =  [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "predict(better_model, all_mat_chi2, x_train_chi2.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Interesting, it wants less regularization power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try 100 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "test.fit(x_train_chi2[:30000], y_train_chi2[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1040203258107906"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train = test.predict(x_train_chi2[30001:])\n",
    "error = 0\n",
    "for i in range(len(y_train_chi2[30001:])):\n",
    "    error += (int(predict_train[i]) - int(y_train_chi2[i])) ** 2\n",
    "error / len(y_train_chi2[30001:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Selection using Lasso for Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.1, 1, 5, 10, 20]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1', dual=False),\n",
    "                          param_grid, scoring=score, cv=5)\n",
    "\n",
    "better_model.fit(x_train_12, y_train_12)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_lasso_12g_feature'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 215461).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.05255</td>\n",
       "      <td>-0.751098</td>\n",
       "      <td>-0.445081</td>\n",
       "      <td>-0.251143</td>\n",
       "      <td>-0.134408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.0517</td>\n",
       "      <td>-0.750008</td>\n",
       "      <td>-0.444824</td>\n",
       "      <td>-0.250986</td>\n",
       "      <td>-0.134415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.05511</td>\n",
       "      <td>-0.770765</td>\n",
       "      <td>-0.720187</td>\n",
       "      <td>-0.745451</td>\n",
       "      <td>-0.773692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.05719</td>\n",
       "      <td>-0.771527</td>\n",
       "      <td>-0.719527</td>\n",
       "      <td>-0.746274</td>\n",
       "      <td>-0.773638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>{'C': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.04646</td>\n",
       "      <td>-0.777611</td>\n",
       "      <td>-0.721505</td>\n",
       "      <td>-0.744271</td>\n",
       "      <td>-0.771091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.05168</td>\n",
       "      <td>-0.751573</td>\n",
       "      <td>-0.443245</td>\n",
       "      <td>-0.249908</td>\n",
       "      <td>-0.133871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.05957</td>\n",
       "      <td>-0.783559</td>\n",
       "      <td>-0.733323</td>\n",
       "      <td>-0.761658</td>\n",
       "      <td>-0.790098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00284741</td>\n",
       "      <td>0.00847726</td>\n",
       "      <td>0.00205692</td>\n",
       "      <td>0.00613523</td>\n",
       "      <td>0.0202308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0479272</td>\n",
       "      <td>0.0536708</td>\n",
       "      <td>0.0479618</td>\n",
       "      <td>0.0517358</td>\n",
       "      <td>0.0600841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.05164</td>\n",
       "      <td>-0.748843</td>\n",
       "      <td>-0.445648</td>\n",
       "      <td>-0.251375</td>\n",
       "      <td>-0.13459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.05061</td>\n",
       "      <td>-0.771958</td>\n",
       "      <td>-0.723292</td>\n",
       "      <td>-0.747898</td>\n",
       "      <td>-0.77467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.695983</td>\n",
       "      <td>0.450616</td>\n",
       "      <td>1.42191</td>\n",
       "      <td>0.749519</td>\n",
       "      <td>1.21083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.05379</td>\n",
       "      <td>-0.775083</td>\n",
       "      <td>-0.723567</td>\n",
       "      <td>-0.74911</td>\n",
       "      <td>-0.776638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000687908</td>\n",
       "      <td>0.00158204</td>\n",
       "      <td>0.000897512</td>\n",
       "      <td>0.000544288</td>\n",
       "      <td>0.000324314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00470244</td>\n",
       "      <td>0.00488443</td>\n",
       "      <td>0.00504463</td>\n",
       "      <td>0.00638363</td>\n",
       "      <td>0.00683325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.05214</td>\n",
       "      <td>-0.747473</td>\n",
       "      <td>-0.444497</td>\n",
       "      <td>-0.251286</td>\n",
       "      <td>-0.134856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.05049</td>\n",
       "      <td>-0.751052</td>\n",
       "      <td>-0.445649</td>\n",
       "      <td>-0.251218</td>\n",
       "      <td>-0.134347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>6.59445</td>\n",
       "      <td>8.66197</td>\n",
       "      <td>17.3326</td>\n",
       "      <td>21.3336</td>\n",
       "      <td>27.3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0.1         1.0          5.0          10.0  \\\n",
       "split1_train_score     -1.05255   -0.751098    -0.445081    -0.251143   \n",
       "mean_train_score        -1.0517   -0.750008    -0.444824    -0.250986   \n",
       "split1_test_score      -1.05511   -0.770765    -0.720187    -0.745451   \n",
       "split3_test_score      -1.05719   -0.771527    -0.719527    -0.746274   \n",
       "params               {'C': 0.1}    {'C': 1}     {'C': 5}    {'C': 10}   \n",
       "split4_test_score      -1.04646   -0.777611    -0.721505    -0.744271   \n",
       "split3_train_score     -1.05168   -0.751573    -0.443245    -0.249908   \n",
       "split2_test_score      -1.05957   -0.783559    -0.733323    -0.761658   \n",
       "std_score_time       0.00284741  0.00847726   0.00205692   0.00613523   \n",
       "mean_score_time       0.0479272   0.0536708    0.0479618    0.0517358   \n",
       "split4_train_score     -1.05164   -0.748843    -0.445648    -0.251375   \n",
       "split0_test_score      -1.05061   -0.771958    -0.723292    -0.747898   \n",
       "std_fit_time           0.695983    0.450616      1.42191     0.749519   \n",
       "mean_test_score        -1.05379   -0.775083    -0.723567     -0.74911   \n",
       "std_train_score     0.000687908  0.00158204  0.000897512  0.000544288   \n",
       "std_test_score       0.00470244  0.00488443   0.00504463   0.00638363   \n",
       "split2_train_score     -1.05214   -0.747473    -0.444497    -0.251286   \n",
       "param_C                     0.1           1            5           10   \n",
       "split0_train_score     -1.05049   -0.751052    -0.445649    -0.251218   \n",
       "mean_fit_time           6.59445     8.66197      17.3326      21.3336   \n",
       "rank_test_score               5           3            1            2   \n",
       "\n",
       "                           20.0  \n",
       "split1_train_score    -0.134408  \n",
       "mean_train_score      -0.134415  \n",
       "split1_test_score     -0.773692  \n",
       "split3_test_score     -0.773638  \n",
       "params                {'C': 20}  \n",
       "split4_test_score     -0.771091  \n",
       "split3_train_score    -0.133871  \n",
       "split2_test_score     -0.790098  \n",
       "std_score_time        0.0202308  \n",
       "mean_score_time       0.0600841  \n",
       "split4_train_score     -0.13459  \n",
       "split0_test_score      -0.77467  \n",
       "std_fit_time            1.21083  \n",
       "mean_test_score       -0.776638  \n",
       "std_train_score     0.000324314  \n",
       "std_test_score       0.00683325  \n",
       "split2_train_score    -0.134856  \n",
       "param_C                      20  \n",
       "split0_train_score    -0.134347  \n",
       "mean_fit_time           27.3549  \n",
       "rank_test_score               4  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.1, 1, 5, 10, 20]\n",
    "predict(better_model, all_mat_12, x_train_12.shape[0], './config/prediction_lasso_12g_feature.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_12 = LogisticRegression(C=5, penalty='l1')\n",
    "model_12 = SelectFromModel(test)\n",
    "model_12.fit(x_train_12, y_train_12)\n",
    "all_mat_12_lasso = model_12.transform(all_mat_12)\n",
    "x_train_12_lasso = model_12.transform(x_train_12)\n",
    "x_train_12_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36692, 5891)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mat_12_lasso = model_12.transform(all_mat_12)\n",
    "x_train_12_lasso = model_12.transform(x_train_12)\n",
    "x_train_12_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then use ridge model\n",
    "test_12_l2 = LogisticRegression(C=5, penalty='l2')\n",
    "test_12_l2.fit(x_train_12_lasso, y_train_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 5891).\n"
     ]
    }
   ],
   "source": [
    "predict(test_12_l2, all_mat_12_lasso, x_train_12.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Unigram Feature Selection\n",
    "Using 30000 to train, other to validate, the result is still pretty bad. We can check if feature selection can help unigram -> give up using bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 23617).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "tf, all_mat, x_train = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector=VECTOR, \n",
    "                                      matrix=MATRIX, re_load=False,\n",
    "                                      min_df=1, max_feature=None, min_n=1, max_n=1)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))\n",
    "\n",
    "chi2_, pval = chi2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [4,5,6]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False),\n",
    "                          param_grid, scoring=score, cv=5)\n",
    "\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_feature'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4.0</th>\n",
       "      <th>4.5</th>\n",
       "      <th>5.0</th>\n",
       "      <th>5.5</th>\n",
       "      <th>6.0</th>\n",
       "      <th>6.5</th>\n",
       "      <th>7.0</th>\n",
       "      <th>7.5</th>\n",
       "      <th>8.0</th>\n",
       "      <th>8.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.602595</td>\n",
       "      <td>-0.593433</td>\n",
       "      <td>-0.585216</td>\n",
       "      <td>-0.577714</td>\n",
       "      <td>-0.5708</td>\n",
       "      <td>-0.56441</td>\n",
       "      <td>-0.558476</td>\n",
       "      <td>-0.552914</td>\n",
       "      <td>-0.547701</td>\n",
       "      <td>-0.54279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.602765</td>\n",
       "      <td>-0.593642</td>\n",
       "      <td>-0.585435</td>\n",
       "      <td>-0.577955</td>\n",
       "      <td>-0.571092</td>\n",
       "      <td>-0.564724</td>\n",
       "      <td>-0.558806</td>\n",
       "      <td>-0.553271</td>\n",
       "      <td>-0.54807</td>\n",
       "      <td>-0.543174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.746274</td>\n",
       "      <td>-0.745897</td>\n",
       "      <td>-0.745803</td>\n",
       "      <td>-0.74591</td>\n",
       "      <td>-0.746166</td>\n",
       "      <td>-0.746549</td>\n",
       "      <td>-0.747001</td>\n",
       "      <td>-0.747532</td>\n",
       "      <td>-0.748111</td>\n",
       "      <td>-0.748734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.747912</td>\n",
       "      <td>-0.74789</td>\n",
       "      <td>-0.748137</td>\n",
       "      <td>-0.74856</td>\n",
       "      <td>-0.749118</td>\n",
       "      <td>-0.749766</td>\n",
       "      <td>-0.750501</td>\n",
       "      <td>-0.751273</td>\n",
       "      <td>-0.752093</td>\n",
       "      <td>-0.752943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 4.0}</td>\n",
       "      <td>{'C': 4.5}</td>\n",
       "      <td>{'C': 5.0}</td>\n",
       "      <td>{'C': 5.5}</td>\n",
       "      <td>{'C': 6.0}</td>\n",
       "      <td>{'C': 6.5}</td>\n",
       "      <td>{'C': 7.0}</td>\n",
       "      <td>{'C': 7.5}</td>\n",
       "      <td>{'C': 8.0}</td>\n",
       "      <td>{'C': 8.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.746095</td>\n",
       "      <td>-0.745571</td>\n",
       "      <td>-0.745346</td>\n",
       "      <td>-0.745348</td>\n",
       "      <td>-0.745506</td>\n",
       "      <td>-0.74578</td>\n",
       "      <td>-0.746171</td>\n",
       "      <td>-0.746622</td>\n",
       "      <td>-0.747126</td>\n",
       "      <td>-0.747679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.602078</td>\n",
       "      <td>-0.592896</td>\n",
       "      <td>-0.584653</td>\n",
       "      <td>-0.577131</td>\n",
       "      <td>-0.570252</td>\n",
       "      <td>-0.563837</td>\n",
       "      <td>-0.557902</td>\n",
       "      <td>-0.552346</td>\n",
       "      <td>-0.547133</td>\n",
       "      <td>-0.542225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.756171</td>\n",
       "      <td>-0.756139</td>\n",
       "      <td>-0.756374</td>\n",
       "      <td>-0.756785</td>\n",
       "      <td>-0.757355</td>\n",
       "      <td>-0.758011</td>\n",
       "      <td>-0.75876</td>\n",
       "      <td>-0.759548</td>\n",
       "      <td>-0.760392</td>\n",
       "      <td>-0.761254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00723236</td>\n",
       "      <td>0.00121893</td>\n",
       "      <td>0.00881874</td>\n",
       "      <td>0.0329008</td>\n",
       "      <td>0.0074007</td>\n",
       "      <td>0.00572176</td>\n",
       "      <td>0.00123468</td>\n",
       "      <td>0.000358444</td>\n",
       "      <td>0.00171617</td>\n",
       "      <td>0.00254675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.04112</td>\n",
       "      <td>0.03399</td>\n",
       "      <td>0.038019</td>\n",
       "      <td>0.0581044</td>\n",
       "      <td>0.0388502</td>\n",
       "      <td>0.0366028</td>\n",
       "      <td>0.0340868</td>\n",
       "      <td>0.0323264</td>\n",
       "      <td>0.0355922</td>\n",
       "      <td>0.0334314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.602991</td>\n",
       "      <td>-0.593894</td>\n",
       "      <td>-0.585709</td>\n",
       "      <td>-0.578242</td>\n",
       "      <td>-0.571378</td>\n",
       "      <td>-0.565062</td>\n",
       "      <td>-0.559139</td>\n",
       "      <td>-0.553609</td>\n",
       "      <td>-0.548417</td>\n",
       "      <td>-0.543515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.739596</td>\n",
       "      <td>-0.739111</td>\n",
       "      <td>-0.738942</td>\n",
       "      <td>-0.739005</td>\n",
       "      <td>-0.73924</td>\n",
       "      <td>-0.739612</td>\n",
       "      <td>-0.740077</td>\n",
       "      <td>-0.740631</td>\n",
       "      <td>-0.741227</td>\n",
       "      <td>-0.741879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.234545</td>\n",
       "      <td>0.131049</td>\n",
       "      <td>0.164222</td>\n",
       "      <td>0.71148</td>\n",
       "      <td>0.413524</td>\n",
       "      <td>0.238084</td>\n",
       "      <td>0.217274</td>\n",
       "      <td>0.160587</td>\n",
       "      <td>0.226181</td>\n",
       "      <td>0.32933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.747209</td>\n",
       "      <td>-0.746921</td>\n",
       "      <td>-0.74692</td>\n",
       "      <td>-0.747121</td>\n",
       "      <td>-0.747476</td>\n",
       "      <td>-0.747943</td>\n",
       "      <td>-0.748501</td>\n",
       "      <td>-0.749121</td>\n",
       "      <td>-0.749789</td>\n",
       "      <td>-0.750497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00133528</td>\n",
       "      <td>0.00134914</td>\n",
       "      <td>0.00134358</td>\n",
       "      <td>0.00134391</td>\n",
       "      <td>0.00135064</td>\n",
       "      <td>0.00135736</td>\n",
       "      <td>0.00136427</td>\n",
       "      <td>0.00136485</td>\n",
       "      <td>0.00135858</td>\n",
       "      <td>0.00136712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0053086</td>\n",
       "      <td>0.00547348</td>\n",
       "      <td>0.00562589</td>\n",
       "      <td>0.00576121</td>\n",
       "      <td>0.00589449</td>\n",
       "      <td>0.00601219</td>\n",
       "      <td>0.00613059</td>\n",
       "      <td>0.00623252</td>\n",
       "      <td>0.00633978</td>\n",
       "      <td>0.00643483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.601061</td>\n",
       "      <td>-0.591971</td>\n",
       "      <td>-0.583795</td>\n",
       "      <td>-0.576356</td>\n",
       "      <td>-0.569529</td>\n",
       "      <td>-0.563176</td>\n",
       "      <td>-0.557272</td>\n",
       "      <td>-0.551772</td>\n",
       "      <td>-0.546597</td>\n",
       "      <td>-0.541709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.605102</td>\n",
       "      <td>-0.596018</td>\n",
       "      <td>-0.587802</td>\n",
       "      <td>-0.580333</td>\n",
       "      <td>-0.573501</td>\n",
       "      <td>-0.567136</td>\n",
       "      <td>-0.561239</td>\n",
       "      <td>-0.555715</td>\n",
       "      <td>-0.550504</td>\n",
       "      <td>-0.54563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>4.41451</td>\n",
       "      <td>4.1354</td>\n",
       "      <td>4.43595</td>\n",
       "      <td>4.83636</td>\n",
       "      <td>4.57782</td>\n",
       "      <td>4.56029</td>\n",
       "      <td>5.14553</td>\n",
       "      <td>4.71049</td>\n",
       "      <td>5.29328</td>\n",
       "      <td>4.87904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           4.0         4.5         5.0         5.5  \\\n",
       "split1_train_score   -0.602595   -0.593433   -0.585216   -0.577714   \n",
       "mean_train_score     -0.602765   -0.593642   -0.585435   -0.577955   \n",
       "split1_test_score    -0.746274   -0.745897   -0.745803    -0.74591   \n",
       "split3_test_score    -0.747912    -0.74789   -0.748137    -0.74856   \n",
       "params              {'C': 4.0}  {'C': 4.5}  {'C': 5.0}  {'C': 5.5}   \n",
       "split4_test_score    -0.746095   -0.745571   -0.745346   -0.745348   \n",
       "split3_train_score   -0.602078   -0.592896   -0.584653   -0.577131   \n",
       "split2_test_score    -0.756171   -0.756139   -0.756374   -0.756785   \n",
       "std_score_time      0.00723236  0.00121893  0.00881874   0.0329008   \n",
       "mean_score_time        0.04112     0.03399    0.038019   0.0581044   \n",
       "split4_train_score   -0.602991   -0.593894   -0.585709   -0.578242   \n",
       "split0_test_score    -0.739596   -0.739111   -0.738942   -0.739005   \n",
       "std_fit_time          0.234545    0.131049    0.164222     0.71148   \n",
       "mean_test_score      -0.747209   -0.746921    -0.74692   -0.747121   \n",
       "std_train_score     0.00133528  0.00134914  0.00134358  0.00134391   \n",
       "std_test_score       0.0053086  0.00547348  0.00562589  0.00576121   \n",
       "split2_train_score   -0.601061   -0.591971   -0.583795   -0.576356   \n",
       "param_C                      4         4.5           5         5.5   \n",
       "split0_train_score   -0.605102   -0.596018   -0.587802   -0.580333   \n",
       "mean_fit_time          4.41451      4.1354     4.43595     4.83636   \n",
       "rank_test_score              4           2           1           3   \n",
       "\n",
       "                           6.0         6.5         7.0          7.5  \\\n",
       "split1_train_score     -0.5708    -0.56441   -0.558476    -0.552914   \n",
       "mean_train_score     -0.571092   -0.564724   -0.558806    -0.553271   \n",
       "split1_test_score    -0.746166   -0.746549   -0.747001    -0.747532   \n",
       "split3_test_score    -0.749118   -0.749766   -0.750501    -0.751273   \n",
       "params              {'C': 6.0}  {'C': 6.5}  {'C': 7.0}   {'C': 7.5}   \n",
       "split4_test_score    -0.745506    -0.74578   -0.746171    -0.746622   \n",
       "split3_train_score   -0.570252   -0.563837   -0.557902    -0.552346   \n",
       "split2_test_score    -0.757355   -0.758011    -0.75876    -0.759548   \n",
       "std_score_time       0.0074007  0.00572176  0.00123468  0.000358444   \n",
       "mean_score_time      0.0388502   0.0366028   0.0340868    0.0323264   \n",
       "split4_train_score   -0.571378   -0.565062   -0.559139    -0.553609   \n",
       "split0_test_score     -0.73924   -0.739612   -0.740077    -0.740631   \n",
       "std_fit_time          0.413524    0.238084    0.217274     0.160587   \n",
       "mean_test_score      -0.747476   -0.747943   -0.748501    -0.749121   \n",
       "std_train_score     0.00135064  0.00135736  0.00136427   0.00136485   \n",
       "std_test_score      0.00589449  0.00601219  0.00613059   0.00623252   \n",
       "split2_train_score   -0.569529   -0.563176   -0.557272    -0.551772   \n",
       "param_C                      6         6.5           7          7.5   \n",
       "split0_train_score   -0.573501   -0.567136   -0.561239    -0.555715   \n",
       "mean_fit_time          4.57782     4.56029     5.14553      4.71049   \n",
       "rank_test_score              5           6           7            8   \n",
       "\n",
       "                           8.0         8.5  \n",
       "split1_train_score   -0.547701    -0.54279  \n",
       "mean_train_score      -0.54807   -0.543174  \n",
       "split1_test_score    -0.748111   -0.748734  \n",
       "split3_test_score    -0.752093   -0.752943  \n",
       "params              {'C': 8.0}  {'C': 8.5}  \n",
       "split4_test_score    -0.747126   -0.747679  \n",
       "split3_train_score   -0.547133   -0.542225  \n",
       "split2_test_score    -0.760392   -0.761254  \n",
       "std_score_time      0.00171617  0.00254675  \n",
       "mean_score_time      0.0355922   0.0334314  \n",
       "split4_train_score   -0.548417   -0.543515  \n",
       "split0_test_score    -0.741227   -0.741879  \n",
       "std_fit_time          0.226181     0.32933  \n",
       "mean_test_score      -0.749789   -0.750497  \n",
       "std_train_score     0.00135858  0.00136712  \n",
       "std_test_score      0.00633978  0.00643483  \n",
       "split2_train_score   -0.546597   -0.541709  \n",
       "param_C                      8         8.5  \n",
       "split0_train_score   -0.550504    -0.54563  \n",
       "mean_fit_time          5.29328     4.87904  \n",
       "rank_test_score              9          10  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = np.arange(4, 9, 0.5)\n",
    "predict(better_model, all_mat, x_train.shape[0], './config/prediction_ridge_feature.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature selection use lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  12.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  12.7s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  12.7s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  12.7s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  10.4s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  10.8s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=  10.9s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=1, total=  10.7s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=1, total=  10.3s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=1, total=  11.0s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.5s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  14.1s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.0s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.2s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.1s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.4s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=  13.1s\n",
      "[CV] .............................................. C=2, total=  13.0s\n",
      "[CV] .............................................. C=2, total=  11.7s\n",
      "[CV] .............................................. C=2, total=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=4, param_grid={'C': [1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x111ee2e18>, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [1,2]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1', dual=False), param_grid, \n",
    "                            scoring=score, cv=10, n_jobs=4, verbose=2)\n",
    "better_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.726845</td>\n",
       "      <td>-0.669956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.723958</td>\n",
       "      <td>-0.666945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.723072</td>\n",
       "      <td>-0.666831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.721597</td>\n",
       "      <td>-0.664231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.77388</td>\n",
       "      <td>-0.759608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.726949</td>\n",
       "      <td>-0.669296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.721971</td>\n",
       "      <td>-0.665655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.778833</td>\n",
       "      <td>-0.763641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.761013</td>\n",
       "      <td>-0.744859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.960552</td>\n",
       "      <td>0.801898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0151279</td>\n",
       "      <td>0.0158491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.763854</td>\n",
       "      <td>-0.745524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.746911</td>\n",
       "      <td>-0.733738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.732745</td>\n",
       "      <td>-0.716775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.781609</td>\n",
       "      <td>-0.766678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.749213</td>\n",
       "      <td>-0.729813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0409639</td>\n",
       "      <td>0.0384331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00190128</td>\n",
       "      <td>0.00168143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.748923</td>\n",
       "      <td>-0.729591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.725785</td>\n",
       "      <td>-0.668251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.723485</td>\n",
       "      <td>-0.665978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.723411</td>\n",
       "      <td>-0.666713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.721882</td>\n",
       "      <td>-0.66555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.769909</td>\n",
       "      <td>-0.750672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.764248</td>\n",
       "      <td>-0.752555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>11.4154</td>\n",
       "      <td>12.9015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.724585</td>\n",
       "      <td>-0.66699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00615676</td>\n",
       "      <td>0.0110444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1\n",
       "split0_train_score   -0.726845   -0.669956\n",
       "mean_train_score     -0.723958   -0.666945\n",
       "split1_train_score   -0.723072   -0.666831\n",
       "split2_train_score   -0.721597   -0.664231\n",
       "split9_test_score     -0.77388   -0.759608\n",
       "split3_train_score   -0.726949   -0.669296\n",
       "rank_test_score              2           1\n",
       "split5_train_score   -0.721971   -0.665655\n",
       "param_C                      1           2\n",
       "split5_test_score    -0.778833   -0.763641\n",
       "mean_test_score      -0.761013   -0.744859\n",
       "std_fit_time          0.960552    0.801898\n",
       "std_test_score       0.0151279   0.0158491\n",
       "split4_test_score    -0.763854   -0.745524\n",
       "split7_test_score    -0.746911   -0.733738\n",
       "params                {'C': 1}    {'C': 2}\n",
       "split3_test_score    -0.732745   -0.716775\n",
       "split2_test_score    -0.781609   -0.766678\n",
       "split8_test_score    -0.749213   -0.729813\n",
       "mean_score_time      0.0409639   0.0384331\n",
       "std_train_score     0.00190128  0.00168143\n",
       "split0_test_score    -0.748923   -0.729591\n",
       "split8_train_score   -0.725785   -0.668251\n",
       "split6_train_score   -0.723485   -0.665978\n",
       "split4_train_score   -0.723411   -0.666713\n",
       "split9_train_score   -0.721882    -0.66555\n",
       "split1_test_score    -0.769909   -0.750672\n",
       "split6_test_score    -0.764248   -0.752555\n",
       "mean_fit_time          11.4154     12.9015\n",
       "split7_train_score   -0.724585    -0.66699\n",
       "std_score_time      0.00615676   0.0110444"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "predict(better_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36692, 4491)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "model = SelectFromModel(better_model.best_estimator_, prefit=True)\n",
    "x_train_lasso = model.transform(x_train)\n",
    "all_mat_lasso = model.transform(all_mat)\n",
    "x_train_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   6.5s\n",
      "[CV] .............................................. C=1, total=   6.7s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   6.8s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   6.8s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................................. C=1, total=   7.2s\n",
      "[CV] .............................................. C=1, total=   7.2s\n",
      "[CV] .............................................. C=1, total=   7.1s\n",
      "[CV] .............................................. C=1, total=   7.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=1 .............................................................\n",
      "[CV] C=2 .............................................................\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=1, total=   6.3s\n",
      "[CV] .............................................. C=1, total=   6.3s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.0s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.1s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.5s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.9s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.8s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.7s\n",
      "[CV] C=2 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.4s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.2s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.1s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=2, total=   7.3s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=   8.9s\n",
      "[CV] .............................................. C=3, total=   9.2s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=   8.5s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=   8.5s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=   7.2s\n",
      "[CV] .............................................. C=3, total=   7.0s\n",
      "[CV] C=3 .............................................................\n",
      "[CV] C=3 .............................................................\n",
      "[CV] .............................................. C=3, total=   7.3s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=3, total=   7.2s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=3, total=   7.4s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=3, total=   7.5s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   7.7s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   7.8s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   7.8s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   8.0s\n",
      "[CV] C=4 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................................. C=4, total=   8.0s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   8.2s\n",
      "[CV] C=4 .............................................................\n",
      "[CV] .............................................. C=4, total=   8.3s\n",
      "[CV] .............................................. C=4, total=   8.2s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=4, total=   8.3s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=4, total=   8.3s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.2s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.3s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.2s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=   9.8s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  11.1s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  11.2s\n",
      "[CV] C=5 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.6s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.8s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=5, total=  10.0s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=5, total=   9.9s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.0s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.1s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=   9.6s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.1s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.1s\n",
      "[CV] .............................................. C=6, total=  10.0s\n",
      "[CV] C=6 .............................................................\n",
      "[CV] C=6 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.1s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=6, total=   9.9s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.2s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=6, total=  10.6s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.3s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.7s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.3s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.2s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.2s\n",
      "[CV] .............................................. C=7, total=   8.8s\n",
      "[CV] C=7 .............................................................\n",
      "[CV] C=7 .............................................................\n",
      "[CV] .............................................. C=7, total=   9.2s\n",
      "[CV] .............................................. C=7, total=   9.0s\n",
      "[CV] .............................................. C=7, total=   5.7s\n",
      "[CV] .............................................. C=7, total=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  70 out of  70 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'C': [1, 2, 3, 4, 5, 6, 7]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x111ee2e18>, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge again\n",
    "param_grid = {'C': [1,2,3,4,5,6,7]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False), param_grid, \n",
    "                            scoring=score, cv=10, n_jobs=4, verbose=2)\n",
    "better_model.fit(x_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 4491).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.72218</td>\n",
       "      <td>-0.682696</td>\n",
       "      <td>-0.662381</td>\n",
       "      <td>-0.649092</td>\n",
       "      <td>-0.639348</td>\n",
       "      <td>-0.631747</td>\n",
       "      <td>-0.625625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.719616</td>\n",
       "      <td>-0.679875</td>\n",
       "      <td>-0.659451</td>\n",
       "      <td>-0.64609</td>\n",
       "      <td>-0.636292</td>\n",
       "      <td>-0.628659</td>\n",
       "      <td>-0.622499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.718722</td>\n",
       "      <td>-0.679206</td>\n",
       "      <td>-0.658869</td>\n",
       "      <td>-0.645528</td>\n",
       "      <td>-0.635735</td>\n",
       "      <td>-0.628107</td>\n",
       "      <td>-0.621935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.71741</td>\n",
       "      <td>-0.677564</td>\n",
       "      <td>-0.657099</td>\n",
       "      <td>-0.643707</td>\n",
       "      <td>-0.633894</td>\n",
       "      <td>-0.626252</td>\n",
       "      <td>-0.620118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_score</th>\n",
       "      <td>-0.783217</td>\n",
       "      <td>-0.762796</td>\n",
       "      <td>-0.755315</td>\n",
       "      <td>-0.75171</td>\n",
       "      <td>-0.749753</td>\n",
       "      <td>-0.748678</td>\n",
       "      <td>-0.748108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.721923</td>\n",
       "      <td>-0.682102</td>\n",
       "      <td>-0.661619</td>\n",
       "      <td>-0.648232</td>\n",
       "      <td>-0.638414</td>\n",
       "      <td>-0.630755</td>\n",
       "      <td>-0.624592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_score</th>\n",
       "      <td>-0.71788</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>-0.657618</td>\n",
       "      <td>-0.644256</td>\n",
       "      <td>-0.634455</td>\n",
       "      <td>-0.626824</td>\n",
       "      <td>-0.620674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_score</th>\n",
       "      <td>-0.783472</td>\n",
       "      <td>-0.76642</td>\n",
       "      <td>-0.761158</td>\n",
       "      <td>-0.759311</td>\n",
       "      <td>-0.758868</td>\n",
       "      <td>-0.759118</td>\n",
       "      <td>-0.759754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.768441</td>\n",
       "      <td>-0.748079</td>\n",
       "      <td>-0.740937</td>\n",
       "      <td>-0.737734</td>\n",
       "      <td>-0.736207</td>\n",
       "      <td>-0.735557</td>\n",
       "      <td>-0.735393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.326317</td>\n",
       "      <td>0.301859</td>\n",
       "      <td>0.770779</td>\n",
       "      <td>0.194304</td>\n",
       "      <td>0.475124</td>\n",
       "      <td>0.236608</td>\n",
       "      <td>1.36852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0138495</td>\n",
       "      <td>0.0149861</td>\n",
       "      <td>0.0155703</td>\n",
       "      <td>0.0159415</td>\n",
       "      <td>0.0162108</td>\n",
       "      <td>0.0164285</td>\n",
       "      <td>0.0166225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.766772</td>\n",
       "      <td>-0.745867</td>\n",
       "      <td>-0.738039</td>\n",
       "      <td>-0.734125</td>\n",
       "      <td>-0.731903</td>\n",
       "      <td>-0.73058</td>\n",
       "      <td>-0.729798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_score</th>\n",
       "      <td>-0.755707</td>\n",
       "      <td>-0.735273</td>\n",
       "      <td>-0.728343</td>\n",
       "      <td>-0.725418</td>\n",
       "      <td>-0.724184</td>\n",
       "      <td>-0.723833</td>\n",
       "      <td>-0.723931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>{'C': 2}</td>\n",
       "      <td>{'C': 3}</td>\n",
       "      <td>{'C': 4}</td>\n",
       "      <td>{'C': 5}</td>\n",
       "      <td>{'C': 6}</td>\n",
       "      <td>{'C': 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.745848</td>\n",
       "      <td>-0.725049</td>\n",
       "      <td>-0.717912</td>\n",
       "      <td>-0.714792</td>\n",
       "      <td>-0.713355</td>\n",
       "      <td>-0.712797</td>\n",
       "      <td>-0.712664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.789319</td>\n",
       "      <td>-0.769908</td>\n",
       "      <td>-0.763068</td>\n",
       "      <td>-0.759901</td>\n",
       "      <td>-0.758295</td>\n",
       "      <td>-0.757531</td>\n",
       "      <td>-0.757239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_score</th>\n",
       "      <td>-0.757537</td>\n",
       "      <td>-0.735185</td>\n",
       "      <td>-0.72675</td>\n",
       "      <td>-0.722639</td>\n",
       "      <td>-0.720421</td>\n",
       "      <td>-0.719206</td>\n",
       "      <td>-0.718564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0400382</td>\n",
       "      <td>0.0486199</td>\n",
       "      <td>0.0348747</td>\n",
       "      <td>0.044506</td>\n",
       "      <td>0.0393154</td>\n",
       "      <td>0.0416899</td>\n",
       "      <td>0.0373652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00163954</td>\n",
       "      <td>0.00168154</td>\n",
       "      <td>0.0016851</td>\n",
       "      <td>0.00168525</td>\n",
       "      <td>0.0016834</td>\n",
       "      <td>0.00168057</td>\n",
       "      <td>0.00167398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.754982</td>\n",
       "      <td>-0.731929</td>\n",
       "      <td>-0.723446</td>\n",
       "      <td>-0.719437</td>\n",
       "      <td>-0.717371</td>\n",
       "      <td>-0.716311</td>\n",
       "      <td>-0.715858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_score</th>\n",
       "      <td>-0.720965</td>\n",
       "      <td>-0.681217</td>\n",
       "      <td>-0.660744</td>\n",
       "      <td>-0.647335</td>\n",
       "      <td>-0.637497</td>\n",
       "      <td>-0.62985</td>\n",
       "      <td>-0.623629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_score</th>\n",
       "      <td>-0.718749</td>\n",
       "      <td>-0.678858</td>\n",
       "      <td>-0.658388</td>\n",
       "      <td>-0.645011</td>\n",
       "      <td>-0.635222</td>\n",
       "      <td>-0.627568</td>\n",
       "      <td>-0.621417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.7195</td>\n",
       "      <td>-0.679768</td>\n",
       "      <td>-0.65939</td>\n",
       "      <td>-0.64608</td>\n",
       "      <td>-0.636331</td>\n",
       "      <td>-0.628751</td>\n",
       "      <td>-0.622622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_score</th>\n",
       "      <td>-0.718068</td>\n",
       "      <td>-0.67835</td>\n",
       "      <td>-0.657989</td>\n",
       "      <td>-0.64469</td>\n",
       "      <td>-0.634937</td>\n",
       "      <td>-0.627353</td>\n",
       "      <td>-0.621214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.772126</td>\n",
       "      <td>-0.751421</td>\n",
       "      <td>-0.744231</td>\n",
       "      <td>-0.741164</td>\n",
       "      <td>-0.739882</td>\n",
       "      <td>-0.739509</td>\n",
       "      <td>-0.73966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_score</th>\n",
       "      <td>-0.775428</td>\n",
       "      <td>-0.756947</td>\n",
       "      <td>-0.751113</td>\n",
       "      <td>-0.748843</td>\n",
       "      <td>-0.748039</td>\n",
       "      <td>-0.748009</td>\n",
       "      <td>-0.74836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>6.74571</td>\n",
       "      <td>7.36033</td>\n",
       "      <td>7.82446</td>\n",
       "      <td>8.02284</td>\n",
       "      <td>10.3672</td>\n",
       "      <td>10.0172</td>\n",
       "      <td>8.48424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_score</th>\n",
       "      <td>-0.720766</td>\n",
       "      <td>-0.680929</td>\n",
       "      <td>-0.660418</td>\n",
       "      <td>-0.646967</td>\n",
       "      <td>-0.637086</td>\n",
       "      <td>-0.629385</td>\n",
       "      <td>-0.623161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00899257</td>\n",
       "      <td>0.0166799</td>\n",
       "      <td>0.00273868</td>\n",
       "      <td>0.0116208</td>\n",
       "      <td>0.0063061</td>\n",
       "      <td>0.00638945</td>\n",
       "      <td>0.0134648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0           1           2           3          4  \\\n",
       "split0_train_score    -0.72218   -0.682696   -0.662381   -0.649092  -0.639348   \n",
       "mean_train_score     -0.719616   -0.679875   -0.659451    -0.64609  -0.636292   \n",
       "split1_train_score   -0.718722   -0.679206   -0.658869   -0.645528  -0.635735   \n",
       "split2_train_score    -0.71741   -0.677564   -0.657099   -0.643707  -0.633894   \n",
       "split9_test_score    -0.783217   -0.762796   -0.755315    -0.75171  -0.749753   \n",
       "split3_train_score   -0.721923   -0.682102   -0.661619   -0.648232  -0.638414   \n",
       "rank_test_score              7           6           5           4          3   \n",
       "split5_train_score    -0.71788   -0.678062   -0.657618   -0.644256  -0.634455   \n",
       "param_C                      1           2           3           4          5   \n",
       "split5_test_score    -0.783472    -0.76642   -0.761158   -0.759311  -0.758868   \n",
       "mean_test_score      -0.768441   -0.748079   -0.740937   -0.737734  -0.736207   \n",
       "std_fit_time          0.326317    0.301859    0.770779    0.194304   0.475124   \n",
       "std_test_score       0.0138495   0.0149861   0.0155703   0.0159415  0.0162108   \n",
       "split4_test_score    -0.766772   -0.745867   -0.738039   -0.734125  -0.731903   \n",
       "split7_test_score    -0.755707   -0.735273   -0.728343   -0.725418  -0.724184   \n",
       "params                {'C': 1}    {'C': 2}    {'C': 3}    {'C': 4}   {'C': 5}   \n",
       "split3_test_score    -0.745848   -0.725049   -0.717912   -0.714792  -0.713355   \n",
       "split2_test_score    -0.789319   -0.769908   -0.763068   -0.759901  -0.758295   \n",
       "split8_test_score    -0.757537   -0.735185    -0.72675   -0.722639  -0.720421   \n",
       "mean_score_time      0.0400382   0.0486199   0.0348747    0.044506  0.0393154   \n",
       "std_train_score     0.00163954  0.00168154   0.0016851  0.00168525  0.0016834   \n",
       "split0_test_score    -0.754982   -0.731929   -0.723446   -0.719437  -0.717371   \n",
       "split8_train_score   -0.720965   -0.681217   -0.660744   -0.647335  -0.637497   \n",
       "split6_train_score   -0.718749   -0.678858   -0.658388   -0.645011  -0.635222   \n",
       "split4_train_score     -0.7195   -0.679768    -0.65939    -0.64608  -0.636331   \n",
       "split9_train_score   -0.718068    -0.67835   -0.657989    -0.64469  -0.634937   \n",
       "split1_test_score    -0.772126   -0.751421   -0.744231   -0.741164  -0.739882   \n",
       "split6_test_score    -0.775428   -0.756947   -0.751113   -0.748843  -0.748039   \n",
       "mean_fit_time          6.74571     7.36033     7.82446     8.02284    10.3672   \n",
       "split7_train_score   -0.720766   -0.680929   -0.660418   -0.646967  -0.637086   \n",
       "std_score_time      0.00899257   0.0166799  0.00273868   0.0116208  0.0063061   \n",
       "\n",
       "                             5           6  \n",
       "split0_train_score   -0.631747   -0.625625  \n",
       "mean_train_score     -0.628659   -0.622499  \n",
       "split1_train_score   -0.628107   -0.621935  \n",
       "split2_train_score   -0.626252   -0.620118  \n",
       "split9_test_score    -0.748678   -0.748108  \n",
       "split3_train_score   -0.630755   -0.624592  \n",
       "rank_test_score              2           1  \n",
       "split5_train_score   -0.626824   -0.620674  \n",
       "param_C                      6           7  \n",
       "split5_test_score    -0.759118   -0.759754  \n",
       "mean_test_score      -0.735557   -0.735393  \n",
       "std_fit_time          0.236608     1.36852  \n",
       "std_test_score       0.0164285   0.0166225  \n",
       "split4_test_score     -0.73058   -0.729798  \n",
       "split7_test_score    -0.723833   -0.723931  \n",
       "params                {'C': 6}    {'C': 7}  \n",
       "split3_test_score    -0.712797   -0.712664  \n",
       "split2_test_score    -0.757531   -0.757239  \n",
       "split8_test_score    -0.719206   -0.718564  \n",
       "mean_score_time      0.0416899   0.0373652  \n",
       "std_train_score     0.00168057  0.00167398  \n",
       "split0_test_score    -0.716311   -0.715858  \n",
       "split8_train_score    -0.62985   -0.623629  \n",
       "split6_train_score   -0.627568   -0.621417  \n",
       "split4_train_score   -0.628751   -0.622622  \n",
       "split9_train_score   -0.627353   -0.621214  \n",
       "split1_test_score    -0.739509    -0.73966  \n",
       "split6_test_score    -0.748009    -0.74836  \n",
       "mean_fit_time          10.0172     8.48424  \n",
       "split7_train_score   -0.629385   -0.623161  \n",
       "std_score_time      0.00638945   0.0134648  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "predict(better_model, all_mat_lasso, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Store the selected data for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=4,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = LogisticRegression(C=2.0, n_jobs=4, penalty='l1', verbose=2)\n",
    "selection.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36692, 4492)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SelectFromModel(selection, prefit=True)\n",
    "x_train_lasso = model.transform(x_train)\n",
    "all_mat_lasso = model.transform(all_mat)\n",
    "x_train_lasso.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dump(all_mat_lasso, open('../../static/selected_matrix.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bigram Lasso Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then train using l2\n",
    "test_l2 = LogisticRegression(C=5, penalty='l2')\n",
    "test_l2.fit(x_train_lasso, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 4492).\n"
     ]
    }
   ],
   "source": [
    "predict(test_l2, all_mat_lasso, x_train.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x10c0e1158>, verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "sgd_params = {'alpha': [0.00006, 0.00007, 0.00008, 0.0001, 0.0005]}\n",
    "sgd_model = GridSearchCV(SGDClassifier(shuffle=True, loss='modified_huber'),\n",
    "                         sgd_params, scoring=score, cv = 5)                         \n",
    "sgd_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6e-05</th>\n",
       "      <th>7e-05</th>\n",
       "      <th>8e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.0005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.574542</td>\n",
       "      <td>-0.589012</td>\n",
       "      <td>-0.587406</td>\n",
       "      <td>-0.595712</td>\n",
       "      <td>-0.716125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.574316</td>\n",
       "      <td>-0.586945</td>\n",
       "      <td>-0.595621</td>\n",
       "      <td>-0.59893</td>\n",
       "      <td>-0.711091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.756563</td>\n",
       "      <td>-0.756287</td>\n",
       "      <td>-0.75367</td>\n",
       "      <td>-0.750614</td>\n",
       "      <td>-0.774099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.763204</td>\n",
       "      <td>-0.76766</td>\n",
       "      <td>-0.761005</td>\n",
       "      <td>-0.754212</td>\n",
       "      <td>-0.763631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 6e-05}</td>\n",
       "      <td>{'alpha': 7e-05}</td>\n",
       "      <td>{'alpha': 8e-05}</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>{'alpha': 0.0005}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.762246</td>\n",
       "      <td>-0.754813</td>\n",
       "      <td>-0.751523</td>\n",
       "      <td>-0.74805</td>\n",
       "      <td>-0.775385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.568673</td>\n",
       "      <td>-0.590607</td>\n",
       "      <td>-0.60309</td>\n",
       "      <td>-0.604274</td>\n",
       "      <td>-0.70056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.787739</td>\n",
       "      <td>-0.768838</td>\n",
       "      <td>-0.764954</td>\n",
       "      <td>-0.754679</td>\n",
       "      <td>-0.776021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00162737</td>\n",
       "      <td>0.00867866</td>\n",
       "      <td>0.00452666</td>\n",
       "      <td>0.00461911</td>\n",
       "      <td>0.00259714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0356758</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>0.0389824</td>\n",
       "      <td>0.0373866</td>\n",
       "      <td>0.0363467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.574711</td>\n",
       "      <td>-0.580125</td>\n",
       "      <td>-0.584402</td>\n",
       "      <td>-0.596663</td>\n",
       "      <td>-0.71603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.764977</td>\n",
       "      <td>-0.754219</td>\n",
       "      <td>-0.75388</td>\n",
       "      <td>-0.74428</td>\n",
       "      <td>-0.767172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0489808</td>\n",
       "      <td>0.0115993</td>\n",
       "      <td>0.0608518</td>\n",
       "      <td>0.0378062</td>\n",
       "      <td>0.0161446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.766946</td>\n",
       "      <td>-0.760363</td>\n",
       "      <td>-0.757006</td>\n",
       "      <td>-0.750367</td>\n",
       "      <td>-0.771261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00377252</td>\n",
       "      <td>0.00465005</td>\n",
       "      <td>0.00876307</td>\n",
       "      <td>0.0078157</td>\n",
       "      <td>0.00601935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0107715</td>\n",
       "      <td>0.00648431</td>\n",
       "      <td>0.0051015</td>\n",
       "      <td>0.0038953</td>\n",
       "      <td>0.00495258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.580467</td>\n",
       "      <td>-0.582837</td>\n",
       "      <td>-0.595981</td>\n",
       "      <td>-0.58757</td>\n",
       "      <td>-0.708179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.573187</td>\n",
       "      <td>-0.592146</td>\n",
       "      <td>-0.607227</td>\n",
       "      <td>-0.610433</td>\n",
       "      <td>-0.714561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.306614</td>\n",
       "      <td>0.283898</td>\n",
       "      <td>0.34856</td>\n",
       "      <td>0.337727</td>\n",
       "      <td>0.295443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>6e-05</td>\n",
       "      <td>7e-05</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0.00006           0.00007           0.00008  \\\n",
       "split1_train_score         -0.574542         -0.589012         -0.587406   \n",
       "mean_train_score           -0.574316         -0.586945         -0.595621   \n",
       "split1_test_score          -0.756563         -0.756287          -0.75367   \n",
       "split3_test_score          -0.763204          -0.76766         -0.761005   \n",
       "params              {'alpha': 6e-05}  {'alpha': 7e-05}  {'alpha': 8e-05}   \n",
       "split4_test_score          -0.762246         -0.754813         -0.751523   \n",
       "split3_train_score         -0.568673         -0.590607          -0.60309   \n",
       "split2_test_score          -0.787739         -0.768838         -0.764954   \n",
       "std_score_time            0.00162737        0.00867866        0.00452666   \n",
       "mean_score_time            0.0356758          0.038696         0.0389824   \n",
       "split4_train_score         -0.574711         -0.580125         -0.584402   \n",
       "split0_test_score          -0.764977         -0.754219          -0.75388   \n",
       "std_fit_time               0.0489808         0.0115993         0.0608518   \n",
       "mean_test_score            -0.766946         -0.760363         -0.757006   \n",
       "std_train_score           0.00377252        0.00465005        0.00876307   \n",
       "std_test_score             0.0107715        0.00648431         0.0051015   \n",
       "split2_train_score         -0.580467         -0.582837         -0.595981   \n",
       "split0_train_score         -0.573187         -0.592146         -0.607227   \n",
       "mean_fit_time               0.306614          0.283898           0.34856   \n",
       "rank_test_score                    4                 3                 2   \n",
       "param_alpha                    6e-05             7e-05             8e-05   \n",
       "\n",
       "                              0.00010            0.00050  \n",
       "split1_train_score          -0.595712          -0.716125  \n",
       "mean_train_score             -0.59893          -0.711091  \n",
       "split1_test_score           -0.750614          -0.774099  \n",
       "split3_test_score           -0.754212          -0.763631  \n",
       "params              {'alpha': 0.0001}  {'alpha': 0.0005}  \n",
       "split4_test_score            -0.74805          -0.775385  \n",
       "split3_train_score          -0.604274           -0.70056  \n",
       "split2_test_score           -0.754679          -0.776021  \n",
       "std_score_time             0.00461911         0.00259714  \n",
       "mean_score_time             0.0373866          0.0363467  \n",
       "split4_train_score          -0.596663           -0.71603  \n",
       "split0_test_score            -0.74428          -0.767172  \n",
       "std_fit_time                0.0378062          0.0161446  \n",
       "mean_test_score             -0.750367          -0.771261  \n",
       "std_train_score             0.0078157         0.00601935  \n",
       "std_test_score              0.0038953         0.00495258  \n",
       "split2_train_score           -0.58757          -0.708179  \n",
       "split0_train_score          -0.610433          -0.714561  \n",
       "mean_fit_time                0.337727           0.295443  \n",
       "rank_test_score                     1                  5  \n",
       "param_alpha                    0.0001             0.0005  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(sgd_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.00006, 0.00007, 0.00008, 0.0001, 0.0005]\n",
    "predict(sgd_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.1, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "ela_aphpa = {'alpha': [0.001, 0.01, 0.1, 1, 5, 10]}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.54939</td>\n",
       "      <td>0.527386</td>\n",
       "      <td>0.565256</td>\n",
       "      <td>0.492988</td>\n",
       "      <td>0.511567</td>\n",
       "      <td>0.495162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0346206</td>\n",
       "      <td>0.0357868</td>\n",
       "      <td>0.0368364</td>\n",
       "      <td>0.0354168</td>\n",
       "      <td>0.0364533</td>\n",
       "      <td>0.0345582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00383276</td>\n",
       "      <td>0.00168446</td>\n",
       "      <td>0.00260632</td>\n",
       "      <td>0.00201341</td>\n",
       "      <td>0.00167451</td>\n",
       "      <td>0.00189142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.11324</td>\n",
       "      <td>-1.29806</td>\n",
       "      <td>-1.41389</td>\n",
       "      <td>-1.45128</td>\n",
       "      <td>-1.45459</td>\n",
       "      <td>-1.45491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.10981</td>\n",
       "      <td>-1.29782</td>\n",
       "      <td>-1.41301</td>\n",
       "      <td>-1.45144</td>\n",
       "      <td>-1.4544</td>\n",
       "      <td>-1.4547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-1.10718</td>\n",
       "      <td>-1.29759</td>\n",
       "      <td>-1.41301</td>\n",
       "      <td>-1.45144</td>\n",
       "      <td>-1.4544</td>\n",
       "      <td>-1.4547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00242824</td>\n",
       "      <td>0.000307041</td>\n",
       "      <td>0.000814103</td>\n",
       "      <td>0.000338604</td>\n",
       "      <td>0.000447177</td>\n",
       "      <td>0.000259863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>{'alpha': 5}</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000570091</td>\n",
       "      <td>0.00109986</td>\n",
       "      <td>0.000742439</td>\n",
       "      <td>0.000370183</td>\n",
       "      <td>0.000479539</td>\n",
       "      <td>0.000243307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.10863</td>\n",
       "      <td>-1.29747</td>\n",
       "      <td>-1.41301</td>\n",
       "      <td>-1.45155</td>\n",
       "      <td>-1.45407</td>\n",
       "      <td>-1.45486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-1.10742</td>\n",
       "      <td>-1.29657</td>\n",
       "      <td>-1.41288</td>\n",
       "      <td>-1.4509</td>\n",
       "      <td>-1.45362</td>\n",
       "      <td>-1.45481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-1.10779</td>\n",
       "      <td>-1.2979</td>\n",
       "      <td>-1.41307</td>\n",
       "      <td>-1.45159</td>\n",
       "      <td>-1.45411</td>\n",
       "      <td>-1.4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-1.10623</td>\n",
       "      <td>-1.29698</td>\n",
       "      <td>-1.41391</td>\n",
       "      <td>-1.45125</td>\n",
       "      <td>-1.45455</td>\n",
       "      <td>-1.45487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.11113</td>\n",
       "      <td>-1.29813</td>\n",
       "      <td>-1.41347</td>\n",
       "      <td>-1.45137</td>\n",
       "      <td>-1.45476</td>\n",
       "      <td>-1.45459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-1.10684</td>\n",
       "      <td>-1.29689</td>\n",
       "      <td>-1.41347</td>\n",
       "      <td>-1.45145</td>\n",
       "      <td>-1.45484</td>\n",
       "      <td>-1.45466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.106</td>\n",
       "      <td>-1.29801</td>\n",
       "      <td>-1.41149</td>\n",
       "      <td>-1.45201</td>\n",
       "      <td>-1.45489</td>\n",
       "      <td>-1.45423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-1.10761</td>\n",
       "      <td>-1.2996</td>\n",
       "      <td>-1.4117</td>\n",
       "      <td>-1.45202</td>\n",
       "      <td>-1.45489</td>\n",
       "      <td>-1.45424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0555808</td>\n",
       "      <td>0.0538461</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.0149393</td>\n",
       "      <td>0.0331419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.11008</td>\n",
       "      <td>-1.29741</td>\n",
       "      <td>-1.41318</td>\n",
       "      <td>-1.45098</td>\n",
       "      <td>-1.4537</td>\n",
       "      <td>-1.45489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0.001            0.010           0.100   \\\n",
       "mean_fit_time                0.54939         0.527386        0.565256   \n",
       "mean_score_time            0.0346206        0.0357868       0.0368364   \n",
       "std_score_time            0.00383276       0.00168446      0.00260632   \n",
       "split2_test_score           -1.11324         -1.29806        -1.41389   \n",
       "mean_test_score             -1.10981         -1.29782        -1.41301   \n",
       "mean_train_score            -1.10718         -1.29759        -1.41301   \n",
       "std_test_score            0.00242824      0.000307041     0.000814103   \n",
       "params              {'alpha': 0.001}  {'alpha': 0.01}  {'alpha': 0.1}   \n",
       "std_train_score          0.000570091       0.00109986     0.000742439   \n",
       "split0_test_score           -1.10863         -1.29747        -1.41301   \n",
       "split1_train_score          -1.10742         -1.29657        -1.41288   \n",
       "split0_train_score          -1.10779          -1.2979        -1.41307   \n",
       "rank_test_score                    1                2               3   \n",
       "split2_train_score          -1.10623         -1.29698        -1.41391   \n",
       "split3_test_score           -1.11113         -1.29813        -1.41347   \n",
       "split3_train_score          -1.10684         -1.29689        -1.41347   \n",
       "split4_test_score             -1.106         -1.29801        -1.41149   \n",
       "split4_train_score          -1.10761          -1.2996         -1.4117   \n",
       "std_fit_time               0.0555808        0.0538461        0.151127   \n",
       "param_alpha                    0.001             0.01             0.1   \n",
       "split1_test_score           -1.11008         -1.29741        -1.41318   \n",
       "\n",
       "                          1.000         5.000          10.000  \n",
       "mean_fit_time           0.492988      0.511567       0.495162  \n",
       "mean_score_time        0.0354168     0.0364533      0.0345582  \n",
       "std_score_time        0.00201341    0.00167451     0.00189142  \n",
       "split2_test_score       -1.45128      -1.45459       -1.45491  \n",
       "mean_test_score         -1.45144       -1.4544        -1.4547  \n",
       "mean_train_score        -1.45144       -1.4544        -1.4547  \n",
       "std_test_score       0.000338604   0.000447177    0.000259863  \n",
       "params              {'alpha': 1}  {'alpha': 5}  {'alpha': 10}  \n",
       "std_train_score      0.000370183   0.000479539    0.000243307  \n",
       "split0_test_score       -1.45155      -1.45407       -1.45486  \n",
       "split1_train_score       -1.4509      -1.45362       -1.45481  \n",
       "split0_train_score      -1.45159      -1.45411        -1.4549  \n",
       "rank_test_score                4             5              6  \n",
       "split2_train_score      -1.45125      -1.45455       -1.45487  \n",
       "split3_test_score       -1.45137      -1.45476       -1.45459  \n",
       "split3_train_score      -1.45145      -1.45484       -1.45466  \n",
       "split4_test_score       -1.45201      -1.45489       -1.45423  \n",
       "split4_train_score      -1.45202      -1.45489       -1.45424  \n",
       "std_fit_time            0.023331     0.0149393      0.0331419  \n",
       "param_alpha                    1             5             10  \n",
       "split1_test_score       -1.45098       -1.4537       -1.45489  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.001, 0.01, 0.1, 1, 5, 10]\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems we need much smaller alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1e-05, 0.0001, 0.001, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_aphpa = {'alpha': [0.00001, 0.0001, 0.001, 0.01]}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-05</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.641025</td>\n",
       "      <td>0.631433</td>\n",
       "      <td>0.624173</td>\n",
       "      <td>0.456832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0339981</td>\n",
       "      <td>0.0373268</td>\n",
       "      <td>0.0382773</td>\n",
       "      <td>0.0360988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00287751</td>\n",
       "      <td>0.00567963</td>\n",
       "      <td>0.00914808</td>\n",
       "      <td>0.00218135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.756885</td>\n",
       "      <td>-0.842876</td>\n",
       "      <td>-1.11286</td>\n",
       "      <td>-1.29859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.751819</td>\n",
       "      <td>-0.840097</td>\n",
       "      <td>-1.10969</td>\n",
       "      <td>-1.29784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.61945</td>\n",
       "      <td>-0.817305</td>\n",
       "      <td>-1.10712</td>\n",
       "      <td>-1.29761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00685984</td>\n",
       "      <td>0.00265796</td>\n",
       "      <td>0.00195302</td>\n",
       "      <td>0.000977789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0044917</td>\n",
       "      <td>0.00274837</td>\n",
       "      <td>0.00101267</td>\n",
       "      <td>0.000443439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.739788</td>\n",
       "      <td>-0.838169</td>\n",
       "      <td>-1.10846</td>\n",
       "      <td>-1.29655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.616324</td>\n",
       "      <td>-0.821262</td>\n",
       "      <td>-1.10704</td>\n",
       "      <td>-1.29771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.616393</td>\n",
       "      <td>-0.818058</td>\n",
       "      <td>-1.10779</td>\n",
       "      <td>-1.29698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.615138</td>\n",
       "      <td>-0.814425</td>\n",
       "      <td>-1.10601</td>\n",
       "      <td>-1.29752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.7594</td>\n",
       "      <td>-0.837505</td>\n",
       "      <td>-1.11031</td>\n",
       "      <td>-1.29872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.622688</td>\n",
       "      <td>-0.818796</td>\n",
       "      <td>-1.10611</td>\n",
       "      <td>-1.2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.753408</td>\n",
       "      <td>-0.83817</td>\n",
       "      <td>-1.10702</td>\n",
       "      <td>-1.29673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.626708</td>\n",
       "      <td>-0.813984</td>\n",
       "      <td>-1.10868</td>\n",
       "      <td>-1.29835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0540429</td>\n",
       "      <td>0.125262</td>\n",
       "      <td>0.0810916</td>\n",
       "      <td>0.00743751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.749619</td>\n",
       "      <td>-0.843765</td>\n",
       "      <td>-1.1098</td>\n",
       "      <td>-1.29858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0.00001            0.00010           0.00100  \\\n",
       "mean_fit_time               0.641025           0.631433          0.624173   \n",
       "mean_score_time            0.0339981          0.0373268         0.0382773   \n",
       "std_score_time            0.00287751         0.00567963        0.00914808   \n",
       "split2_test_score          -0.756885          -0.842876          -1.11286   \n",
       "mean_test_score            -0.751819          -0.840097          -1.10969   \n",
       "mean_train_score            -0.61945          -0.817305          -1.10712   \n",
       "std_test_score            0.00685984         0.00265796        0.00195302   \n",
       "params              {'alpha': 1e-05}  {'alpha': 0.0001}  {'alpha': 0.001}   \n",
       "std_train_score            0.0044917         0.00274837        0.00101267   \n",
       "split0_test_score          -0.739788          -0.838169          -1.10846   \n",
       "split1_train_score         -0.616324          -0.821262          -1.10704   \n",
       "split0_train_score         -0.616393          -0.818058          -1.10779   \n",
       "rank_test_score                    1                  2                 3   \n",
       "split2_train_score         -0.615138          -0.814425          -1.10601   \n",
       "split3_test_score            -0.7594          -0.837505          -1.11031   \n",
       "split3_train_score         -0.622688          -0.818796          -1.10611   \n",
       "split4_test_score          -0.753408           -0.83817          -1.10702   \n",
       "split4_train_score         -0.626708          -0.813984          -1.10868   \n",
       "std_fit_time               0.0540429           0.125262         0.0810916   \n",
       "param_alpha                    1e-05             0.0001             0.001   \n",
       "split1_test_score          -0.749619          -0.843765           -1.1098   \n",
       "\n",
       "                            0.01000  \n",
       "mean_fit_time              0.456832  \n",
       "mean_score_time           0.0360988  \n",
       "std_score_time           0.00218135  \n",
       "split2_test_score          -1.29859  \n",
       "mean_test_score            -1.29784  \n",
       "mean_train_score           -1.29761  \n",
       "std_test_score          0.000977789  \n",
       "params              {'alpha': 0.01}  \n",
       "std_train_score         0.000443439  \n",
       "split0_test_score          -1.29655  \n",
       "split1_train_score         -1.29771  \n",
       "split0_train_score         -1.29698  \n",
       "rank_test_score                   4  \n",
       "split2_train_score         -1.29752  \n",
       "split3_test_score          -1.29872  \n",
       "split3_train_score          -1.2975  \n",
       "split4_test_score          -1.29673  \n",
       "split4_train_score         -1.29835  \n",
       "std_fit_time             0.00743751  \n",
       "param_alpha                    0.01  \n",
       "split1_test_score          -1.29858  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0.00001, 0.0001, 0.001, 0.01]\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1e-08, 1e-07, 1e-06, 1e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_aphpa = {'alpha': [1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1e-07</th>\n",
       "      <th>1e-06</th>\n",
       "      <th>1e-05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.665506</td>\n",
       "      <td>0.773316</td>\n",
       "      <td>0.654345</td>\n",
       "      <td>0.621546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0359776</td>\n",
       "      <td>0.0373822</td>\n",
       "      <td>0.0347206</td>\n",
       "      <td>0.0349836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00136851</td>\n",
       "      <td>0.00294813</td>\n",
       "      <td>0.00186751</td>\n",
       "      <td>0.00265751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-1.05798</td>\n",
       "      <td>-1.02287</td>\n",
       "      <td>-0.881948</td>\n",
       "      <td>-0.761034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-1.04518</td>\n",
       "      <td>-1.00187</td>\n",
       "      <td>-0.854591</td>\n",
       "      <td>-0.750032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.680501</td>\n",
       "      <td>-0.650783</td>\n",
       "      <td>-0.510752</td>\n",
       "      <td>-0.618973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0337951</td>\n",
       "      <td>0.0245153</td>\n",
       "      <td>0.0160622</td>\n",
       "      <td>0.0071658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 1e-08}</td>\n",
       "      <td>{'alpha': 1e-07}</td>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0169347</td>\n",
       "      <td>0.0185159</td>\n",
       "      <td>0.0115786</td>\n",
       "      <td>0.0045002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-1.06017</td>\n",
       "      <td>-0.986569</td>\n",
       "      <td>-0.854782</td>\n",
       "      <td>-0.739714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.710005</td>\n",
       "      <td>-0.677256</td>\n",
       "      <td>-0.508222</td>\n",
       "      <td>-0.624533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.680602</td>\n",
       "      <td>-0.646466</td>\n",
       "      <td>-0.532615</td>\n",
       "      <td>-0.61422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.683619</td>\n",
       "      <td>-0.628637</td>\n",
       "      <td>-0.498086</td>\n",
       "      <td>-0.619111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-1.00476</td>\n",
       "      <td>-1.03166</td>\n",
       "      <td>-0.852158</td>\n",
       "      <td>-0.7473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.661116</td>\n",
       "      <td>-0.666657</td>\n",
       "      <td>-0.506139</td>\n",
       "      <td>-0.613637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-1.00899</td>\n",
       "      <td>-0.963958</td>\n",
       "      <td>-0.831535</td>\n",
       "      <td>-0.747923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.667162</td>\n",
       "      <td>-0.634898</td>\n",
       "      <td>-0.508699</td>\n",
       "      <td>-0.623362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0437416</td>\n",
       "      <td>0.126891</td>\n",
       "      <td>0.0188493</td>\n",
       "      <td>0.0285964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>1e-08</td>\n",
       "      <td>1e-07</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-1.09395</td>\n",
       "      <td>-1.00427</td>\n",
       "      <td>-0.852526</td>\n",
       "      <td>-0.754191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0.000000e+00      1.000000e-07      1.000000e-06  \\\n",
       "mean_fit_time               0.665506          0.773316          0.654345   \n",
       "mean_score_time            0.0359776         0.0373822         0.0347206   \n",
       "std_score_time            0.00136851        0.00294813        0.00186751   \n",
       "split2_test_score           -1.05798          -1.02287         -0.881948   \n",
       "mean_test_score             -1.04518          -1.00187         -0.854591   \n",
       "mean_train_score           -0.680501         -0.650783         -0.510752   \n",
       "std_test_score             0.0337951         0.0245153         0.0160622   \n",
       "params              {'alpha': 1e-08}  {'alpha': 1e-07}  {'alpha': 1e-06}   \n",
       "std_train_score            0.0169347         0.0185159         0.0115786   \n",
       "split0_test_score           -1.06017         -0.986569         -0.854782   \n",
       "split1_train_score         -0.710005         -0.677256         -0.508222   \n",
       "split0_train_score         -0.680602         -0.646466         -0.532615   \n",
       "rank_test_score                    4                 3                 2   \n",
       "split2_train_score         -0.683619         -0.628637         -0.498086   \n",
       "split3_test_score           -1.00476          -1.03166         -0.852158   \n",
       "split3_train_score         -0.661116         -0.666657         -0.506139   \n",
       "split4_test_score           -1.00899         -0.963958         -0.831535   \n",
       "split4_train_score         -0.667162         -0.634898         -0.508699   \n",
       "std_fit_time               0.0437416          0.126891         0.0188493   \n",
       "param_alpha                    1e-08             1e-07             1e-06   \n",
       "split1_test_score           -1.09395          -1.00427         -0.852526   \n",
       "\n",
       "                        1.000000e-05  \n",
       "mean_fit_time               0.621546  \n",
       "mean_score_time            0.0349836  \n",
       "std_score_time            0.00265751  \n",
       "split2_test_score          -0.761034  \n",
       "mean_test_score            -0.750032  \n",
       "mean_train_score           -0.618973  \n",
       "std_test_score             0.0071658  \n",
       "params              {'alpha': 1e-05}  \n",
       "std_train_score            0.0045002  \n",
       "split0_test_score          -0.739714  \n",
       "split1_train_score         -0.624533  \n",
       "split0_train_score          -0.61422  \n",
       "rank_test_score                    1  \n",
       "split2_train_score         -0.619111  \n",
       "split3_test_score            -0.7473  \n",
       "split3_train_score         -0.613637  \n",
       "split4_test_score          -0.747923  \n",
       "split4_train_score         -0.623362  \n",
       "std_fit_time               0.0285964  \n",
       "param_alpha                    1e-05  \n",
       "split1_test_score          -0.754191  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = [0, 1e-7, 1e-6, 1e-5]\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-06,   1.20000e-05,   2.30000e-05,   3.40000e-05,\n",
       "         4.50000e-05,   5.60000e-05,   6.70000e-05,   7.80000e-05,\n",
       "         8.90000e-05,   1.00000e-04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_aphpa = {'alpha': np.linspace(1e-06, 1e-04, num=10)}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1e-06</th>\n",
       "      <th>1.2e-05</th>\n",
       "      <th>2.3e-05</th>\n",
       "      <th>3.4e-05</th>\n",
       "      <th>4.5e-05</th>\n",
       "      <th>5.6e-05</th>\n",
       "      <th>6.7e-05</th>\n",
       "      <th>7.8e-05</th>\n",
       "      <th>8.9e-05</th>\n",
       "      <th>0.0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.798895</td>\n",
       "      <td>0.667359</td>\n",
       "      <td>0.693477</td>\n",
       "      <td>0.609737</td>\n",
       "      <td>0.595307</td>\n",
       "      <td>0.575512</td>\n",
       "      <td>0.598852</td>\n",
       "      <td>0.59438</td>\n",
       "      <td>0.601583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0374146</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>0.036863</td>\n",
       "      <td>0.0386744</td>\n",
       "      <td>0.034585</td>\n",
       "      <td>0.0349566</td>\n",
       "      <td>0.0342207</td>\n",
       "      <td>0.0369718</td>\n",
       "      <td>0.036057</td>\n",
       "      <td>0.0387134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00391999</td>\n",
       "      <td>0.00357656</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.00498904</td>\n",
       "      <td>0.00296915</td>\n",
       "      <td>0.00188154</td>\n",
       "      <td>0.00153458</td>\n",
       "      <td>0.00299741</td>\n",
       "      <td>0.00434963</td>\n",
       "      <td>0.0071664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.875787</td>\n",
       "      <td>-0.76015</td>\n",
       "      <td>-0.771219</td>\n",
       "      <td>-0.778</td>\n",
       "      <td>-0.794257</td>\n",
       "      <td>-0.804994</td>\n",
       "      <td>-0.81287</td>\n",
       "      <td>-0.823748</td>\n",
       "      <td>-0.832429</td>\n",
       "      <td>-0.84412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.863589</td>\n",
       "      <td>-0.752425</td>\n",
       "      <td>-0.76271</td>\n",
       "      <td>-0.775311</td>\n",
       "      <td>-0.788959</td>\n",
       "      <td>-0.800098</td>\n",
       "      <td>-0.808022</td>\n",
       "      <td>-0.820812</td>\n",
       "      <td>-0.829947</td>\n",
       "      <td>-0.840404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.50858</td>\n",
       "      <td>-0.635684</td>\n",
       "      <td>-0.687578</td>\n",
       "      <td>-0.720061</td>\n",
       "      <td>-0.744616</td>\n",
       "      <td>-0.763165</td>\n",
       "      <td>-0.775688</td>\n",
       "      <td>-0.792393</td>\n",
       "      <td>-0.804676</td>\n",
       "      <td>-0.817439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0155493</td>\n",
       "      <td>0.0067757</td>\n",
       "      <td>0.00562278</td>\n",
       "      <td>0.00332753</td>\n",
       "      <td>0.00328717</td>\n",
       "      <td>0.0036531</td>\n",
       "      <td>0.00273596</td>\n",
       "      <td>0.00322317</td>\n",
       "      <td>0.00251226</td>\n",
       "      <td>0.0026939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 1e-06}</td>\n",
       "      <td>{'alpha': 1.2e-05}</td>\n",
       "      <td>{'alpha': 2.3e-05}</td>\n",
       "      <td>{'alpha': 3.4e-05}</td>\n",
       "      <td>{'alpha': 4.5e-05}</td>\n",
       "      <td>{'alpha': 5.6e-05}</td>\n",
       "      <td>{'alpha': 6.7e-05}</td>\n",
       "      <td>{'alpha': 7.8e-05}</td>\n",
       "      <td>{'alpha': 8.9e-05}</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0248748</td>\n",
       "      <td>0.00547491</td>\n",
       "      <td>0.00328355</td>\n",
       "      <td>0.00595362</td>\n",
       "      <td>0.00171524</td>\n",
       "      <td>0.00284345</td>\n",
       "      <td>0.00124989</td>\n",
       "      <td>0.0025222</td>\n",
       "      <td>0.00242386</td>\n",
       "      <td>0.00109798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.870658</td>\n",
       "      <td>-0.741843</td>\n",
       "      <td>-0.754862</td>\n",
       "      <td>-0.77227</td>\n",
       "      <td>-0.786484</td>\n",
       "      <td>-0.79616</td>\n",
       "      <td>-0.805458</td>\n",
       "      <td>-0.81809</td>\n",
       "      <td>-0.830095</td>\n",
       "      <td>-0.838175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.503129</td>\n",
       "      <td>-0.630032</td>\n",
       "      <td>-0.693667</td>\n",
       "      <td>-0.726825</td>\n",
       "      <td>-0.744329</td>\n",
       "      <td>-0.767991</td>\n",
       "      <td>-0.77505</td>\n",
       "      <td>-0.796959</td>\n",
       "      <td>-0.803295</td>\n",
       "      <td>-0.816628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.557159</td>\n",
       "      <td>-0.635188</td>\n",
       "      <td>-0.687253</td>\n",
       "      <td>-0.724046</td>\n",
       "      <td>-0.74731</td>\n",
       "      <td>-0.763887</td>\n",
       "      <td>-0.777192</td>\n",
       "      <td>-0.792779</td>\n",
       "      <td>-0.808118</td>\n",
       "      <td>-0.817945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.498565</td>\n",
       "      <td>-0.629817</td>\n",
       "      <td>-0.687234</td>\n",
       "      <td>-0.712998</td>\n",
       "      <td>-0.742736</td>\n",
       "      <td>-0.761305</td>\n",
       "      <td>-0.774295</td>\n",
       "      <td>-0.789432</td>\n",
       "      <td>-0.801131</td>\n",
       "      <td>-0.815742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.870468</td>\n",
       "      <td>-0.754819</td>\n",
       "      <td>-0.760724</td>\n",
       "      <td>-0.775102</td>\n",
       "      <td>-0.785224</td>\n",
       "      <td>-0.796849</td>\n",
       "      <td>-0.805663</td>\n",
       "      <td>-0.816314</td>\n",
       "      <td>-0.82621</td>\n",
       "      <td>-0.837084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.486752</td>\n",
       "      <td>-0.63934</td>\n",
       "      <td>-0.685852</td>\n",
       "      <td>-0.723644</td>\n",
       "      <td>-0.742994</td>\n",
       "      <td>-0.763103</td>\n",
       "      <td>-0.77719</td>\n",
       "      <td>-0.791568</td>\n",
       "      <td>-0.804431</td>\n",
       "      <td>-0.818103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.832889</td>\n",
       "      <td>-0.757761</td>\n",
       "      <td>-0.760273</td>\n",
       "      <td>-0.771193</td>\n",
       "      <td>-0.79107</td>\n",
       "      <td>-0.798593</td>\n",
       "      <td>-0.809005</td>\n",
       "      <td>-0.821151</td>\n",
       "      <td>-0.832825</td>\n",
       "      <td>-0.842872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.497294</td>\n",
       "      <td>-0.644044</td>\n",
       "      <td>-0.683886</td>\n",
       "      <td>-0.71279</td>\n",
       "      <td>-0.745711</td>\n",
       "      <td>-0.759539</td>\n",
       "      <td>-0.774715</td>\n",
       "      <td>-0.791225</td>\n",
       "      <td>-0.806407</td>\n",
       "      <td>-0.818778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0405396</td>\n",
       "      <td>0.133948</td>\n",
       "      <td>0.0914395</td>\n",
       "      <td>0.0625646</td>\n",
       "      <td>0.0413219</td>\n",
       "      <td>0.0128864</td>\n",
       "      <td>0.0182418</td>\n",
       "      <td>0.0157395</td>\n",
       "      <td>0.0603916</td>\n",
       "      <td>0.072123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>1.2e-05</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>3.4e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "      <td>5.6e-05</td>\n",
       "      <td>6.7e-05</td>\n",
       "      <td>7.8e-05</td>\n",
       "      <td>8.9e-05</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.868131</td>\n",
       "      <td>-0.74756</td>\n",
       "      <td>-0.766474</td>\n",
       "      <td>-0.779989</td>\n",
       "      <td>-0.787762</td>\n",
       "      <td>-0.803895</td>\n",
       "      <td>-0.807114</td>\n",
       "      <td>-0.824758</td>\n",
       "      <td>-0.828177</td>\n",
       "      <td>-0.83977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.000001            0.000012            0.000023  \\\n",
       "mean_fit_time               0.695885            0.798895            0.667359   \n",
       "mean_score_time            0.0374146            0.040598            0.036863   \n",
       "std_score_time            0.00391999          0.00357656            0.004885   \n",
       "split2_test_score          -0.875787            -0.76015           -0.771219   \n",
       "mean_test_score            -0.863589           -0.752425            -0.76271   \n",
       "mean_train_score            -0.50858           -0.635684           -0.687578   \n",
       "std_test_score             0.0155493           0.0067757          0.00562278   \n",
       "params              {'alpha': 1e-06}  {'alpha': 1.2e-05}  {'alpha': 2.3e-05}   \n",
       "std_train_score            0.0248748          0.00547491          0.00328355   \n",
       "split0_test_score          -0.870658           -0.741843           -0.754862   \n",
       "split1_train_score         -0.503129           -0.630032           -0.693667   \n",
       "split0_train_score         -0.557159           -0.635188           -0.687253   \n",
       "rank_test_score                   10                   1                   2   \n",
       "split2_train_score         -0.498565           -0.629817           -0.687234   \n",
       "split3_test_score          -0.870468           -0.754819           -0.760724   \n",
       "split3_train_score         -0.486752            -0.63934           -0.685852   \n",
       "split4_test_score          -0.832889           -0.757761           -0.760273   \n",
       "split4_train_score         -0.497294           -0.644044           -0.683886   \n",
       "std_fit_time               0.0405396            0.133948           0.0914395   \n",
       "param_alpha                    1e-06             1.2e-05             2.3e-05   \n",
       "split1_test_score          -0.868131            -0.74756           -0.766474   \n",
       "\n",
       "                              0.000034            0.000045  \\\n",
       "mean_fit_time                 0.693477            0.609737   \n",
       "mean_score_time              0.0386744            0.034585   \n",
       "std_score_time              0.00498904          0.00296915   \n",
       "split2_test_score               -0.778           -0.794257   \n",
       "mean_test_score              -0.775311           -0.788959   \n",
       "mean_train_score             -0.720061           -0.744616   \n",
       "std_test_score              0.00332753          0.00328717   \n",
       "params              {'alpha': 3.4e-05}  {'alpha': 4.5e-05}   \n",
       "std_train_score             0.00595362          0.00171524   \n",
       "split0_test_score             -0.77227           -0.786484   \n",
       "split1_train_score           -0.726825           -0.744329   \n",
       "split0_train_score           -0.724046            -0.74731   \n",
       "rank_test_score                      3                   4   \n",
       "split2_train_score           -0.712998           -0.742736   \n",
       "split3_test_score            -0.775102           -0.785224   \n",
       "split3_train_score           -0.723644           -0.742994   \n",
       "split4_test_score            -0.771193            -0.79107   \n",
       "split4_train_score            -0.71279           -0.745711   \n",
       "std_fit_time                 0.0625646           0.0413219   \n",
       "param_alpha                    3.4e-05             4.5e-05   \n",
       "split1_test_score            -0.779989           -0.787762   \n",
       "\n",
       "                              0.000056            0.000067  \\\n",
       "mean_fit_time                 0.595307            0.575512   \n",
       "mean_score_time              0.0349566           0.0342207   \n",
       "std_score_time              0.00188154          0.00153458   \n",
       "split2_test_score            -0.804994            -0.81287   \n",
       "mean_test_score              -0.800098           -0.808022   \n",
       "mean_train_score             -0.763165           -0.775688   \n",
       "std_test_score               0.0036531          0.00273596   \n",
       "params              {'alpha': 5.6e-05}  {'alpha': 6.7e-05}   \n",
       "std_train_score             0.00284345          0.00124989   \n",
       "split0_test_score             -0.79616           -0.805458   \n",
       "split1_train_score           -0.767991            -0.77505   \n",
       "split0_train_score           -0.763887           -0.777192   \n",
       "rank_test_score                      5                   6   \n",
       "split2_train_score           -0.761305           -0.774295   \n",
       "split3_test_score            -0.796849           -0.805663   \n",
       "split3_train_score           -0.763103            -0.77719   \n",
       "split4_test_score            -0.798593           -0.809005   \n",
       "split4_train_score           -0.759539           -0.774715   \n",
       "std_fit_time                 0.0128864           0.0182418   \n",
       "param_alpha                    5.6e-05             6.7e-05   \n",
       "split1_test_score            -0.803895           -0.807114   \n",
       "\n",
       "                              0.000078            0.000089           0.000100  \n",
       "mean_fit_time                 0.598852             0.59438           0.601583  \n",
       "mean_score_time              0.0369718            0.036057          0.0387134  \n",
       "std_score_time              0.00299741          0.00434963          0.0071664  \n",
       "split2_test_score            -0.823748           -0.832429           -0.84412  \n",
       "mean_test_score              -0.820812           -0.829947          -0.840404  \n",
       "mean_train_score             -0.792393           -0.804676          -0.817439  \n",
       "std_test_score              0.00322317          0.00251226          0.0026939  \n",
       "params              {'alpha': 7.8e-05}  {'alpha': 8.9e-05}  {'alpha': 0.0001}  \n",
       "std_train_score              0.0025222          0.00242386         0.00109798  \n",
       "split0_test_score             -0.81809           -0.830095          -0.838175  \n",
       "split1_train_score           -0.796959           -0.803295          -0.816628  \n",
       "split0_train_score           -0.792779           -0.808118          -0.817945  \n",
       "rank_test_score                      7                   8                  9  \n",
       "split2_train_score           -0.789432           -0.801131          -0.815742  \n",
       "split3_test_score            -0.816314            -0.82621          -0.837084  \n",
       "split3_train_score           -0.791568           -0.804431          -0.818103  \n",
       "split4_test_score            -0.821151           -0.832825          -0.842872  \n",
       "split4_train_score           -0.791225           -0.806407          -0.818778  \n",
       "std_fit_time                 0.0157395           0.0603916           0.072123  \n",
       "param_alpha                    7.8e-05             8.9e-05             0.0001  \n",
       "split1_test_score            -0.824758           -0.828177           -0.83977  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "cv_result_better.columns = np.linspace(1e-06, 1e-04, num=10)\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': array([ 0.15  ,  0.2375,  0.325 ,  0.4125,  0.5   ]), 'alpha': array([  1.00000e-06,   2.30000e-05,   4.50000e-05])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_aphpa = {'alpha': np.linspace(1e-06, 4.5e-05, num=3), 'l1_ratio': np.linspace(0.15, 0.5, num=5)}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet'),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00181269</td>\n",
       "      <td>0.000306481</td>\n",
       "      <td>0.00107535</td>\n",
       "      <td>0.00294731</td>\n",
       "      <td>0.0120152</td>\n",
       "      <td>0.00137243</td>\n",
       "      <td>0.0012291</td>\n",
       "      <td>0.00109214</td>\n",
       "      <td>0.000962128</td>\n",
       "      <td>0.000796275</td>\n",
       "      <td>0.000329349</td>\n",
       "      <td>0.00209603</td>\n",
       "      <td>0.000394245</td>\n",
       "      <td>0.00104462</td>\n",
       "      <td>0.000856644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.622599</td>\n",
       "      <td>0.611212</td>\n",
       "      <td>0.615387</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>0.748349</td>\n",
       "      <td>0.64732</td>\n",
       "      <td>0.645397</td>\n",
       "      <td>0.603871</td>\n",
       "      <td>0.566564</td>\n",
       "      <td>0.580117</td>\n",
       "      <td>0.602533</td>\n",
       "      <td>0.600767</td>\n",
       "      <td>0.585995</td>\n",
       "      <td>0.552044</td>\n",
       "      <td>0.541899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.863524</td>\n",
       "      <td>-0.855405</td>\n",
       "      <td>-0.875271</td>\n",
       "      <td>-0.863631</td>\n",
       "      <td>-0.878052</td>\n",
       "      <td>-0.760705</td>\n",
       "      <td>-0.760077</td>\n",
       "      <td>-0.762024</td>\n",
       "      <td>-0.761728</td>\n",
       "      <td>-0.760154</td>\n",
       "      <td>-0.787933</td>\n",
       "      <td>-0.789338</td>\n",
       "      <td>-0.789001</td>\n",
       "      <td>-0.789043</td>\n",
       "      <td>-0.786817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0178282</td>\n",
       "      <td>0.0108884</td>\n",
       "      <td>0.0174892</td>\n",
       "      <td>0.0125911</td>\n",
       "      <td>0.0182421</td>\n",
       "      <td>0.00608935</td>\n",
       "      <td>0.00538047</td>\n",
       "      <td>0.00504238</td>\n",
       "      <td>0.00360788</td>\n",
       "      <td>0.00390513</td>\n",
       "      <td>0.00497006</td>\n",
       "      <td>0.00467231</td>\n",
       "      <td>0.00209793</td>\n",
       "      <td>0.00311165</td>\n",
       "      <td>0.00489251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.878568</td>\n",
       "      <td>-0.868106</td>\n",
       "      <td>-0.875746</td>\n",
       "      <td>-0.867129</td>\n",
       "      <td>-0.907945</td>\n",
       "      <td>-0.759155</td>\n",
       "      <td>-0.751853</td>\n",
       "      <td>-0.757729</td>\n",
       "      <td>-0.755436</td>\n",
       "      <td>-0.756837</td>\n",
       "      <td>-0.784517</td>\n",
       "      <td>-0.784663</td>\n",
       "      <td>-0.78554</td>\n",
       "      <td>-0.784633</td>\n",
       "      <td>-0.781583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.831799</td>\n",
       "      <td>-0.841429</td>\n",
       "      <td>-0.894541</td>\n",
       "      <td>-0.857856</td>\n",
       "      <td>-0.861816</td>\n",
       "      <td>-0.752707</td>\n",
       "      <td>-0.75804</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>-0.760086</td>\n",
       "      <td>-0.756352</td>\n",
       "      <td>-0.784346</td>\n",
       "      <td>-0.783007</td>\n",
       "      <td>-0.788422</td>\n",
       "      <td>-0.789061</td>\n",
       "      <td>-0.783677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.868378</td>\n",
       "      <td>-0.844059</td>\n",
       "      <td>-0.862671</td>\n",
       "      <td>-0.842664</td>\n",
       "      <td>-0.870246</td>\n",
       "      <td>-0.763986</td>\n",
       "      <td>-0.766473</td>\n",
       "      <td>-0.766018</td>\n",
       "      <td>-0.76526</td>\n",
       "      <td>-0.759446</td>\n",
       "      <td>-0.792932</td>\n",
       "      <td>-0.792348</td>\n",
       "      <td>-0.790368</td>\n",
       "      <td>-0.791254</td>\n",
       "      <td>-0.790661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.481263</td>\n",
       "      <td>-0.490431</td>\n",
       "      <td>-0.474763</td>\n",
       "      <td>-0.493743</td>\n",
       "      <td>-0.449816</td>\n",
       "      <td>-0.688773</td>\n",
       "      <td>-0.696302</td>\n",
       "      <td>-0.700497</td>\n",
       "      <td>-0.701591</td>\n",
       "      <td>-0.699402</td>\n",
       "      <td>-0.747185</td>\n",
       "      <td>-0.750792</td>\n",
       "      <td>-0.752407</td>\n",
       "      <td>-0.756113</td>\n",
       "      <td>-0.756724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.517421</td>\n",
       "      <td>-0.48184</td>\n",
       "      <td>-0.503288</td>\n",
       "      <td>-0.462708</td>\n",
       "      <td>-0.489322</td>\n",
       "      <td>-0.687935</td>\n",
       "      <td>-0.685991</td>\n",
       "      <td>-0.687076</td>\n",
       "      <td>-0.691223</td>\n",
       "      <td>-0.697985</td>\n",
       "      <td>-0.743876</td>\n",
       "      <td>-0.747582</td>\n",
       "      <td>-0.747125</td>\n",
       "      <td>-0.750911</td>\n",
       "      <td>-0.754513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.496221</td>\n",
       "      <td>-0.488929</td>\n",
       "      <td>-0.493316</td>\n",
       "      <td>-0.482099</td>\n",
       "      <td>-0.466261</td>\n",
       "      <td>-0.686045</td>\n",
       "      <td>-0.689915</td>\n",
       "      <td>-0.696667</td>\n",
       "      <td>-0.699479</td>\n",
       "      <td>-0.700339</td>\n",
       "      <td>-0.743515</td>\n",
       "      <td>-0.749906</td>\n",
       "      <td>-0.752218</td>\n",
       "      <td>-0.755277</td>\n",
       "      <td>-0.754676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'l1_ratio': 0.15, 'alpha': 1e-06}</td>\n",
       "      <td>{'l1_ratio': 0.2375, 'alpha': 1e-06}</td>\n",
       "      <td>{'l1_ratio': 0.325, 'alpha': 1e-06}</td>\n",
       "      <td>{'l1_ratio': 0.4125, 'alpha': 1e-06}</td>\n",
       "      <td>{'l1_ratio': 0.5, 'alpha': 1e-06}</td>\n",
       "      <td>{'l1_ratio': 0.15, 'alpha': 2.3e-05}</td>\n",
       "      <td>{'l1_ratio': 0.2375, 'alpha': 2.3e-05}</td>\n",
       "      <td>{'l1_ratio': 0.325, 'alpha': 2.3e-05}</td>\n",
       "      <td>{'l1_ratio': 0.4125, 'alpha': 2.3e-05}</td>\n",
       "      <td>{'l1_ratio': 0.5, 'alpha': 2.3e-05}</td>\n",
       "      <td>{'l1_ratio': 0.15, 'alpha': 4.5e-05}</td>\n",
       "      <td>{'l1_ratio': 0.2375, 'alpha': 4.5e-05}</td>\n",
       "      <td>{'l1_ratio': 0.325, 'alpha': 4.5e-05}</td>\n",
       "      <td>{'l1_ratio': 0.4125, 'alpha': 4.5e-05}</td>\n",
       "      <td>{'l1_ratio': 0.5, 'alpha': 4.5e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0119139</td>\n",
       "      <td>0.010276</td>\n",
       "      <td>0.0153939</td>\n",
       "      <td>0.0110993</td>\n",
       "      <td>0.0136799</td>\n",
       "      <td>0.00232362</td>\n",
       "      <td>0.00478612</td>\n",
       "      <td>0.00578036</td>\n",
       "      <td>0.00495956</td>\n",
       "      <td>0.00202008</td>\n",
       "      <td>0.00281057</td>\n",
       "      <td>0.00207113</td>\n",
       "      <td>0.00303318</td>\n",
       "      <td>0.00303477</td>\n",
       "      <td>0.00145976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.880901</td>\n",
       "      <td>-0.865439</td>\n",
       "      <td>-0.893757</td>\n",
       "      <td>-0.879583</td>\n",
       "      <td>-0.889773</td>\n",
       "      <td>-0.770496</td>\n",
       "      <td>-0.765519</td>\n",
       "      <td>-0.763019</td>\n",
       "      <td>-0.764499</td>\n",
       "      <td>-0.767203</td>\n",
       "      <td>-0.794935</td>\n",
       "      <td>-0.795095</td>\n",
       "      <td>-0.791796</td>\n",
       "      <td>-0.793427</td>\n",
       "      <td>-0.794441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0342822</td>\n",
       "      <td>0.0325624</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.041088</td>\n",
       "      <td>0.0361953</td>\n",
       "      <td>0.0366334</td>\n",
       "      <td>0.0338488</td>\n",
       "      <td>0.0327708</td>\n",
       "      <td>0.0333604</td>\n",
       "      <td>0.0345178</td>\n",
       "      <td>0.0352038</td>\n",
       "      <td>0.032491</td>\n",
       "      <td>0.032939</td>\n",
       "      <td>0.0330273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.491846</td>\n",
       "      <td>-0.505797</td>\n",
       "      <td>-0.511474</td>\n",
       "      <td>-0.491488</td>\n",
       "      <td>-0.462935</td>\n",
       "      <td>-0.684518</td>\n",
       "      <td>-0.694946</td>\n",
       "      <td>-0.696567</td>\n",
       "      <td>-0.705745</td>\n",
       "      <td>-0.703105</td>\n",
       "      <td>-0.744953</td>\n",
       "      <td>-0.74795</td>\n",
       "      <td>-0.756428</td>\n",
       "      <td>-0.760081</td>\n",
       "      <td>-0.755901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>2.3e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "      <td>4.5e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.492493</td>\n",
       "      <td>-0.491265</td>\n",
       "      <td>-0.502048</td>\n",
       "      <td>-0.478551</td>\n",
       "      <td>-0.472265</td>\n",
       "      <td>-0.682393</td>\n",
       "      <td>-0.687739</td>\n",
       "      <td>-0.704247</td>\n",
       "      <td>-0.701774</td>\n",
       "      <td>-0.702362</td>\n",
       "      <td>-0.738675</td>\n",
       "      <td>-0.753287</td>\n",
       "      <td>-0.753579</td>\n",
       "      <td>-0.753546</td>\n",
       "      <td>-0.752902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.85799</td>\n",
       "      <td>-0.857998</td>\n",
       "      <td>-0.849638</td>\n",
       "      <td>-0.870921</td>\n",
       "      <td>-0.860492</td>\n",
       "      <td>-0.757188</td>\n",
       "      <td>-0.758503</td>\n",
       "      <td>-0.768441</td>\n",
       "      <td>-0.763358</td>\n",
       "      <td>-0.760935</td>\n",
       "      <td>-0.782937</td>\n",
       "      <td>-0.791578</td>\n",
       "      <td>-0.788882</td>\n",
       "      <td>-0.786839</td>\n",
       "      <td>-0.783727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0308554</td>\n",
       "      <td>0.0103889</td>\n",
       "      <td>0.0109242</td>\n",
       "      <td>0.0664395</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.0413693</td>\n",
       "      <td>0.0240771</td>\n",
       "      <td>0.0287301</td>\n",
       "      <td>0.0107372</td>\n",
       "      <td>0.0132349</td>\n",
       "      <td>0.0117427</td>\n",
       "      <td>0.00905683</td>\n",
       "      <td>0.0506188</td>\n",
       "      <td>0.00538641</td>\n",
       "      <td>0.00958259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.498082</td>\n",
       "      <td>-0.47531</td>\n",
       "      <td>-0.475006</td>\n",
       "      <td>-0.484005</td>\n",
       "      <td>-0.456968</td>\n",
       "      <td>-0.686607</td>\n",
       "      <td>-0.684595</td>\n",
       "      <td>-0.694949</td>\n",
       "      <td>-0.697064</td>\n",
       "      <td>-0.698842</td>\n",
       "      <td>-0.742885</td>\n",
       "      <td>-0.749918</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.755735</td>\n",
       "      <td>-0.753339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0   \\\n",
       "std_score_time                              0.00181269   \n",
       "mean_fit_time                                 0.622599   \n",
       "mean_test_score                              -0.863524   \n",
       "std_test_score                               0.0178282   \n",
       "split3_test_score                            -0.878568   \n",
       "split0_test_score                            -0.831799   \n",
       "split4_test_score                            -0.868378   \n",
       "split4_train_score                           -0.481263   \n",
       "split2_train_score                           -0.517421   \n",
       "param_l1_ratio                                    0.15   \n",
       "mean_train_score                             -0.496221   \n",
       "params              {'l1_ratio': 0.15, 'alpha': 1e-06}   \n",
       "std_train_score                              0.0119139   \n",
       "split2_test_score                            -0.880901   \n",
       "mean_score_time                              0.0342822   \n",
       "split0_train_score                           -0.491846   \n",
       "rank_test_score                                     12   \n",
       "param_alpha                                      1e-06   \n",
       "split1_train_score                           -0.492493   \n",
       "split1_test_score                             -0.85799   \n",
       "std_fit_time                                 0.0308554   \n",
       "split3_train_score                           -0.498082   \n",
       "\n",
       "                                                      1   \\\n",
       "std_score_time                               0.000306481   \n",
       "mean_fit_time                                   0.611212   \n",
       "mean_test_score                                -0.855405   \n",
       "std_test_score                                 0.0108884   \n",
       "split3_test_score                              -0.868106   \n",
       "split0_test_score                              -0.841429   \n",
       "split4_test_score                              -0.844059   \n",
       "split4_train_score                             -0.490431   \n",
       "split2_train_score                              -0.48184   \n",
       "param_l1_ratio                                    0.2375   \n",
       "mean_train_score                               -0.488929   \n",
       "params              {'l1_ratio': 0.2375, 'alpha': 1e-06}   \n",
       "std_train_score                                 0.010276   \n",
       "split2_test_score                              -0.865439   \n",
       "mean_score_time                                0.0325624   \n",
       "split0_train_score                             -0.505797   \n",
       "rank_test_score                                       11   \n",
       "param_alpha                                        1e-06   \n",
       "split1_train_score                             -0.491265   \n",
       "split1_test_score                              -0.857998   \n",
       "std_fit_time                                   0.0103889   \n",
       "split3_train_score                              -0.47531   \n",
       "\n",
       "                                                     2   \\\n",
       "std_score_time                               0.00107535   \n",
       "mean_fit_time                                  0.615387   \n",
       "mean_test_score                               -0.875271   \n",
       "std_test_score                                0.0174892   \n",
       "split3_test_score                             -0.875746   \n",
       "split0_test_score                             -0.894541   \n",
       "split4_test_score                             -0.862671   \n",
       "split4_train_score                            -0.474763   \n",
       "split2_train_score                            -0.503288   \n",
       "param_l1_ratio                                    0.325   \n",
       "mean_train_score                              -0.493316   \n",
       "params              {'l1_ratio': 0.325, 'alpha': 1e-06}   \n",
       "std_train_score                               0.0153939   \n",
       "split2_test_score                             -0.893757   \n",
       "mean_score_time                                0.033517   \n",
       "split0_train_score                            -0.511474   \n",
       "rank_test_score                                      14   \n",
       "param_alpha                                       1e-06   \n",
       "split1_train_score                            -0.502048   \n",
       "split1_test_score                             -0.849638   \n",
       "std_fit_time                                  0.0109242   \n",
       "split3_train_score                            -0.475006   \n",
       "\n",
       "                                                      3   \\\n",
       "std_score_time                                0.00294731   \n",
       "mean_fit_time                                   0.697394   \n",
       "mean_test_score                                -0.863631   \n",
       "std_test_score                                 0.0125911   \n",
       "split3_test_score                              -0.867129   \n",
       "split0_test_score                              -0.857856   \n",
       "split4_test_score                              -0.842664   \n",
       "split4_train_score                             -0.493743   \n",
       "split2_train_score                             -0.462708   \n",
       "param_l1_ratio                                    0.4125   \n",
       "mean_train_score                               -0.482099   \n",
       "params              {'l1_ratio': 0.4125, 'alpha': 1e-06}   \n",
       "std_train_score                                0.0110993   \n",
       "split2_test_score                              -0.879583   \n",
       "mean_score_time                                 0.036802   \n",
       "split0_train_score                             -0.491488   \n",
       "rank_test_score                                       13   \n",
       "param_alpha                                        1e-06   \n",
       "split1_train_score                             -0.478551   \n",
       "split1_test_score                              -0.870921   \n",
       "std_fit_time                                   0.0664395   \n",
       "split3_train_score                             -0.484005   \n",
       "\n",
       "                                                   4   \\\n",
       "std_score_time                              0.0120152   \n",
       "mean_fit_time                                0.748349   \n",
       "mean_test_score                             -0.878052   \n",
       "std_test_score                              0.0182421   \n",
       "split3_test_score                           -0.907945   \n",
       "split0_test_score                           -0.861816   \n",
       "split4_test_score                           -0.870246   \n",
       "split4_train_score                          -0.449816   \n",
       "split2_train_score                          -0.489322   \n",
       "param_l1_ratio                                    0.5   \n",
       "mean_train_score                            -0.466261   \n",
       "params              {'l1_ratio': 0.5, 'alpha': 1e-06}   \n",
       "std_train_score                             0.0136799   \n",
       "split2_test_score                           -0.889773   \n",
       "mean_score_time                              0.041088   \n",
       "split0_train_score                          -0.462935   \n",
       "rank_test_score                                    15   \n",
       "param_alpha                                     1e-06   \n",
       "split1_train_score                          -0.472265   \n",
       "split1_test_score                           -0.860492   \n",
       "std_fit_time                                 0.109667   \n",
       "split3_train_score                          -0.456968   \n",
       "\n",
       "                                                      5   \\\n",
       "std_score_time                                0.00137243   \n",
       "mean_fit_time                                    0.64732   \n",
       "mean_test_score                                -0.760705   \n",
       "std_test_score                                0.00608935   \n",
       "split3_test_score                              -0.759155   \n",
       "split0_test_score                              -0.752707   \n",
       "split4_test_score                              -0.763986   \n",
       "split4_train_score                             -0.688773   \n",
       "split2_train_score                             -0.687935   \n",
       "param_l1_ratio                                      0.15   \n",
       "mean_train_score                               -0.686045   \n",
       "params              {'l1_ratio': 0.15, 'alpha': 2.3e-05}   \n",
       "std_train_score                               0.00232362   \n",
       "split2_test_score                              -0.770496   \n",
       "mean_score_time                                0.0361953   \n",
       "split0_train_score                             -0.684518   \n",
       "rank_test_score                                        3   \n",
       "param_alpha                                      2.3e-05   \n",
       "split1_train_score                             -0.682393   \n",
       "split1_test_score                              -0.757188   \n",
       "std_fit_time                                   0.0413693   \n",
       "split3_train_score                             -0.686607   \n",
       "\n",
       "                                                        6   \\\n",
       "std_score_time                                   0.0012291   \n",
       "mean_fit_time                                     0.645397   \n",
       "mean_test_score                                  -0.760077   \n",
       "std_test_score                                  0.00538047   \n",
       "split3_test_score                                -0.751853   \n",
       "split0_test_score                                 -0.75804   \n",
       "split4_test_score                                -0.766473   \n",
       "split4_train_score                               -0.696302   \n",
       "split2_train_score                               -0.685991   \n",
       "param_l1_ratio                                      0.2375   \n",
       "mean_train_score                                 -0.689915   \n",
       "params              {'l1_ratio': 0.2375, 'alpha': 2.3e-05}   \n",
       "std_train_score                                 0.00478612   \n",
       "split2_test_score                                -0.765519   \n",
       "mean_score_time                                  0.0366334   \n",
       "split0_train_score                               -0.694946   \n",
       "rank_test_score                                          1   \n",
       "param_alpha                                        2.3e-05   \n",
       "split1_train_score                               -0.687739   \n",
       "split1_test_score                                -0.758503   \n",
       "std_fit_time                                     0.0240771   \n",
       "split3_train_score                               -0.684595   \n",
       "\n",
       "                                                       7   \\\n",
       "std_score_time                                 0.00109214   \n",
       "mean_fit_time                                    0.603871   \n",
       "mean_test_score                                 -0.762024   \n",
       "std_test_score                                 0.00504238   \n",
       "split3_test_score                               -0.757729   \n",
       "split0_test_score                               -0.754915   \n",
       "split4_test_score                               -0.766018   \n",
       "split4_train_score                              -0.700497   \n",
       "split2_train_score                              -0.687076   \n",
       "param_l1_ratio                                      0.325   \n",
       "mean_train_score                                -0.696667   \n",
       "params              {'l1_ratio': 0.325, 'alpha': 2.3e-05}   \n",
       "std_train_score                                0.00578036   \n",
       "split2_test_score                               -0.763019   \n",
       "mean_score_time                                 0.0338488   \n",
       "split0_train_score                              -0.696567   \n",
       "rank_test_score                                         5   \n",
       "param_alpha                                       2.3e-05   \n",
       "split1_train_score                              -0.704247   \n",
       "split1_test_score                               -0.768441   \n",
       "std_fit_time                                    0.0287301   \n",
       "split3_train_score                              -0.694949   \n",
       "\n",
       "                                                        8   \\\n",
       "std_score_time                                 0.000962128   \n",
       "mean_fit_time                                     0.566564   \n",
       "mean_test_score                                  -0.761728   \n",
       "std_test_score                                  0.00360788   \n",
       "split3_test_score                                -0.755436   \n",
       "split0_test_score                                -0.760086   \n",
       "split4_test_score                                 -0.76526   \n",
       "split4_train_score                               -0.701591   \n",
       "split2_train_score                               -0.691223   \n",
       "param_l1_ratio                                      0.4125   \n",
       "mean_train_score                                 -0.699479   \n",
       "params              {'l1_ratio': 0.4125, 'alpha': 2.3e-05}   \n",
       "std_train_score                                 0.00495956   \n",
       "split2_test_score                                -0.764499   \n",
       "mean_score_time                                  0.0327708   \n",
       "split0_train_score                               -0.705745   \n",
       "rank_test_score                                          4   \n",
       "param_alpha                                        2.3e-05   \n",
       "split1_train_score                               -0.701774   \n",
       "split1_test_score                                -0.763358   \n",
       "std_fit_time                                     0.0107372   \n",
       "split3_train_score                               -0.697064   \n",
       "\n",
       "                                                     9   \\\n",
       "std_score_time                              0.000796275   \n",
       "mean_fit_time                                  0.580117   \n",
       "mean_test_score                               -0.760154   \n",
       "std_test_score                               0.00390513   \n",
       "split3_test_score                             -0.756837   \n",
       "split0_test_score                             -0.756352   \n",
       "split4_test_score                             -0.759446   \n",
       "split4_train_score                            -0.699402   \n",
       "split2_train_score                            -0.697985   \n",
       "param_l1_ratio                                      0.5   \n",
       "mean_train_score                              -0.700339   \n",
       "params              {'l1_ratio': 0.5, 'alpha': 2.3e-05}   \n",
       "std_train_score                              0.00202008   \n",
       "split2_test_score                             -0.767203   \n",
       "mean_score_time                               0.0333604   \n",
       "split0_train_score                            -0.703105   \n",
       "rank_test_score                                       2   \n",
       "param_alpha                                     2.3e-05   \n",
       "split1_train_score                            -0.702362   \n",
       "split1_test_score                             -0.760935   \n",
       "std_fit_time                                  0.0132349   \n",
       "split3_train_score                            -0.698842   \n",
       "\n",
       "                                                      10  \\\n",
       "std_score_time                               0.000329349   \n",
       "mean_fit_time                                   0.602533   \n",
       "mean_test_score                                -0.787933   \n",
       "std_test_score                                0.00497006   \n",
       "split3_test_score                              -0.784517   \n",
       "split0_test_score                              -0.784346   \n",
       "split4_test_score                              -0.792932   \n",
       "split4_train_score                             -0.747185   \n",
       "split2_train_score                             -0.743876   \n",
       "param_l1_ratio                                      0.15   \n",
       "mean_train_score                               -0.743515   \n",
       "params              {'l1_ratio': 0.15, 'alpha': 4.5e-05}   \n",
       "std_train_score                               0.00281057   \n",
       "split2_test_score                              -0.794935   \n",
       "mean_score_time                                0.0345178   \n",
       "split0_train_score                             -0.744953   \n",
       "rank_test_score                                        7   \n",
       "param_alpha                                      4.5e-05   \n",
       "split1_train_score                             -0.738675   \n",
       "split1_test_score                              -0.782937   \n",
       "std_fit_time                                   0.0117427   \n",
       "split3_train_score                             -0.742885   \n",
       "\n",
       "                                                        11  \\\n",
       "std_score_time                                  0.00209603   \n",
       "mean_fit_time                                     0.600767   \n",
       "mean_test_score                                  -0.789338   \n",
       "std_test_score                                  0.00467231   \n",
       "split3_test_score                                -0.784663   \n",
       "split0_test_score                                -0.783007   \n",
       "split4_test_score                                -0.792348   \n",
       "split4_train_score                               -0.750792   \n",
       "split2_train_score                               -0.747582   \n",
       "param_l1_ratio                                      0.2375   \n",
       "mean_train_score                                 -0.749906   \n",
       "params              {'l1_ratio': 0.2375, 'alpha': 4.5e-05}   \n",
       "std_train_score                                 0.00207113   \n",
       "split2_test_score                                -0.795095   \n",
       "mean_score_time                                  0.0352038   \n",
       "split0_train_score                                -0.74795   \n",
       "rank_test_score                                         10   \n",
       "param_alpha                                        4.5e-05   \n",
       "split1_train_score                               -0.753287   \n",
       "split1_test_score                                -0.791578   \n",
       "std_fit_time                                    0.00905683   \n",
       "split3_train_score                               -0.749918   \n",
       "\n",
       "                                                       12  \\\n",
       "std_score_time                                0.000394245   \n",
       "mean_fit_time                                    0.585995   \n",
       "mean_test_score                                 -0.789001   \n",
       "std_test_score                                 0.00209793   \n",
       "split3_test_score                                -0.78554   \n",
       "split0_test_score                               -0.788422   \n",
       "split4_test_score                               -0.790368   \n",
       "split4_train_score                              -0.752407   \n",
       "split2_train_score                              -0.747125   \n",
       "param_l1_ratio                                      0.325   \n",
       "mean_train_score                                -0.752218   \n",
       "params              {'l1_ratio': 0.325, 'alpha': 4.5e-05}   \n",
       "std_train_score                                0.00303318   \n",
       "split2_test_score                               -0.791796   \n",
       "mean_score_time                                  0.032491   \n",
       "split0_train_score                              -0.756428   \n",
       "rank_test_score                                         8   \n",
       "param_alpha                                       4.5e-05   \n",
       "split1_train_score                              -0.753579   \n",
       "split1_test_score                               -0.788882   \n",
       "std_fit_time                                    0.0506188   \n",
       "split3_train_score                              -0.751551   \n",
       "\n",
       "                                                        13  \\\n",
       "std_score_time                                  0.00104462   \n",
       "mean_fit_time                                     0.552044   \n",
       "mean_test_score                                  -0.789043   \n",
       "std_test_score                                  0.00311165   \n",
       "split3_test_score                                -0.784633   \n",
       "split0_test_score                                -0.789061   \n",
       "split4_test_score                                -0.791254   \n",
       "split4_train_score                               -0.756113   \n",
       "split2_train_score                               -0.750911   \n",
       "param_l1_ratio                                      0.4125   \n",
       "mean_train_score                                 -0.755277   \n",
       "params              {'l1_ratio': 0.4125, 'alpha': 4.5e-05}   \n",
       "std_train_score                                 0.00303477   \n",
       "split2_test_score                                -0.793427   \n",
       "mean_score_time                                   0.032939   \n",
       "split0_train_score                               -0.760081   \n",
       "rank_test_score                                          9   \n",
       "param_alpha                                        4.5e-05   \n",
       "split1_train_score                               -0.753546   \n",
       "split1_test_score                                -0.786839   \n",
       "std_fit_time                                    0.00538641   \n",
       "split3_train_score                               -0.755735   \n",
       "\n",
       "                                                     14  \n",
       "std_score_time                              0.000856644  \n",
       "mean_fit_time                                  0.541899  \n",
       "mean_test_score                               -0.786817  \n",
       "std_test_score                               0.00489251  \n",
       "split3_test_score                             -0.781583  \n",
       "split0_test_score                             -0.783677  \n",
       "split4_test_score                             -0.790661  \n",
       "split4_train_score                            -0.756724  \n",
       "split2_train_score                            -0.754513  \n",
       "param_l1_ratio                                      0.5  \n",
       "mean_train_score                              -0.754676  \n",
       "params              {'l1_ratio': 0.5, 'alpha': 4.5e-05}  \n",
       "std_train_score                              0.00145976  \n",
       "split2_test_score                             -0.794441  \n",
       "mean_score_time                               0.0330273  \n",
       "split0_train_score                            -0.755901  \n",
       "rank_test_score                                       6  \n",
       "param_alpha                                     4.5e-05  \n",
       "split1_train_score                            -0.752902  \n",
       "split1_test_score                             -0.783727  \n",
       "std_fit_time                                 0.00958259  \n",
       "split3_train_score                            -0.753339  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=2.3e-05, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'l1_ratio': array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function score at 0x115a197b8>, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_aphpa = {'l1_ratio': np.linspace(0.1, 1, num=10)}\n",
    "ela_model = GridSearchCV(SGDClassifier(loss='log', penalty='elasticnet', alpha=2.3e-05),\n",
    "                         ela_aphpa, scoring=score, cv = 5)                         \n",
    "ela_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.734057</td>\n",
       "      <td>0.687199</td>\n",
       "      <td>0.605905</td>\n",
       "      <td>0.560829</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>0.552245</td>\n",
       "      <td>0.625029</td>\n",
       "      <td>0.638881</td>\n",
       "      <td>0.575644</td>\n",
       "      <td>0.596567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0352354</td>\n",
       "      <td>0.0340768</td>\n",
       "      <td>0.0346968</td>\n",
       "      <td>0.0343143</td>\n",
       "      <td>0.0332084</td>\n",
       "      <td>0.0340524</td>\n",
       "      <td>0.035207</td>\n",
       "      <td>0.0593375</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>0.0365136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00337863</td>\n",
       "      <td>0.00139589</td>\n",
       "      <td>0.00122149</td>\n",
       "      <td>0.00148884</td>\n",
       "      <td>0.000859302</td>\n",
       "      <td>0.00148557</td>\n",
       "      <td>0.000769904</td>\n",
       "      <td>0.0456824</td>\n",
       "      <td>0.00212812</td>\n",
       "      <td>0.00181547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.771854</td>\n",
       "      <td>-0.77146</td>\n",
       "      <td>-0.762962</td>\n",
       "      <td>-0.769854</td>\n",
       "      <td>-0.765132</td>\n",
       "      <td>-0.763382</td>\n",
       "      <td>-0.765489</td>\n",
       "      <td>-0.768701</td>\n",
       "      <td>-0.76301</td>\n",
       "      <td>-0.761687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.762518</td>\n",
       "      <td>-0.763448</td>\n",
       "      <td>-0.761959</td>\n",
       "      <td>-0.762536</td>\n",
       "      <td>-0.759822</td>\n",
       "      <td>-0.756755</td>\n",
       "      <td>-0.757164</td>\n",
       "      <td>-0.758759</td>\n",
       "      <td>-0.75584</td>\n",
       "      <td>-0.754148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.683573</td>\n",
       "      <td>-0.691764</td>\n",
       "      <td>-0.695493</td>\n",
       "      <td>-0.699736</td>\n",
       "      <td>-0.699706</td>\n",
       "      <td>-0.698359</td>\n",
       "      <td>-0.700661</td>\n",
       "      <td>-0.70451</td>\n",
       "      <td>-0.70039</td>\n",
       "      <td>-0.698457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00601522</td>\n",
       "      <td>0.00466992</td>\n",
       "      <td>0.00183532</td>\n",
       "      <td>0.00591737</td>\n",
       "      <td>0.00522045</td>\n",
       "      <td>0.00519496</td>\n",
       "      <td>0.00568462</td>\n",
       "      <td>0.00618751</td>\n",
       "      <td>0.00467143</td>\n",
       "      <td>0.00450448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'l1_ratio': 0.1}</td>\n",
       "      <td>{'l1_ratio': 0.2}</td>\n",
       "      <td>{'l1_ratio': 0.3}</td>\n",
       "      <td>{'l1_ratio': 0.4}</td>\n",
       "      <td>{'l1_ratio': 0.5}</td>\n",
       "      <td>{'l1_ratio': 0.6}</td>\n",
       "      <td>{'l1_ratio': 0.7}</td>\n",
       "      <td>{'l1_ratio': 0.8}</td>\n",
       "      <td>{'l1_ratio': 0.9}</td>\n",
       "      <td>{'l1_ratio': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.0015636</td>\n",
       "      <td>0.00135538</td>\n",
       "      <td>0.00569432</td>\n",
       "      <td>0.00315701</td>\n",
       "      <td>0.00524762</td>\n",
       "      <td>0.00335583</td>\n",
       "      <td>0.00295569</td>\n",
       "      <td>0.00298681</td>\n",
       "      <td>0.00457212</td>\n",
       "      <td>0.00282435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.753659</td>\n",
       "      <td>-0.758001</td>\n",
       "      <td>-0.760154</td>\n",
       "      <td>-0.753726</td>\n",
       "      <td>-0.757219</td>\n",
       "      <td>-0.749417</td>\n",
       "      <td>-0.753151</td>\n",
       "      <td>-0.75049</td>\n",
       "      <td>-0.756362</td>\n",
       "      <td>-0.751228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.683461</td>\n",
       "      <td>-0.689858</td>\n",
       "      <td>-0.693034</td>\n",
       "      <td>-0.702054</td>\n",
       "      <td>-0.692198</td>\n",
       "      <td>-0.702492</td>\n",
       "      <td>-0.698465</td>\n",
       "      <td>-0.708461</td>\n",
       "      <td>-0.704123</td>\n",
       "      <td>-0.702949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.68231</td>\n",
       "      <td>-0.693116</td>\n",
       "      <td>-0.700893</td>\n",
       "      <td>-0.697452</td>\n",
       "      <td>-0.703128</td>\n",
       "      <td>-0.697315</td>\n",
       "      <td>-0.7036</td>\n",
       "      <td>-0.70111</td>\n",
       "      <td>-0.707386</td>\n",
       "      <td>-0.700321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.684009</td>\n",
       "      <td>-0.691912</td>\n",
       "      <td>-0.685436</td>\n",
       "      <td>-0.698014</td>\n",
       "      <td>-0.695807</td>\n",
       "      <td>-0.694155</td>\n",
       "      <td>-0.699453</td>\n",
       "      <td>-0.703946</td>\n",
       "      <td>-0.695694</td>\n",
       "      <td>-0.69546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.760467</td>\n",
       "      <td>-0.761025</td>\n",
       "      <td>-0.761123</td>\n",
       "      <td>-0.758045</td>\n",
       "      <td>-0.75671</td>\n",
       "      <td>-0.752028</td>\n",
       "      <td>-0.751043</td>\n",
       "      <td>-0.755829</td>\n",
       "      <td>-0.74909</td>\n",
       "      <td>-0.749217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.681809</td>\n",
       "      <td>-0.690621</td>\n",
       "      <td>-0.699538</td>\n",
       "      <td>-0.696404</td>\n",
       "      <td>-0.700345</td>\n",
       "      <td>-0.695766</td>\n",
       "      <td>-0.697108</td>\n",
       "      <td>-0.707443</td>\n",
       "      <td>-0.696539</td>\n",
       "      <td>-0.697675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.765522</td>\n",
       "      <td>-0.765536</td>\n",
       "      <td>-0.765074</td>\n",
       "      <td>-0.767233</td>\n",
       "      <td>-0.766793</td>\n",
       "      <td>-0.759376</td>\n",
       "      <td>-0.762375</td>\n",
       "      <td>-0.756667</td>\n",
       "      <td>-0.752977</td>\n",
       "      <td>-0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.686278</td>\n",
       "      <td>-0.693312</td>\n",
       "      <td>-0.698562</td>\n",
       "      <td>-0.704753</td>\n",
       "      <td>-0.707054</td>\n",
       "      <td>-0.702065</td>\n",
       "      <td>-0.704678</td>\n",
       "      <td>-0.701592</td>\n",
       "      <td>-0.698207</td>\n",
       "      <td>-0.69588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.0327775</td>\n",
       "      <td>0.108711</td>\n",
       "      <td>0.00748429</td>\n",
       "      <td>0.00274802</td>\n",
       "      <td>0.00760586</td>\n",
       "      <td>0.0042598</td>\n",
       "      <td>0.0389804</td>\n",
       "      <td>0.0413817</td>\n",
       "      <td>0.00473018</td>\n",
       "      <td>0.0317437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.761095</td>\n",
       "      <td>-0.761223</td>\n",
       "      <td>-0.760483</td>\n",
       "      <td>-0.763825</td>\n",
       "      <td>-0.753263</td>\n",
       "      <td>-0.759575</td>\n",
       "      <td>-0.753763</td>\n",
       "      <td>-0.762109</td>\n",
       "      <td>-0.75776</td>\n",
       "      <td>-0.756725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0                  1                  2  \\\n",
       "mean_fit_time                0.734057           0.687199           0.605905   \n",
       "mean_score_time             0.0352354          0.0340768          0.0346968   \n",
       "std_score_time             0.00337863         0.00139589         0.00122149   \n",
       "split2_test_score           -0.771854           -0.77146          -0.762962   \n",
       "mean_test_score             -0.762518          -0.763448          -0.761959   \n",
       "mean_train_score            -0.683573          -0.691764          -0.695493   \n",
       "std_test_score             0.00601522         0.00466992         0.00183532   \n",
       "params              {'l1_ratio': 0.1}  {'l1_ratio': 0.2}  {'l1_ratio': 0.3}   \n",
       "std_train_score             0.0015636         0.00135538         0.00569432   \n",
       "param_l1_ratio                    0.1                0.2                0.3   \n",
       "split0_test_score           -0.753659          -0.758001          -0.760154   \n",
       "split1_train_score          -0.683461          -0.689858          -0.693034   \n",
       "split0_train_score           -0.68231          -0.693116          -0.700893   \n",
       "rank_test_score                     8                 10                  7   \n",
       "split2_train_score          -0.684009          -0.691912          -0.685436   \n",
       "split3_test_score           -0.760467          -0.761025          -0.761123   \n",
       "split3_train_score          -0.681809          -0.690621          -0.699538   \n",
       "split4_test_score           -0.765522          -0.765536          -0.765074   \n",
       "split4_train_score          -0.686278          -0.693312          -0.698562   \n",
       "std_fit_time                0.0327775           0.108711         0.00748429   \n",
       "split1_test_score           -0.761095          -0.761223          -0.760483   \n",
       "\n",
       "                                    3                  4                  5  \\\n",
       "mean_fit_time                0.560829             0.5608           0.552245   \n",
       "mean_score_time             0.0343143          0.0332084          0.0340524   \n",
       "std_score_time             0.00148884        0.000859302         0.00148557   \n",
       "split2_test_score           -0.769854          -0.765132          -0.763382   \n",
       "mean_test_score             -0.762536          -0.759822          -0.756755   \n",
       "mean_train_score            -0.699736          -0.699706          -0.698359   \n",
       "std_test_score             0.00591737         0.00522045         0.00519496   \n",
       "params              {'l1_ratio': 0.4}  {'l1_ratio': 0.5}  {'l1_ratio': 0.6}   \n",
       "std_train_score            0.00315701         0.00524762         0.00335583   \n",
       "param_l1_ratio                    0.4                0.5                0.6   \n",
       "split0_test_score           -0.753726          -0.757219          -0.749417   \n",
       "split1_train_score          -0.702054          -0.692198          -0.702492   \n",
       "split0_train_score          -0.697452          -0.703128          -0.697315   \n",
       "rank_test_score                     9                  6                  3   \n",
       "split2_train_score          -0.698014          -0.695807          -0.694155   \n",
       "split3_test_score           -0.758045           -0.75671          -0.752028   \n",
       "split3_train_score          -0.696404          -0.700345          -0.695766   \n",
       "split4_test_score           -0.767233          -0.766793          -0.759376   \n",
       "split4_train_score          -0.704753          -0.707054          -0.702065   \n",
       "std_fit_time               0.00274802         0.00760586          0.0042598   \n",
       "split1_test_score           -0.763825          -0.753263          -0.759575   \n",
       "\n",
       "                                    6                  7                  8  \\\n",
       "mean_fit_time                0.625029           0.638881           0.575644   \n",
       "mean_score_time              0.035207          0.0593375           0.035324   \n",
       "std_score_time            0.000769904          0.0456824         0.00212812   \n",
       "split2_test_score           -0.765489          -0.768701           -0.76301   \n",
       "mean_test_score             -0.757164          -0.758759           -0.75584   \n",
       "mean_train_score            -0.700661           -0.70451           -0.70039   \n",
       "std_test_score             0.00568462         0.00618751         0.00467143   \n",
       "params              {'l1_ratio': 0.7}  {'l1_ratio': 0.8}  {'l1_ratio': 0.9}   \n",
       "std_train_score            0.00295569         0.00298681         0.00457212   \n",
       "param_l1_ratio                    0.7                0.8                0.9   \n",
       "split0_test_score           -0.753151           -0.75049          -0.756362   \n",
       "split1_train_score          -0.698465          -0.708461          -0.704123   \n",
       "split0_train_score            -0.7036           -0.70111          -0.707386   \n",
       "rank_test_score                     4                  5                  2   \n",
       "split2_train_score          -0.699453          -0.703946          -0.695694   \n",
       "split3_test_score           -0.751043          -0.755829           -0.74909   \n",
       "split3_train_score          -0.697108          -0.707443          -0.696539   \n",
       "split4_test_score           -0.762375          -0.756667          -0.752977   \n",
       "split4_train_score          -0.704678          -0.701592          -0.698207   \n",
       "std_fit_time                0.0389804          0.0413817         0.00473018   \n",
       "split1_test_score           -0.753763          -0.762109           -0.75776   \n",
       "\n",
       "                                    9  \n",
       "mean_fit_time                0.596567  \n",
       "mean_score_time             0.0365136  \n",
       "std_score_time             0.00181547  \n",
       "split2_test_score           -0.761687  \n",
       "mean_test_score             -0.754148  \n",
       "mean_train_score            -0.698457  \n",
       "std_test_score             0.00450448  \n",
       "params              {'l1_ratio': 1.0}  \n",
       "std_train_score            0.00282435  \n",
       "param_l1_ratio                      1  \n",
       "split0_test_score           -0.751228  \n",
       "split1_train_score          -0.702949  \n",
       "split0_train_score          -0.700321  \n",
       "rank_test_score                     1  \n",
       "split2_train_score           -0.69546  \n",
       "split3_test_score           -0.749217  \n",
       "split3_train_score          -0.697675  \n",
       "split4_test_score            -0.75188  \n",
       "split4_train_score           -0.69588  \n",
       "std_fit_time                0.0317437  \n",
       "split1_test_score           -0.756725  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_model.cv_results_, orient='index')\n",
    "predict(ela_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So it turns out Ridge has better performence than Lossa. We don't need to really do elastic net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Elastic Net with Prediction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 1102302).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat_12, x_train_12 = vectorize_text(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/tf_vector_12_gram_min3.pickle', \n",
    "                                      matrix='../../static/tf_matrix_12_gram_min3.pickle', re_load=False,\n",
    "                                      min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=2)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_12 = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "[CV] ...................................... alpha=1e-05, total= 1.5min\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "[CV] ...................................... alpha=1e-05, total= 2.7min\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "[CV] ...................................... alpha=1e-05, total= 3.2min\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "[CV] ..................................... alpha=0.0001, total=  30.4s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "[CV] ...................................... alpha=1e-05, total= 3.6min\n",
      "[CV] ..................................... alpha=0.0001, total=  27.3s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "[CV] ..................................... alpha=0.0001, total=  32.9s\n",
      "[CV] ..................................... alpha=0.0001, total=  26.1s\n",
      "[CV] ..................................... alpha=0.0001, total=  29.6s\n",
      "[CV] ...................................... alpha=1e-05, total= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'alpha': [1e-05, 0.0001]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True,\n",
       "       scoring=<function score_mlr at 0x10751c598>, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ela_para = {'alpha': [1e-5, 1e-4]}\n",
    "ela_pre = GridSearchCV(ElasticNet(), ela_para, scoring=score_mlr, cv = 5, verbose=2, n_jobs=4)                         \n",
    "ela_pre.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.827446</td>\n",
       "      <td>-0.798283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.600691</td>\n",
       "      <td>-0.753622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.830804</td>\n",
       "      <td>-0.804493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00151323</td>\n",
       "      <td>0.00188013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.604444</td>\n",
       "      <td>-0.759017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.850614</td>\n",
       "      <td>-0.819575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>42.2386</td>\n",
       "      <td>2.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000850522</td>\n",
       "      <td>0.000595956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_alpha</th>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.604097</td>\n",
       "      <td>-0.757039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.815019</td>\n",
       "      <td>-0.793197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0040791</td>\n",
       "      <td>0.00356193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.603543</td>\n",
       "      <td>-0.757591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.60356</td>\n",
       "      <td>-0.757132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>167.551</td>\n",
       "      <td>29.2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.605025</td>\n",
       "      <td>-0.75839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0114842</td>\n",
       "      <td>0.00893042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.832252</td>\n",
       "      <td>-0.804664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.82869</td>\n",
       "      <td>-0.806748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   0                  1\n",
       "split4_test_score          -0.827446          -0.798283\n",
       "split3_train_score         -0.600691          -0.753622\n",
       "mean_test_score            -0.830804          -0.804493\n",
       "std_train_score           0.00151323         0.00188013\n",
       "split1_train_score         -0.604444          -0.759017\n",
       "split3_test_score          -0.850614          -0.819575\n",
       "std_fit_time                 42.2386              2.378\n",
       "std_score_time           0.000850522        0.000595956\n",
       "rank_test_score                    2                  1\n",
       "param_alpha                    1e-05             0.0001\n",
       "split2_train_score         -0.604097          -0.757039\n",
       "split1_test_score          -0.815019          -0.793197\n",
       "mean_score_time            0.0040791         0.00356193\n",
       "split0_train_score         -0.603543          -0.757591\n",
       "mean_train_score            -0.60356          -0.757132\n",
       "mean_fit_time                167.551            29.2644\n",
       "split4_train_score         -0.605025           -0.75839\n",
       "std_test_score             0.0114842         0.00893042\n",
       "params              {'alpha': 1e-05}  {'alpha': 0.0001}\n",
       "split2_test_score          -0.832252          -0.804664\n",
       "split0_test_score           -0.82869          -0.806748"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(ela_pre.cv_results_, orient='index')\n",
    "predict_mlr(ela_pre, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Try not using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 55778).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat_c, x_train_c = vectorize_text_count(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/count_vector.pickle', \n",
    "                                      matrix='../../static/count_matrix.pickle', re_load=False)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train_c = list(map(str, table_train['stars'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] ........................................... C=0.03, total=  18.6s\n",
      "[CV] C=0.03 ..........................................................\n",
      "[CV] ........................................... C=0.03, total=  18.7s\n",
      "[CV] ........................................... C=0.03, total=  18.9s\n",
      "[CV] ........................................... C=0.03, total=  18.8s\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] ........................................... C=0.03, total=  22.6s\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] ........................................... C=0.07, total=  30.3s\n",
      "[CV] C=0.07 ..........................................................\n",
      "[CV] ........................................... C=0.07, total=  31.9s\n",
      "[CV] C=0.09 ..........................................................\n",
      "[CV] ........................................... C=0.07, total=  32.3s\n",
      "[CV] C=0.09 ..........................................................\n",
      "[CV] ........................................... C=0.07, total=  29.1s\n",
      "[CV] C=0.09 ..........................................................\n",
      "[CV] ........................................... C=0.07, total=  24.1s\n",
      "[CV] C=0.09 ..........................................................\n",
      "[CV] ........................................... C=0.09, total=  30.9s\n",
      "[CV] C=0.09 ..........................................................\n",
      "[CV] ........................................... C=0.09, total=  31.1s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ........................................... C=0.09, total=  24.8s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ........................................... C=0.09, total=  26.2s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ........................................... C=0.09, total=  26.3s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ............................................ C=0.2, total=  44.7s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ............................................ C=0.2, total=  46.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.2, total=  48.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.2, total=  48.4s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.2, total=  43.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total= 1.1min\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ............................................ C=0.5, total= 1.0min\n",
      "[CV] C=0.7 ...........................................................\n",
      "[CV] ............................................ C=0.5, total= 1.1min\n",
      "[CV] C=0.7 ...........................................................\n",
      "[CV] ............................................ C=0.5, total= 1.1min\n",
      "[CV] C=0.7 ...........................................................\n",
      "[CV] ............................................ C=0.5, total= 1.2min\n",
      "[CV] C=0.7 ...........................................................\n",
      "[CV] ............................................ C=0.7, total= 1.4min\n",
      "[CV] C=0.7 ...........................................................\n",
      "[CV] ............................................ C=0.7, total= 1.4min\n",
      "[CV] ............................................ C=0.7, total= 1.4min\n",
      "[CV] ............................................ C=0.7, total=  56.6s\n",
      "[CV] ............................................ C=0.7, total=  52.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': [0.03, 0.07, 0.09, 0.2, 0.5, 0.7]}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False),\n",
    "                          param_grid, scoring=score, cv=5, n_jobs=4, verbose=2)\n",
    "\n",
    "better_model.fit(x_train_c, y_train_c)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_count'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 55778).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.796542</td>\n",
       "      <td>-0.779391</td>\n",
       "      <td>-0.776097</td>\n",
       "      <td>-0.77072</td>\n",
       "      <td>-0.773472</td>\n",
       "      <td>-0.776843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.726452</td>\n",
       "      <td>-0.674326</td>\n",
       "      <td>-0.658341</td>\n",
       "      <td>-0.604458</td>\n",
       "      <td>-0.535222</td>\n",
       "      <td>-0.507823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.795992</td>\n",
       "      <td>-0.779601</td>\n",
       "      <td>-0.776625</td>\n",
       "      <td>-0.772499</td>\n",
       "      <td>-0.777432</td>\n",
       "      <td>-0.781816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000899204</td>\n",
       "      <td>0.000759678</td>\n",
       "      <td>0.000762437</td>\n",
       "      <td>0.00087802</td>\n",
       "      <td>0.00107791</td>\n",
       "      <td>0.00118423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.728126</td>\n",
       "      <td>-0.675712</td>\n",
       "      <td>-0.659722</td>\n",
       "      <td>-0.605891</td>\n",
       "      <td>-0.536886</td>\n",
       "      <td>-0.509745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.796955</td>\n",
       "      <td>-0.781424</td>\n",
       "      <td>-0.778825</td>\n",
       "      <td>-0.775953</td>\n",
       "      <td>-0.781918</td>\n",
       "      <td>-0.786582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>1.5058</td>\n",
       "      <td>2.94923</td>\n",
       "      <td>2.62902</td>\n",
       "      <td>1.98345</td>\n",
       "      <td>4.53613</td>\n",
       "      <td>14.9812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.0178429</td>\n",
       "      <td>0.00659208</td>\n",
       "      <td>0.00701611</td>\n",
       "      <td>0.0139558</td>\n",
       "      <td>0.0317628</td>\n",
       "      <td>0.0257985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.725434</td>\n",
       "      <td>-0.67373</td>\n",
       "      <td>-0.657898</td>\n",
       "      <td>-0.604365</td>\n",
       "      <td>-0.535472</td>\n",
       "      <td>-0.508185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.793982</td>\n",
       "      <td>-0.777696</td>\n",
       "      <td>-0.774751</td>\n",
       "      <td>-0.770363</td>\n",
       "      <td>-0.77387</td>\n",
       "      <td>-0.777503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0975264</td>\n",
       "      <td>0.0877451</td>\n",
       "      <td>0.0889888</td>\n",
       "      <td>0.0967586</td>\n",
       "      <td>0.112118</td>\n",
       "      <td>0.0760234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.727344</td>\n",
       "      <td>-0.67562</td>\n",
       "      <td>-0.659854</td>\n",
       "      <td>-0.606686</td>\n",
       "      <td>-0.538157</td>\n",
       "      <td>-0.51105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.726822</td>\n",
       "      <td>-0.674816</td>\n",
       "      <td>-0.658924</td>\n",
       "      <td>-0.605375</td>\n",
       "      <td>-0.536545</td>\n",
       "      <td>-0.509336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>19.4154</td>\n",
       "      <td>29.4408</td>\n",
       "      <td>27.7472</td>\n",
       "      <td>46.0543</td>\n",
       "      <td>65.5965</td>\n",
       "      <td>72.8014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.726753</td>\n",
       "      <td>-0.674692</td>\n",
       "      <td>-0.658806</td>\n",
       "      <td>-0.605475</td>\n",
       "      <td>-0.536987</td>\n",
       "      <td>-0.509878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00364021</td>\n",
       "      <td>0.00384704</td>\n",
       "      <td>0.00398789</td>\n",
       "      <td>0.00490056</td>\n",
       "      <td>0.00667878</td>\n",
       "      <td>0.007449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.03}</td>\n",
       "      <td>{'C': 0.07}</td>\n",
       "      <td>{'C': 0.09}</td>\n",
       "      <td>{'C': 0.2}</td>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>{'C': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.801758</td>\n",
       "      <td>-0.785534</td>\n",
       "      <td>-0.78268</td>\n",
       "      <td>-0.779812</td>\n",
       "      <td>-0.788169</td>\n",
       "      <td>-0.794107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.790726</td>\n",
       "      <td>-0.773962</td>\n",
       "      <td>-0.770775</td>\n",
       "      <td>-0.765649</td>\n",
       "      <td>-0.769734</td>\n",
       "      <td>-0.774049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0            1            2           3  \\\n",
       "split4_test_score     -0.796542    -0.779391    -0.776097    -0.77072   \n",
       "split3_train_score    -0.726452    -0.674326    -0.658341   -0.604458   \n",
       "mean_test_score       -0.795992    -0.779601    -0.776625   -0.772499   \n",
       "std_train_score     0.000899204  0.000759678  0.000762437  0.00087802   \n",
       "split1_train_score    -0.728126    -0.675712    -0.659722   -0.605891   \n",
       "split3_test_score     -0.796955    -0.781424    -0.778825   -0.775953   \n",
       "std_fit_time             1.5058      2.94923      2.62902     1.98345   \n",
       "std_score_time        0.0178429   0.00659208   0.00701611   0.0139558   \n",
       "rank_test_score               6            4            2           1   \n",
       "param_C                    0.03         0.07         0.09         0.2   \n",
       "split2_train_score    -0.725434     -0.67373    -0.657898   -0.604365   \n",
       "split1_test_score     -0.793982    -0.777696    -0.774751   -0.770363   \n",
       "mean_score_time       0.0975264    0.0877451    0.0889888   0.0967586   \n",
       "split0_train_score    -0.727344     -0.67562    -0.659854   -0.606686   \n",
       "mean_train_score      -0.726822    -0.674816    -0.658924   -0.605375   \n",
       "mean_fit_time           19.4154      29.4408      27.7472     46.0543   \n",
       "split4_train_score    -0.726753    -0.674692    -0.658806   -0.605475   \n",
       "std_test_score       0.00364021   0.00384704   0.00398789  0.00490056   \n",
       "params              {'C': 0.03}  {'C': 0.07}  {'C': 0.09}  {'C': 0.2}   \n",
       "split2_test_score     -0.801758    -0.785534     -0.78268   -0.779812   \n",
       "split0_test_score     -0.790726    -0.773962    -0.770775   -0.765649   \n",
       "\n",
       "                             4           5  \n",
       "split4_test_score    -0.773472   -0.776843  \n",
       "split3_train_score   -0.535222   -0.507823  \n",
       "mean_test_score      -0.777432   -0.781816  \n",
       "std_train_score     0.00107791  0.00118423  \n",
       "split1_train_score   -0.536886   -0.509745  \n",
       "split3_test_score    -0.781918   -0.786582  \n",
       "std_fit_time           4.53613     14.9812  \n",
       "std_score_time       0.0317628   0.0257985  \n",
       "rank_test_score              3           5  \n",
       "param_C                    0.5         0.7  \n",
       "split2_train_score   -0.535472   -0.508185  \n",
       "split1_test_score     -0.77387   -0.777503  \n",
       "mean_score_time       0.112118   0.0760234  \n",
       "split0_train_score   -0.538157    -0.51105  \n",
       "mean_train_score     -0.536545   -0.509336  \n",
       "mean_fit_time          65.5965     72.8014  \n",
       "split4_train_score   -0.536987   -0.509878  \n",
       "std_test_score      0.00667878    0.007449  \n",
       "params              {'C': 0.5}  {'C': 0.7}  \n",
       "split2_test_score    -0.788169   -0.794107  \n",
       "split0_test_score    -0.769734   -0.774049  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "predict_mlr(better_model, all_mat_c, x_train_c.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.177035528504\n",
      "  (0, 18)\t0.0914622594844\n",
      "  (0, 20)\t0.0522683063597\n",
      "  (0, 21)\t0.0513662342105\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discuss\n",
      "16-17\n",
      "biz\n",
      "soundproof\n",
      "lacross\n",
      "litmus\n",
      "entre\n",
      "ar\n",
      "montana\n",
      "yayyy\n",
      "23617\n"
     ]
    }
   ],
   "source": [
    "# coef = better_model.best_estimator_.coef_[0]\n",
    "# index = np.argpartition(coef, -100)[-100:]\n",
    "index = [7067, 868, 3652, 19508, 12097, 12503, 7884, 2618, 13874, 23389]\n",
    "for i in index:\n",
    "    for k, v in tf.vocabulary_.items():\n",
    "        if i == v:\n",
    "            print(k)\n",
    "print(len(tf.vocabulary_.items())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = load(open(\"./config/model_lasso_1-6.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coef1 = model.best_estimator_.coef_[0]\n",
    "coef2 = model.best_estimator_.coef_[1]\n",
    "coef1_no = [i for i in coef1 if i != 0]\n",
    "coef2_no = [i for i in coef2 if i != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1175"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef1 = model.best_estimator_.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coef2_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Presentation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   9.6s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=  10.1s\n",
      "[CV] C=1.04081632653 .................................................\n",
      "[CV] ............................................ C=1.0, total=  10.4s\n",
      "[CV] C=1.04081632653 .................................................\n",
      "[CV] ............................................ C=1.0, total=  10.2s\n",
      "[CV] C=1.04081632653 .................................................\n",
      "[CV] ............................................ C=1.0, total=  11.4s\n",
      "[CV] C=1.04081632653 .................................................\n",
      "[CV] .................................. C=1.04081632653, total=  11.2s\n",
      "[CV] .................................. C=1.04081632653, total=  10.9s\n",
      "[CV] C=1.04081632653 .................................................\n",
      "[CV] C=1.08163265306 .................................................\n",
      "[CV] .................................. C=1.04081632653, total=  11.4s\n",
      "[CV] C=1.08163265306 .................................................\n",
      "[CV] .................................. C=1.04081632653, total=  11.3s\n",
      "[CV] C=1.08163265306 .................................................\n",
      "[CV] .................................. C=1.08163265306, total=  11.4s\n",
      "[CV] .................................. C=1.04081632653, total=  11.5s\n",
      "[CV] C=1.08163265306 .................................................\n",
      "[CV] C=1.08163265306 .................................................\n",
      "[CV] .................................. C=1.08163265306, total=  11.3s\n",
      "[CV] C=1.12244897959 .................................................\n",
      "[CV] .................................. C=1.08163265306, total=   9.4s\n",
      "[CV] C=1.12244897959 .................................................\n",
      "[CV] .................................. C=1.12244897959, total=   9.1s\n",
      "[CV] .................................. C=1.08163265306, total=   9.4s\n",
      "[CV] C=1.12244897959 .................................................\n",
      "[CV] C=1.12244897959 .................................................\n",
      "[CV] .................................. C=1.08163265306, total=   9.6s\n",
      "[CV] C=1.12244897959 .................................................\n",
      "[CV] .................................. C=1.12244897959, total=   8.9s\n",
      "[CV] .................................. C=1.12244897959, total=   9.3s\n",
      "[CV] C=1.16326530612 .................................................\n",
      "[CV] C=1.16326530612 .................................................\n",
      "[CV] .................................. C=1.12244897959, total=   9.0s\n",
      "[CV] C=1.16326530612 .................................................\n",
      "[CV] .................................. C=1.12244897959, total=   9.4s\n",
      "[CV] C=1.16326530612 .................................................\n",
      "[CV] .................................. C=1.16326530612, total=  12.8s\n",
      "[CV] C=1.16326530612 .................................................\n",
      "[CV] .................................. C=1.16326530612, total=  13.2s\n",
      "[CV] C=1.20408163265 .................................................\n",
      "[CV] .................................. C=1.16326530612, total=  13.0s\n",
      "[CV] C=1.20408163265 .................................................\n",
      "[CV] .................................. C=1.16326530612, total=  13.1s\n",
      "[CV] C=1.20408163265 .................................................\n",
      "[CV] .................................. C=1.16326530612, total=  10.4s\n",
      "[CV] C=1.20408163265 .................................................\n",
      "[CV] .................................. C=1.20408163265, total=  10.2s\n",
      "[CV] C=1.20408163265 .................................................\n",
      "[CV] .................................. C=1.20408163265, total=   9.7s\n",
      "[CV] C=1.24489795918 .................................................\n",
      "[CV] .................................. C=1.20408163265, total=  10.3s\n",
      "[CV] C=1.24489795918 .................................................\n",
      "[CV] .................................. C=1.20408163265, total=  13.1s\n",
      "[CV] C=1.24489795918 .................................................\n",
      "[CV] .................................. C=1.20408163265, total=  13.5s\n",
      "[CV] C=1.24489795918 .................................................\n",
      "[CV] .................................. C=1.24489795918, total=  13.3s\n",
      "[CV] C=1.24489795918 .................................................\n",
      "[CV] .................................. C=1.24489795918, total=  13.5s\n",
      "[CV] C=1.28571428571 .................................................\n",
      "[CV] .................................. C=1.24489795918, total=  11.7s\n",
      "[CV] C=1.28571428571 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=1.24489795918, total=  12.2s\n",
      "[CV] C=1.28571428571 .................................................\n",
      "[CV] .................................. C=1.28571428571, total=  12.1s\n",
      "[CV] .................................. C=1.24489795918, total=  12.7s\n",
      "[CV] C=1.28571428571 .................................................\n",
      "[CV] C=1.28571428571 .................................................\n",
      "[CV] .................................. C=1.28571428571, total=  12.3s\n",
      "[CV] C=1.32653061224 .................................................\n",
      "[CV] .................................. C=1.28571428571, total=  12.4s\n",
      "[CV] C=1.32653061224 .................................................\n",
      "[CV] .................................. C=1.28571428571, total=  12.4s\n",
      "[CV] C=1.32653061224 .................................................\n",
      "[CV] .................................. C=1.28571428571, total=  12.8s\n",
      "[CV] C=1.32653061224 .................................................\n",
      "[CV] .................................. C=1.32653061224, total=  11.1s\n",
      "[CV] C=1.32653061224 .................................................\n",
      "[CV] .................................. C=1.32653061224, total=  11.1s\n",
      "[CV] C=1.36734693878 .................................................\n",
      "[CV] .................................. C=1.32653061224, total=  10.4s\n",
      "[CV] C=1.36734693878 .................................................\n",
      "[CV] .................................. C=1.32653061224, total=  11.1s\n",
      "[CV] C=1.36734693878 .................................................\n",
      "[CV] .................................. C=1.32653061224, total=  11.0s\n",
      "[CV] C=1.36734693878 .................................................\n",
      "[CV] .................................. C=1.36734693878, total=  11.4s\n",
      "[CV] C=1.36734693878 .................................................\n",
      "[CV] .................................. C=1.36734693878, total=  11.9s\n",
      "[CV] C=1.40816326531 .................................................\n",
      "[CV] .................................. C=1.36734693878, total=  12.4s\n",
      "[CV] C=1.40816326531 .................................................\n",
      "[CV] .................................. C=1.36734693878, total=  13.3s\n",
      "[CV] C=1.40816326531 .................................................\n",
      "[CV] .................................. C=1.36734693878, total=  12.9s\n",
      "[CV] C=1.40816326531 .................................................\n",
      "[CV] .................................. C=1.40816326531, total=  13.0s\n",
      "[CV] C=1.40816326531 .................................................\n",
      "[CV] .................................. C=1.40816326531, total=  12.8s\n",
      "[CV] C=1.44897959184 .................................................\n",
      "[CV] .................................. C=1.40816326531, total=  10.7s\n",
      "[CV] C=1.44897959184 .................................................\n",
      "[CV] .................................. C=1.40816326531, total=  11.0s\n",
      "[CV] C=1.44897959184 .................................................\n",
      "[CV] .................................. C=1.40816326531, total=  11.1s\n",
      "[CV] C=1.44897959184 .................................................\n",
      "[CV] .................................. C=1.44897959184, total=  10.6s\n",
      "[CV] C=1.44897959184 .................................................\n",
      "[CV] .................................. C=1.44897959184, total=  10.6s\n",
      "[CV] C=1.48979591837 .................................................\n",
      "[CV] .................................. C=1.44897959184, total=  10.4s\n",
      "[CV] C=1.48979591837 .................................................\n",
      "[CV] .................................. C=1.44897959184, total=  10.2s\n",
      "[CV] C=1.48979591837 .................................................\n",
      "[CV] .................................. C=1.44897959184, total=  10.0s\n",
      "[CV] C=1.48979591837 .................................................\n",
      "[CV] .................................. C=1.48979591837, total=  10.9s\n",
      "[CV] C=1.48979591837 .................................................\n",
      "[CV] .................................. C=1.48979591837, total=  11.0s\n",
      "[CV] C=1.5306122449 ..................................................\n",
      "[CV] .................................. C=1.48979591837, total=  11.0s\n",
      "[CV] C=1.5306122449 ..................................................\n",
      "[CV] .................................. C=1.48979591837, total=  10.6s\n",
      "[CV] C=1.5306122449 ..................................................\n",
      "[CV] .................................. C=1.48979591837, total=  10.6s\n",
      "[CV] C=1.5306122449 ..................................................\n",
      "[CV] ................................... C=1.5306122449, total=  11.2s\n",
      "[CV] C=1.5306122449 ..................................................\n",
      "[CV] ................................... C=1.5306122449, total=  11.0s\n",
      "[CV] C=1.57142857143 .................................................\n",
      "[CV] ................................... C=1.5306122449, total=  11.3s\n",
      "[CV] C=1.57142857143 .................................................\n",
      "[CV] ................................... C=1.5306122449, total=  11.6s\n",
      "[CV] C=1.57142857143 .................................................\n",
      "[CV] .................................. C=1.57142857143, total=  11.8s\n",
      "[CV] C=1.57142857143 .................................................\n",
      "[CV] ................................... C=1.5306122449, total=  12.1s\n",
      "[CV] C=1.57142857143 .................................................\n",
      "[CV] .................................. C=1.57142857143, total=  12.0s\n",
      "[CV] C=1.61224489796 .................................................\n",
      "[CV] .................................. C=1.57142857143, total=  12.6s\n",
      "[CV] C=1.61224489796 .................................................\n",
      "[CV] .................................. C=1.57142857143, total=  12.5s\n",
      "[CV] C=1.61224489796 .................................................\n",
      "[CV] .................................. C=1.57142857143, total=  12.8s\n",
      "[CV] C=1.61224489796 .................................................\n",
      "[CV] .................................. C=1.61224489796, total=  12.4s\n",
      "[CV] C=1.61224489796 .................................................\n",
      "[CV] .................................. C=1.61224489796, total=  11.6s\n",
      "[CV] C=1.65306122449 .................................................\n",
      "[CV] .................................. C=1.61224489796, total=  11.4s\n",
      "[CV] C=1.65306122449 .................................................\n",
      "[CV] .................................. C=1.61224489796, total=  11.6s\n",
      "[CV] C=1.65306122449 .................................................\n",
      "[CV] .................................. C=1.61224489796, total=  11.4s\n",
      "[CV] C=1.65306122449 .................................................\n",
      "[CV] .................................. C=1.65306122449, total=  13.0s\n",
      "[CV] C=1.65306122449 .................................................\n",
      "[CV] .................................. C=1.65306122449, total=  13.1s\n",
      "[CV] C=1.69387755102 .................................................\n",
      "[CV] .................................. C=1.65306122449, total=  13.3s\n",
      "[CV] C=1.69387755102 .................................................\n",
      "[CV] .................................. C=1.65306122449, total=  13.8s\n",
      "[CV] C=1.69387755102 .................................................\n",
      "[CV] .................................. C=1.65306122449, total=  12.0s\n",
      "[CV] C=1.69387755102 .................................................\n",
      "[CV] .................................. C=1.69387755102, total=  11.9s\n",
      "[CV] C=1.69387755102 .................................................\n",
      "[CV] .................................. C=1.69387755102, total=  12.1s\n",
      "[CV] C=1.73469387755 .................................................\n",
      "[CV] .................................. C=1.69387755102, total=  11.9s\n",
      "[CV] C=1.73469387755 .................................................\n",
      "[CV] .................................. C=1.69387755102, total=  10.5s\n",
      "[CV] C=1.73469387755 .................................................\n",
      "[CV] .................................. C=1.69387755102, total=  11.1s\n",
      "[CV] C=1.73469387755 .................................................\n",
      "[CV] .................................. C=1.73469387755, total=  11.4s\n",
      "[CV] C=1.73469387755 .................................................\n",
      "[CV] .................................. C=1.73469387755, total=  11.5s\n",
      "[CV] C=1.77551020408 .................................................\n",
      "[CV] .................................. C=1.73469387755, total=  12.8s\n",
      "[CV] C=1.77551020408 .................................................\n",
      "[CV] .................................. C=1.73469387755, total=  13.6s\n",
      "[CV] C=1.77551020408 .................................................\n",
      "[CV] .................................. C=1.73469387755, total=  14.4s\n",
      "[CV] C=1.77551020408 .................................................\n",
      "[CV] .................................. C=1.77551020408, total=  14.5s\n",
      "[CV] C=1.77551020408 .................................................\n",
      "[CV] .................................. C=1.77551020408, total=  14.5s\n",
      "[CV] C=1.81632653061 .................................................\n",
      "[CV] .................................. C=1.77551020408, total=  13.7s\n",
      "[CV] C=1.81632653061 .................................................\n",
      "[CV] .................................. C=1.77551020408, total=  14.6s\n",
      "[CV] C=1.81632653061 .................................................\n",
      "[CV] .................................. C=1.77551020408, total=  14.9s\n",
      "[CV] C=1.81632653061 .................................................\n",
      "[CV] .................................. C=1.81632653061, total=  11.6s\n",
      "[CV] C=1.81632653061 .................................................\n",
      "[CV] .................................. C=1.81632653061, total=  11.0s\n",
      "[CV] C=1.85714285714 .................................................\n",
      "[CV] .................................. C=1.81632653061, total=  10.4s\n",
      "[CV] C=1.85714285714 .................................................\n",
      "[CV] .................................. C=1.81632653061, total=  10.6s\n",
      "[CV] C=1.85714285714 .................................................\n",
      "[CV] .................................. C=1.81632653061, total=  10.7s\n",
      "[CV] C=1.85714285714 .................................................\n",
      "[CV] .................................. C=1.85714285714, total=  10.6s\n",
      "[CV] C=1.85714285714 .................................................\n",
      "[CV] .................................. C=1.85714285714, total=  10.4s\n",
      "[CV] C=1.89795918367 .................................................\n",
      "[CV] .................................. C=1.85714285714, total=  10.8s\n",
      "[CV] C=1.89795918367 .................................................\n",
      "[CV] .................................. C=1.85714285714, total=  10.8s\n",
      "[CV] C=1.89795918367 .................................................\n",
      "[CV] .................................. C=1.85714285714, total=  10.9s\n",
      "[CV] C=1.89795918367 .................................................\n",
      "[CV] .................................. C=1.89795918367, total=  11.1s\n",
      "[CV] C=1.89795918367 .................................................\n",
      "[CV] .................................. C=1.89795918367, total=  11.3s\n",
      "[CV] C=1.9387755102 ..................................................\n",
      "[CV] .................................. C=1.89795918367, total=  11.1s\n",
      "[CV] C=1.9387755102 ..................................................\n",
      "[CV] .................................. C=1.89795918367, total=  11.1s\n",
      "[CV] C=1.9387755102 ..................................................\n",
      "[CV] .................................. C=1.89795918367, total=  10.6s\n",
      "[CV] C=1.9387755102 ..................................................\n",
      "[CV] ................................... C=1.9387755102, total=  10.7s\n",
      "[CV] C=1.9387755102 ..................................................\n",
      "[CV] ................................... C=1.9387755102, total=  12.9s\n",
      "[CV] C=1.97959183673 .................................................\n",
      "[CV] ................................... C=1.9387755102, total=  13.3s\n",
      "[CV] C=1.97959183673 .................................................\n",
      "[CV] ................................... C=1.9387755102, total=  15.0s\n",
      "[CV] C=1.97959183673 .................................................\n",
      "[CV] ................................... C=1.9387755102, total=  16.2s\n",
      "[CV] C=1.97959183673 .................................................\n",
      "[CV] .................................. C=1.97959183673, total=  17.8s\n",
      "[CV] C=1.97959183673 .................................................\n",
      "[CV] .................................. C=1.97959183673, total=  17.1s\n",
      "[CV] C=2.02040816327 .................................................\n",
      "[CV] .................................. C=1.97959183673, total=  15.6s\n",
      "[CV] C=2.02040816327 .................................................\n",
      "[CV] .................................. C=1.97959183673, total=  14.2s\n",
      "[CV] C=2.02040816327 .................................................\n",
      "[CV] .................................. C=1.97959183673, total=  11.0s\n",
      "[CV] C=2.02040816327 .................................................\n",
      "[CV] .................................. C=2.02040816327, total=  11.0s\n",
      "[CV] C=2.02040816327 .................................................\n",
      "[CV] .................................. C=2.02040816327, total=  11.0s\n",
      "[CV] C=2.0612244898 ..................................................\n",
      "[CV] .................................. C=2.02040816327, total=  11.2s\n",
      "[CV] C=2.0612244898 ..................................................\n",
      "[CV] .................................. C=2.02040816327, total=  11.4s\n",
      "[CV] C=2.0612244898 ..................................................\n",
      "[CV] .................................. C=2.02040816327, total=  11.9s\n",
      "[CV] C=2.0612244898 ..................................................\n",
      "[CV] ................................... C=2.0612244898, total=  12.7s\n",
      "[CV] C=2.0612244898 ..................................................\n",
      "[CV] ................................... C=2.0612244898, total=  13.8s\n",
      "[CV] C=2.10204081633 .................................................\n",
      "[CV] ................................... C=2.0612244898, total=  15.6s\n",
      "[CV] C=2.10204081633 .................................................\n",
      "[CV] ................................... C=2.0612244898, total=  14.5s\n",
      "[CV] C=2.10204081633 .................................................\n",
      "[CV] ................................... C=2.0612244898, total=  13.9s\n",
      "[CV] C=2.10204081633 .................................................\n",
      "[CV] .................................. C=2.10204081633, total=  12.8s\n",
      "[CV] C=2.10204081633 .................................................\n",
      "[CV] .................................. C=2.10204081633, total=  12.2s\n",
      "[CV] C=2.14285714286 .................................................\n",
      "[CV] .................................. C=2.10204081633, total=  12.3s\n",
      "[CV] C=2.14285714286 .................................................\n",
      "[CV] .................................. C=2.10204081633, total=  12.2s\n",
      "[CV] C=2.14285714286 .................................................\n",
      "[CV] .................................. C=2.10204081633, total=  12.5s\n",
      "[CV] C=2.14285714286 .................................................\n",
      "[CV] .................................. C=2.14285714286, total=  12.4s\n",
      "[CV] C=2.14285714286 .................................................\n",
      "[CV] .................................. C=2.14285714286, total=  12.4s\n",
      "[CV] C=2.18367346939 .................................................\n",
      "[CV] .................................. C=2.14285714286, total=  12.3s\n",
      "[CV] C=2.18367346939 .................................................\n",
      "[CV] .................................. C=2.14285714286, total=  13.5s\n",
      "[CV] C=2.18367346939 .................................................\n",
      "[CV] .................................. C=2.14285714286, total=  16.0s\n",
      "[CV] C=2.18367346939 .................................................\n",
      "[CV] .................................. C=2.18367346939, total=  15.5s\n",
      "[CV] C=2.18367346939 .................................................\n",
      "[CV] .................................. C=2.18367346939, total=  15.4s\n",
      "[CV] C=2.22448979592 .................................................\n",
      "[CV] .................................. C=2.18367346939, total=  14.8s\n",
      "[CV] C=2.22448979592 .................................................\n",
      "[CV] .................................. C=2.18367346939, total=  13.1s\n",
      "[CV] C=2.22448979592 .................................................\n",
      "[CV] .................................. C=2.18367346939, total=  12.9s\n",
      "[CV] C=2.22448979592 .................................................\n",
      "[CV] .................................. C=2.22448979592, total=  12.8s\n",
      "[CV] C=2.22448979592 .................................................\n",
      "[CV] .................................. C=2.22448979592, total=  13.8s\n",
      "[CV] C=2.26530612245 .................................................\n",
      "[CV] .................................. C=2.22448979592, total=  14.9s\n",
      "[CV] C=2.26530612245 .................................................\n",
      "[CV] .................................. C=2.22448979592, total=  15.2s\n",
      "[CV] C=2.26530612245 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  8.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=2.22448979592, total=  15.6s\n",
      "[CV] C=2.26530612245 .................................................\n",
      "[CV] .................................. C=2.26530612245, total=  14.1s\n",
      "[CV] C=2.26530612245 .................................................\n",
      "[CV] .................................. C=2.26530612245, total=  13.5s\n",
      "[CV] C=2.30612244898 .................................................\n",
      "[CV] .................................. C=2.26530612245, total=  13.3s\n",
      "[CV] C=2.30612244898 .................................................\n",
      "[CV] .................................. C=2.26530612245, total=  12.9s\n",
      "[CV] C=2.30612244898 .................................................\n",
      "[CV] .................................. C=2.26530612245, total=  12.7s\n",
      "[CV] C=2.30612244898 .................................................\n",
      "[CV] .................................. C=2.30612244898, total=  12.5s\n",
      "[CV] C=2.30612244898 .................................................\n",
      "[CV] .................................. C=2.30612244898, total=  12.4s\n",
      "[CV] C=2.34693877551 .................................................\n",
      "[CV] .................................. C=2.30612244898, total=  13.0s\n",
      "[CV] C=2.34693877551 .................................................\n",
      "[CV] .................................. C=2.30612244898, total=  12.9s\n",
      "[CV] C=2.34693877551 .................................................\n",
      "[CV] .................................. C=2.34693877551, total=  14.2s\n",
      "[CV] C=2.34693877551 .................................................\n",
      "[CV] .................................. C=2.30612244898, total=  16.0s\n",
      "[CV] C=2.34693877551 .................................................\n",
      "[CV] .................................. C=2.34693877551, total=  15.2s\n",
      "[CV] C=2.38775510204 .................................................\n",
      "[CV] .................................. C=2.34693877551, total=  16.3s\n",
      "[CV] C=2.38775510204 .................................................\n",
      "[CV] .................................. C=2.34693877551, total=  15.3s\n",
      "[CV] C=2.38775510204 .................................................\n",
      "[CV] .................................. C=2.34693877551, total=  15.1s\n",
      "[CV] C=2.38775510204 .................................................\n",
      "[CV] .................................. C=2.38775510204, total=  14.4s\n",
      "[CV] C=2.38775510204 .................................................\n",
      "[CV] .................................. C=2.38775510204, total=  13.9s\n",
      "[CV] C=2.42857142857 .................................................\n",
      "[CV] .................................. C=2.38775510204, total=  13.4s\n",
      "[CV] C=2.42857142857 .................................................\n",
      "[CV] .................................. C=2.38775510204, total=  13.4s\n",
      "[CV] C=2.42857142857 .................................................\n",
      "[CV] .................................. C=2.38775510204, total=  13.2s\n",
      "[CV] C=2.42857142857 .................................................\n",
      "[CV] .................................. C=2.42857142857, total=  15.2s\n",
      "[CV] C=2.42857142857 .................................................\n",
      "[CV] .................................. C=2.42857142857, total=  18.6s\n",
      "[CV] C=2.4693877551 ..................................................\n",
      "[CV] .................................. C=2.42857142857, total=  18.8s\n",
      "[CV] C=2.4693877551 ..................................................\n",
      "[CV] .................................. C=2.42857142857, total=  19.0s\n",
      "[CV] C=2.4693877551 ..................................................\n",
      "[CV] .................................. C=2.42857142857, total=  18.3s\n",
      "[CV] C=2.4693877551 ..................................................\n",
      "[CV] ................................... C=2.4693877551, total=  16.8s\n",
      "[CV] C=2.4693877551 ..................................................\n",
      "[CV] ................................... C=2.4693877551, total=  17.9s\n",
      "[CV] C=2.51020408163 .................................................\n",
      "[CV] ................................... C=2.4693877551, total=  17.7s\n",
      "[CV] C=2.51020408163 .................................................\n",
      "[CV] ................................... C=2.4693877551, total=  18.8s\n",
      "[CV] C=2.51020408163 .................................................\n",
      "[CV] ................................... C=2.4693877551, total=  16.7s\n",
      "[CV] C=2.51020408163 .................................................\n",
      "[CV] .................................. C=2.51020408163, total=  16.8s\n",
      "[CV] C=2.51020408163 .................................................\n",
      "[CV] .................................. C=2.51020408163, total=  16.5s\n",
      "[CV] C=2.55102040816 .................................................\n",
      "[CV] .................................. C=2.51020408163, total=  15.3s\n",
      "[CV] C=2.55102040816 .................................................\n",
      "[CV] .................................. C=2.51020408163, total=  14.7s\n",
      "[CV] C=2.55102040816 .................................................\n",
      "[CV] .................................. C=2.51020408163, total=  15.2s\n",
      "[CV] C=2.55102040816 .................................................\n",
      "[CV] .................................. C=2.55102040816, total=  15.2s\n",
      "[CV] C=2.55102040816 .................................................\n",
      "[CV] .................................. C=2.55102040816, total=  15.5s\n",
      "[CV] C=2.59183673469 .................................................\n",
      "[CV] .................................. C=2.55102040816, total=  16.6s\n",
      "[CV] C=2.59183673469 .................................................\n",
      "[CV] .................................. C=2.55102040816, total=  15.6s\n",
      "[CV] C=2.59183673469 .................................................\n",
      "[CV] .................................. C=2.55102040816, total=  16.0s\n",
      "[CV] C=2.59183673469 .................................................\n",
      "[CV] .................................. C=2.59183673469, total=  15.7s\n",
      "[CV] C=2.59183673469 .................................................\n",
      "[CV] .................................. C=2.59183673469, total=  15.7s\n",
      "[CV] C=2.63265306122 .................................................\n",
      "[CV] .................................. C=2.59183673469, total=  15.9s\n",
      "[CV] C=2.63265306122 .................................................\n",
      "[CV] .................................. C=2.59183673469, total=  15.6s\n",
      "[CV] C=2.63265306122 .................................................\n",
      "[CV] .................................. C=2.59183673469, total=  15.5s\n",
      "[CV] C=2.63265306122 .................................................\n",
      "[CV] .................................. C=2.63265306122, total=  17.3s\n",
      "[CV] C=2.63265306122 .................................................\n",
      "[CV] .................................. C=2.63265306122, total=  17.8s\n",
      "[CV] C=2.67346938776 .................................................\n",
      "[CV] .................................. C=2.63265306122, total=  18.0s\n",
      "[CV] C=2.67346938776 .................................................\n",
      "[CV] .................................. C=2.63265306122, total=  17.7s\n",
      "[CV] C=2.67346938776 .................................................\n",
      "[CV] .................................. C=2.63265306122, total=  14.2s\n",
      "[CV] C=2.67346938776 .................................................\n",
      "[CV] .................................. C=2.67346938776, total=  13.6s\n",
      "[CV] C=2.67346938776 .................................................\n",
      "[CV] .................................. C=2.67346938776, total=  13.3s\n",
      "[CV] C=2.71428571429 .................................................\n",
      "[CV] .................................. C=2.67346938776, total=  12.7s\n",
      "[CV] C=2.71428571429 .................................................\n",
      "[CV] .................................. C=2.67346938776, total=  12.4s\n",
      "[CV] C=2.71428571429 .................................................\n",
      "[CV] .................................. C=2.67346938776, total=  13.3s\n",
      "[CV] C=2.71428571429 .................................................\n",
      "[CV] .................................. C=2.71428571429, total=  13.0s\n",
      "[CV] C=2.71428571429 .................................................\n",
      "[CV] .................................. C=2.71428571429, total=  13.7s\n",
      "[CV] C=2.75510204082 .................................................\n",
      "[CV] .................................. C=2.71428571429, total=  13.7s\n",
      "[CV] C=2.75510204082 .................................................\n",
      "[CV] .................................. C=2.71428571429, total=  13.7s\n",
      "[CV] C=2.75510204082 .................................................\n",
      "[CV] .................................. C=2.71428571429, total=  13.6s\n",
      "[CV] C=2.75510204082 .................................................\n",
      "[CV] .................................. C=2.75510204082, total=  13.1s\n",
      "[CV] C=2.75510204082 .................................................\n",
      "[CV] .................................. C=2.75510204082, total=  15.7s\n",
      "[CV] C=2.79591836735 .................................................\n",
      "[CV] .................................. C=2.75510204082, total=  14.9s\n",
      "[CV] C=2.79591836735 .................................................\n",
      "[CV] .................................. C=2.75510204082, total=  15.3s\n",
      "[CV] C=2.79591836735 .................................................\n",
      "[CV] .................................. C=2.75510204082, total=  15.3s\n",
      "[CV] C=2.79591836735 .................................................\n",
      "[CV] .................................. C=2.79591836735, total=  12.7s\n",
      "[CV] C=2.79591836735 .................................................\n",
      "[CV] .................................. C=2.79591836735, total=  13.0s\n",
      "[CV] C=2.83673469388 .................................................\n",
      "[CV] .................................. C=2.79591836735, total=  13.2s\n",
      "[CV] C=2.83673469388 .................................................\n",
      "[CV] .................................. C=2.79591836735, total=  13.0s\n",
      "[CV] C=2.83673469388 .................................................\n",
      "[CV] .................................. C=2.79591836735, total=  14.9s\n",
      "[CV] C=2.83673469388 .................................................\n",
      "[CV] .................................. C=2.83673469388, total=  15.6s\n",
      "[CV] C=2.83673469388 .................................................\n",
      "[CV] .................................. C=2.83673469388, total=  15.4s\n",
      "[CV] C=2.87755102041 .................................................\n",
      "[CV] .................................. C=2.83673469388, total=  16.1s\n",
      "[CV] C=2.87755102041 .................................................\n",
      "[CV] .................................. C=2.83673469388, total=  17.6s\n",
      "[CV] C=2.87755102041 .................................................\n",
      "[CV] .................................. C=2.83673469388, total=  17.7s\n",
      "[CV] C=2.87755102041 .................................................\n",
      "[CV] .................................. C=2.87755102041, total=  17.8s\n",
      "[CV] C=2.87755102041 .................................................\n",
      "[CV] .................................. C=2.87755102041, total=  17.3s\n",
      "[CV] C=2.91836734694 .................................................\n",
      "[CV] .................................. C=2.87755102041, total=  17.0s\n",
      "[CV] C=2.91836734694 .................................................\n",
      "[CV] .................................. C=2.87755102041, total=  16.5s\n",
      "[CV] C=2.91836734694 .................................................\n",
      "[CV] .................................. C=2.87755102041, total=  16.2s\n",
      "[CV] C=2.91836734694 .................................................\n",
      "[CV] .................................. C=2.91836734694, total=  16.0s\n",
      "[CV] C=2.91836734694 .................................................\n",
      "[CV] .................................. C=2.91836734694, total=  16.4s\n",
      "[CV] C=2.95918367347 .................................................\n",
      "[CV] .................................. C=2.91836734694, total=  15.5s\n",
      "[CV] C=2.95918367347 .................................................\n",
      "[CV] .................................. C=2.91836734694, total=  16.5s\n",
      "[CV] C=2.95918367347 .................................................\n",
      "[CV] .................................. C=2.91836734694, total=  16.1s\n",
      "[CV] C=2.95918367347 .................................................\n",
      "[CV] .................................. C=2.95918367347, total=  13.4s\n",
      "[CV] C=2.95918367347 .................................................\n",
      "[CV] .................................. C=2.95918367347, total=  13.0s\n",
      "[CV] C=3.0 ...........................................................\n",
      "[CV] .................................. C=2.95918367347, total=  13.2s\n",
      "[CV] C=3.0 ...........................................................\n",
      "[CV] .................................. C=2.95918367347, total=  13.4s\n",
      "[CV] C=3.0 ...........................................................\n",
      "[CV] .................................. C=2.95918367347, total=  13.8s\n",
      "[CV] C=3.0 ...........................................................\n",
      "[CV] ............................................ C=3.0, total=  13.6s\n",
      "[CV] C=3.0 ...........................................................\n",
      "[CV] ............................................ C=3.0, total=  14.6s\n",
      "[CV] ............................................ C=3.0, total=  14.6s\n",
      "[CV] ............................................ C=3.0, total=  10.5s\n",
      "[CV] ............................................ C=3.0, total=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 14.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Use cross validation to search parameter (regularization strength)\n",
    "param_grid = {'C': np.linspace(1.0, 3.0, num=50)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1'),\n",
    "                          param_grid, scoring=score, cv=5, n_jobs=4, verbose=2)\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_final_lasso'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 23617).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.76518492, -0.76352171, -0.76198775, -0.76058296, -0.75929908,\n",
       "       -0.75811209, -0.75701266, -0.75600112, -0.75506071, -0.75418746,\n",
       "       -0.75336486, -0.75260384, -0.75189601, -0.75123687, -0.75064747,\n",
       "       -0.7501157 , -0.74962105, -0.74916817, -0.74875741, -0.74839132,\n",
       "       -0.74806879, -0.74778406, -0.74753944, -0.74732052, -0.74712408,\n",
       "       -0.74694478, -0.74678885, -0.74665373, -0.74654433, -0.74645448,\n",
       "       -0.74638019, -0.74632891, -0.74630217, -0.7462818 , -0.74627977,\n",
       "       -0.74629496, -0.7463317 , -0.74638847, -0.74646078, -0.74655236,\n",
       "       -0.74666124, -0.74678124, -0.74691705, -0.74706255, -0.74721864,\n",
       "       -0.74738157, -0.74754979, -0.74772065, -0.74790191, -0.74809335])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "predict_mlr(better_model, all_mat, x_train.shape[0], './config/prediction_test.csv')\n",
    "better_model.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.3877551020408161, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00015997886657714844 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "test = LogisticRegression(C=2.3877551020408161, penalty='l1', n_jobs=4)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 21109).\n"
     ]
    }
   ],
   "source": [
    "tf_tt, all_mat_tt, x_train_tt = vectorize_text(TRAIN_TEXT, TEST_TEXT, \"./test.csv\",\n",
    "                                      VECTOR, MATRIX, True,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=1, max_n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.32295349222\n",
      "  (0, 15435)\t0.108850310505\n",
      "  (0, 6993)\t0.14329861833\n",
      "  (0, 15727)\t0.113840690792\n",
      "  (0, 6195)\t0.329233914307\n",
      "  (0, 18190)\t0.724391972603\n",
      "  (0, 15733)\t0.46606840117\n"
     ]
    }
   ],
   "source": [
    "for i in all_mat_tt[-1,]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'realli',\n",
       " 'enjoy',\n",
       " 'dine',\n",
       " 'surpris',\n",
       " 'restaurant.すばらしい！唔知几好食',\n",
       " 'i',\n",
       " 'surpris',\n",
       " '!',\n",
       " 'i',\n",
       " 'dine',\n",
       " 'surpris',\n",
       " 'restaur',\n",
       " '!',\n",
       " 'surpris',\n",
       " '!']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = \"I really enjoy dining at this surprising restaurant.すばらしい！唔知几好食 I am surprised! I will dine at this surprising restaurant again! Surprised!\"\n",
    "tokenize(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "realli\n",
      "enjoy\n",
      "restaur\n",
      "dine\n",
      "surpris\n",
      "restaurant.\n"
     ]
    }
   ],
   "source": [
    "index = [0, 15435, 6993, 15727, 6195, 18190, 15733]\n",
    "for i in index:\n",
    "    for k, v in tf_tt.vocabulary_.items():\n",
    "        if i == v:\n",
    "            print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text_new(train_txt, vali_txt, test_txt, vector, matrix, re_load,\n",
    "                   min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1):\n",
    "    \"\"\" Feature engineering from the raw text input. \"\"\"\n",
    "    # If there is saved model, then just use it\n",
    "    if exists(vector) and exists(matrix) and not re_load:\n",
    "        # Get train length\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "\n",
    "        # Load stored data\n",
    "        all_mat = load(open(matrix, 'rb'))\n",
    "        x_train = all_mat[:table_train.shape[0]]\n",
    "        tf = load(open(vector, 'rb'))\n",
    "\n",
    "    else:\n",
    "        # Read all files\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "        table_test = pd.read_csv(vali_txt)\n",
    "        table_vali = pd.read_csv(test_txt)\n",
    "\n",
    "        text_train = table_train['clean'].tolist()\n",
    "        text_test = table_test['clean'].tolist()\n",
    "        text_vali = table_vali['clean'].tolist()\n",
    "\n",
    "        # We want to have a overall vocabulary bank as `np.py`, so we combine\n",
    "        # all the text first\n",
    "        all_text = text_train + text_test + text_vali\n",
    "\n",
    "        # Record the length so we can recover the training set\n",
    "        train_length = len(text_train)\n",
    "\n",
    "        # Initialize TFID arguments\n",
    "        # Only work for English, discard all Chinese\n",
    "        tf = TfidfVectorizer(min_df=min_df, max_features=max_feature,\n",
    "                             strip_accents='ascii', analyzer='word',\n",
    "                             tokenizer=tokenize, ngram_range=(min_n, max_n))\n",
    "\n",
    "        # Vectorize all, and transform (more efficient than fit + transform)\n",
    "        all_mat = tf.fit_transform(all_text)\n",
    "\n",
    "        # Recover the training data\n",
    "        x_train = all_mat[:train_length]\n",
    "\n",
    "        # Store the fitted matrix and tf_vectorizor\n",
    "        dump(all_mat, open(matrix, 'wb'))\n",
    "        dump(tf, open(vector, 'wb'))\n",
    "\n",
    "    print(\"Successfully load TF-IDF matrix, with shape {}.\".format(\n",
    "        x_train.shape))\n",
    "\n",
    "    return tf, all_mat, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 21888).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat, x_train = vectorize_text_new(TRAIN_TEXT, TEST_TEXT, VALI_TEXT,\n",
    "                                      '../../static/tf_vector_clean.pickle',\n",
    "                                      '../../static/tf_matrix_clean.pickle', LOAD_NEW,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=1, max_n=1)\n",
    "# predict(test_model, all_mat, x_train.shape[0], './config/prediction_lasso_1-6.csv')\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=2.3877551020408161)\n",
    "test.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21888).\n"
     ]
    }
   ],
   "source": [
    "predict(test, all_mat, x_train.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21888).\n"
     ]
    }
   ],
   "source": [
    "test = LogisticRegression(C=5, penalty='l2')\n",
    "test.fit(x_train, y_train)\n",
    "predict(test, all_mat, x_train.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually generate the coefficient converging path data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_alphas = 200\n",
    "alphas = np.linspace(0.01, 10, n_alphas)\n",
    "clf = LogisticRegression(penalty='l1')\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    clf.set_params(C=a)\n",
    "    clf.fit(x_train, y_train)\n",
    "    coefs.append(clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_table = pd.DataFrame(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_table.to_csv(\"./config/coe_path.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01, 10, n_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.01      ,   0.06020101,   0.11040201,   0.16060302,\n",
       "         0.21080402,   0.26100503,   0.31120603,   0.36140704,\n",
       "         0.41160804,   0.46180905,   0.51201005,   0.56221106,\n",
       "         0.61241206,   0.66261307,   0.71281407,   0.76301508,\n",
       "         0.81321608,   0.86341709,   0.91361809,   0.9638191 ,\n",
       "         1.0140201 ,   1.06422111,   1.11442211,   1.16462312,\n",
       "         1.21482412,   1.26502513,   1.31522613,   1.36542714,\n",
       "         1.41562814,   1.46582915,   1.51603015,   1.56623116,\n",
       "         1.61643216,   1.66663317,   1.71683417,   1.76703518,\n",
       "         1.81723618,   1.86743719,   1.91763819,   1.9678392 ,\n",
       "         2.0180402 ,   2.06824121,   2.11844221,   2.16864322,\n",
       "         2.21884422,   2.26904523,   2.31924623,   2.36944724,\n",
       "         2.41964824,   2.46984925,   2.52005025,   2.57025126,\n",
       "         2.62045226,   2.67065327,   2.72085427,   2.77105528,\n",
       "         2.82125628,   2.87145729,   2.92165829,   2.9718593 ,\n",
       "         3.0220603 ,   3.07226131,   3.12246231,   3.17266332,\n",
       "         3.22286432,   3.27306533,   3.32326633,   3.37346734,\n",
       "         3.42366834,   3.47386935,   3.52407035,   3.57427136,\n",
       "         3.62447236,   3.67467337,   3.72487437,   3.77507538,\n",
       "         3.82527638,   3.87547739,   3.92567839,   3.9758794 ,\n",
       "         4.0260804 ,   4.07628141,   4.12648241,   4.17668342,\n",
       "         4.22688442,   4.27708543,   4.32728643,   4.37748744,\n",
       "         4.42768844,   4.47788945,   4.52809045,   4.57829146,\n",
       "         4.62849246,   4.67869347,   4.72889447,   4.77909548,\n",
       "         4.82929648,   4.87949749,   4.92969849,   4.9798995 ,\n",
       "         5.0301005 ,   5.08030151,   5.13050251,   5.18070352,\n",
       "         5.23090452,   5.28110553,   5.33130653,   5.38150754,\n",
       "         5.43170854,   5.48190955,   5.53211055,   5.58231156,\n",
       "         5.63251256,   5.68271357,   5.73291457,   5.78311558,\n",
       "         5.83331658,   5.88351759,   5.93371859,   5.9839196 ,\n",
       "         6.0341206 ,   6.08432161,   6.13452261,   6.18472362,\n",
       "         6.23492462,   6.28512563,   6.33532663,   6.38552764,\n",
       "         6.43572864,   6.48592965,   6.53613065,   6.58633166,\n",
       "         6.63653266,   6.68673367,   6.73693467,   6.78713568,\n",
       "         6.83733668,   6.88753769,   6.93773869,   6.9879397 ,\n",
       "         7.0381407 ,   7.08834171,   7.13854271,   7.18874372,\n",
       "         7.23894472,   7.28914573,   7.33934673,   7.38954774,\n",
       "         7.43974874,   7.48994975,   7.54015075,   7.59035176,\n",
       "         7.64055276,   7.69075377,   7.74095477,   7.79115578,\n",
       "         7.84135678,   7.89155779,   7.94175879,   7.9919598 ,\n",
       "         8.0421608 ,   8.09236181,   8.14256281,   8.19276382,\n",
       "         8.24296482,   8.29316583,   8.34336683,   8.39356784,\n",
       "         8.44376884,   8.49396985,   8.54417085,   8.59437186,\n",
       "         8.64457286,   8.69477387,   8.74497487,   8.79517588,\n",
       "         8.84537688,   8.89557789,   8.94577889,   8.9959799 ,\n",
       "         9.0461809 ,   9.09638191,   9.14658291,   9.19678392,\n",
       "         9.24698492,   9.29718593,   9.34738693,   9.39758794,\n",
       "         9.44778894,   9.49798995,   9.54819095,   9.59839196,\n",
       "         9.64859296,   9.69879397,   9.74899497,   9.79919598,\n",
       "         9.84939698,   9.89959799,   9.94979899,  10.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEaCAYAAAC8UDhJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAqFYs5RYqRQKBSKOef/B0/Y30LE+eX7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134ec6080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.xlabel('log lambda')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('1-star Class Lasso coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.savefig('test.png', dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate CV data for plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   1.8s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................................... C=0.01, total=   2.0s\n",
      "[CV] C=0.0602010050251 ...............................................\n",
      "[CV] ........................................... C=0.01, total=   1.8s\n",
      "[CV] ........................................... C=0.01, total=   2.0s\n",
      "[CV] C=0.0602010050251 ...............................................\n",
      "[CV] C=0.0602010050251 ...............................................\n",
      "[CV] ........................................... C=0.01, total=   1.8s\n",
      "[CV] C=0.0602010050251 ...............................................\n",
      "[CV] ................................ C=0.0602010050251, total=   3.0s\n",
      "[CV] C=0.0602010050251 ...............................................\n",
      "[CV] ................................ C=0.0602010050251, total=   3.0s\n",
      "[CV] C=0.11040201005 .................................................\n",
      "[CV] ................................ C=0.0602010050251, total=   3.2s\n",
      "[CV] C=0.11040201005 .................................................\n",
      "[CV] ................................ C=0.0602010050251, total=   3.0s\n",
      "[CV] C=0.11040201005 .................................................\n",
      "[CV] ................................ C=0.0602010050251, total=   3.1s\n",
      "[CV] C=0.11040201005 .................................................\n",
      "[CV] .................................. C=0.11040201005, total=   3.3s\n",
      "[CV] .................................. C=0.11040201005, total=   3.4s\n",
      "[CV] C=0.11040201005 .................................................\n",
      "[CV] C=0.160603015075 ................................................\n",
      "[CV] .................................. C=0.11040201005, total=   3.5s\n",
      "[CV] C=0.160603015075 ................................................\n",
      "[CV] .................................. C=0.11040201005, total=   4.0s\n",
      "[CV] C=0.160603015075 ................................................\n",
      "[CV] .................................. C=0.11040201005, total=   4.1s\n",
      "[CV] C=0.160603015075 ................................................\n",
      "[CV] ................................. C=0.160603015075, total=   4.6s\n",
      "[CV] C=0.160603015075 ................................................\n",
      "[CV] ................................. C=0.160603015075, total=   6.3s\n",
      "[CV] C=0.210804020101 ................................................\n",
      "[CV] ................................. C=0.160603015075, total=   6.3s\n",
      "[CV] C=0.210804020101 ................................................\n",
      "[CV] ................................. C=0.160603015075, total=   6.2s\n",
      "[CV] C=0.210804020101 ................................................\n",
      "[CV] ................................. C=0.160603015075, total=   6.2s\n",
      "[CV] C=0.210804020101 ................................................\n",
      "[CV] ................................. C=0.210804020101, total=   6.5s\n",
      "[CV] C=0.210804020101 ................................................\n",
      "[CV] ................................. C=0.210804020101, total=   6.7s\n",
      "[CV] C=0.261005025126 ................................................\n",
      "[CV] ................................. C=0.210804020101, total=   6.7s\n",
      "[CV] C=0.261005025126 ................................................\n",
      "[CV] ................................. C=0.210804020101, total=   7.5s\n",
      "[CV] C=0.261005025126 ................................................\n",
      "[CV] ................................. C=0.210804020101, total=   7.1s\n",
      "[CV] C=0.261005025126 ................................................\n",
      "[CV] ................................. C=0.261005025126, total=   7.2s\n",
      "[CV] C=0.261005025126 ................................................\n",
      "[CV] ................................. C=0.261005025126, total=   7.3s\n",
      "[CV] C=0.311206030151 ................................................\n",
      "[CV] ................................. C=0.261005025126, total=   7.1s\n",
      "[CV] C=0.311206030151 ................................................\n",
      "[CV] ................................. C=0.261005025126, total=   6.8s\n",
      "[CV] C=0.311206030151 ................................................\n",
      "[CV] ................................. C=0.261005025126, total=   6.2s\n",
      "[CV] C=0.311206030151 ................................................\n",
      "[CV] ................................. C=0.311206030151, total=   6.4s\n",
      "[CV] C=0.311206030151 ................................................\n",
      "[CV] ................................. C=0.311206030151, total=   6.7s\n",
      "[CV] C=0.361407035176 ................................................\n",
      "[CV] ................................. C=0.311206030151, total=   6.5s\n",
      "[CV] C=0.361407035176 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   48.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=0.311206030151, total=   6.4s\n",
      "[CV] C=0.361407035176 ................................................\n",
      "[CV] ................................. C=0.311206030151, total=   6.5s\n",
      "[CV] C=0.361407035176 ................................................\n",
      "[CV] ................................. C=0.361407035176, total=   7.2s\n",
      "[CV] C=0.361407035176 ................................................\n",
      "[CV] ................................. C=0.361407035176, total=   7.3s\n",
      "[CV] C=0.411608040201 ................................................\n",
      "[CV] ................................. C=0.361407035176, total=   6.9s\n",
      "[CV] C=0.411608040201 ................................................\n",
      "[CV] ................................. C=0.361407035176, total=   7.1s\n",
      "[CV] C=0.411608040201 ................................................\n",
      "[CV] ................................. C=0.361407035176, total=   7.2s\n",
      "[CV] C=0.411608040201 ................................................\n",
      "[CV] ................................. C=0.411608040201, total=   9.1s\n",
      "[CV] C=0.411608040201 ................................................\n",
      "[CV] ................................. C=0.411608040201, total=   9.0s\n",
      "[CV] C=0.461809045226 ................................................\n",
      "[CV] ................................. C=0.411608040201, total=   8.9s\n",
      "[CV] C=0.461809045226 ................................................\n",
      "[CV] ................................. C=0.411608040201, total=   8.4s\n",
      "[CV] C=0.461809045226 ................................................\n",
      "[CV] ................................. C=0.411608040201, total=   7.6s\n",
      "[CV] C=0.461809045226 ................................................\n",
      "[CV] ................................. C=0.461809045226, total=   7.4s\n",
      "[CV] C=0.461809045226 ................................................\n",
      "[CV] ................................. C=0.461809045226, total=   7.7s\n",
      "[CV] C=0.512010050251 ................................................\n",
      "[CV] ................................. C=0.461809045226, total=   7.4s\n",
      "[CV] C=0.512010050251 ................................................\n",
      "[CV] ................................. C=0.461809045226, total=   7.4s\n",
      "[CV] C=0.512010050251 ................................................\n",
      "[CV] ................................. C=0.461809045226, total=   7.3s\n",
      "[CV] C=0.512010050251 ................................................\n",
      "[CV] ................................. C=0.512010050251, total=   7.4s\n",
      "[CV] C=0.512010050251 ................................................\n",
      "[CV] ................................. C=0.512010050251, total=   7.1s\n",
      "[CV] C=0.562211055276 ................................................\n",
      "[CV] ................................. C=0.512010050251, total=   7.5s\n",
      "[CV] C=0.562211055276 ................................................\n",
      "[CV] ................................. C=0.512010050251, total=   7.5s\n",
      "[CV] C=0.562211055276 ................................................\n",
      "[CV] ................................. C=0.512010050251, total=   8.0s\n",
      "[CV] C=0.562211055276 ................................................\n",
      "[CV] ................................. C=0.562211055276, total=   8.2s\n",
      "[CV] C=0.562211055276 ................................................\n",
      "[CV] ................................. C=0.562211055276, total=   7.3s\n",
      "[CV] C=0.612412060302 ................................................\n",
      "[CV] ................................. C=0.562211055276, total=   6.9s\n",
      "[CV] C=0.612412060302 ................................................\n",
      "[CV] ................................. C=0.562211055276, total=   7.6s\n",
      "[CV] C=0.612412060302 ................................................\n",
      "[CV] ................................. C=0.562211055276, total=   7.8s\n",
      "[CV] C=0.612412060302 ................................................\n",
      "[CV] ................................. C=0.612412060302, total=   9.2s\n",
      "[CV] C=0.612412060302 ................................................\n",
      "[CV] ................................. C=0.612412060302, total=   9.5s\n",
      "[CV] C=0.662613065327 ................................................\n",
      "[CV] ................................. C=0.612412060302, total=   8.9s\n",
      "[CV] C=0.662613065327 ................................................\n",
      "[CV] ................................. C=0.612412060302, total=   9.1s\n",
      "[CV] C=0.662613065327 ................................................\n",
      "[CV] ................................. C=0.612412060302, total=   8.7s\n",
      "[CV] C=0.662613065327 ................................................\n",
      "[CV] ................................. C=0.662613065327, total=   8.4s\n",
      "[CV] C=0.662613065327 ................................................\n",
      "[CV] ................................. C=0.662613065327, total=   8.7s\n",
      "[CV] C=0.712814070352 ................................................\n",
      "[CV] ................................. C=0.662613065327, total=   8.0s\n",
      "[CV] C=0.712814070352 ................................................\n",
      "[CV] ................................. C=0.662613065327, total=  14.5s\n",
      "[CV] C=0.712814070352 ................................................\n",
      "[CV] ................................. C=0.662613065327, total=  15.4s\n",
      "[CV] C=0.712814070352 ................................................\n",
      "[CV] ................................. C=0.712814070352, total=  16.7s\n",
      "[CV] C=0.712814070352 ................................................\n",
      "[CV] ................................. C=0.712814070352, total=  17.1s\n",
      "[CV] C=0.763015075377 ................................................\n",
      "[CV] ................................. C=0.712814070352, total=   9.4s\n",
      "[CV] ................................. C=0.712814070352, total=   9.7s\n",
      "[CV] C=0.763015075377 ................................................\n",
      "[CV] C=0.763015075377 ................................................\n",
      "[CV] ................................. C=0.712814070352, total=   7.9s\n",
      "[CV] C=0.763015075377 ................................................\n",
      "[CV] ................................. C=0.763015075377, total=   7.5s\n",
      "[CV] C=0.763015075377 ................................................\n",
      "[CV] ................................. C=0.763015075377, total=   9.3s\n",
      "[CV] C=0.813216080402 ................................................\n",
      "[CV] ................................. C=0.763015075377, total=   9.7s\n",
      "[CV] C=0.813216080402 ................................................\n",
      "[CV] ................................. C=0.763015075377, total=  10.0s\n",
      "[CV] C=0.813216080402 ................................................\n",
      "[CV] ................................. C=0.763015075377, total=  10.8s\n",
      "[CV] C=0.813216080402 ................................................\n",
      "[CV] ................................. C=0.813216080402, total=  10.7s\n",
      "[CV] C=0.813216080402 ................................................\n",
      "[CV] ................................. C=0.813216080402, total=  10.5s\n",
      "[CV] C=0.863417085427 ................................................\n",
      "[CV] ................................. C=0.813216080402, total=  10.1s\n",
      "[CV] C=0.863417085427 ................................................\n",
      "[CV] ................................. C=0.813216080402, total=  10.0s\n",
      "[CV] C=0.863417085427 ................................................\n",
      "[CV] ................................. C=0.813216080402, total=  12.5s\n",
      "[CV] C=0.863417085427 ................................................\n",
      "[CV] ................................. C=0.863417085427, total=  12.5s\n",
      "[CV] C=0.863417085427 ................................................\n",
      "[CV] ................................. C=0.863417085427, total=  13.2s\n",
      "[CV] C=0.913618090452 ................................................\n",
      "[CV] ................................. C=0.863417085427, total=  13.0s\n",
      "[CV] C=0.913618090452 ................................................\n",
      "[CV] ................................. C=0.863417085427, total=  12.7s\n",
      "[CV] C=0.913618090452 ................................................\n",
      "[CV] ................................. C=0.863417085427, total=  12.9s\n",
      "[CV] C=0.913618090452 ................................................\n",
      "[CV] ................................. C=0.913618090452, total=  13.7s\n",
      "[CV] C=0.913618090452 ................................................\n",
      "[CV] ................................. C=0.913618090452, total=  14.5s\n",
      "[CV] C=0.963819095477 ................................................\n",
      "[CV] ................................. C=0.913618090452, total=  16.8s\n",
      "[CV] C=0.963819095477 ................................................\n",
      "[CV] ................................. C=0.913618090452, total=  16.5s\n",
      "[CV] C=0.963819095477 ................................................\n",
      "[CV] ................................. C=0.913618090452, total=  15.2s\n",
      "[CV] C=0.963819095477 ................................................\n",
      "[CV] ................................. C=0.963819095477, total=  14.7s\n",
      "[CV] C=0.963819095477 ................................................\n",
      "[CV] ................................. C=0.963819095477, total=  13.8s\n",
      "[CV] C=1.0140201005 ..................................................\n",
      "[CV] ................................. C=0.963819095477, total=  14.2s\n",
      "[CV] C=1.0140201005 ..................................................\n",
      "[CV] ................................. C=0.963819095477, total=  13.5s\n",
      "[CV] C=1.0140201005 ..................................................\n",
      "[CV] ................................. C=0.963819095477, total=  12.3s\n",
      "[CV] C=1.0140201005 ..................................................\n",
      "[CV] ................................... C=1.0140201005, total=  10.4s\n",
      "[CV] C=1.0140201005 ..................................................\n",
      "[CV] ................................... C=1.0140201005, total=  10.9s\n",
      "[CV] C=1.06422110553 .................................................\n",
      "[CV] ................................... C=1.0140201005, total=  11.3s\n",
      "[CV] C=1.06422110553 .................................................\n",
      "[CV] ................................... C=1.0140201005, total=  11.7s\n",
      "[CV] C=1.06422110553 .................................................\n",
      "[CV] ................................... C=1.0140201005, total=  15.3s\n",
      "[CV] C=1.06422110553 .................................................\n",
      "[CV] .................................. C=1.06422110553, total=  15.5s\n",
      "[CV] C=1.06422110553 .................................................\n",
      "[CV] .................................. C=1.06422110553, total=  15.5s\n",
      "[CV] C=1.11442211055 .................................................\n",
      "[CV] .................................. C=1.06422110553, total=  14.7s\n",
      "[CV] C=1.11442211055 .................................................\n",
      "[CV] .................................. C=1.06422110553, total=  10.8s\n",
      "[CV] C=1.11442211055 .................................................\n",
      "[CV] .................................. C=1.06422110553, total=  10.8s\n",
      "[CV] C=1.11442211055 .................................................\n",
      "[CV] .................................. C=1.11442211055, total=  10.5s\n",
      "[CV] C=1.11442211055 .................................................\n",
      "[CV] .................................. C=1.11442211055, total=  11.0s\n",
      "[CV] C=1.16462311558 .................................................\n",
      "[CV] .................................. C=1.11442211055, total=  12.3s\n",
      "[CV] C=1.16462311558 .................................................\n",
      "[CV] .................................. C=1.11442211055, total=  13.2s\n",
      "[CV] C=1.16462311558 .................................................\n",
      "[CV] .................................. C=1.11442211055, total=  13.1s\n",
      "[CV] C=1.16462311558 .................................................\n",
      "[CV] .................................. C=1.16462311558, total=  13.0s\n",
      "[CV] C=1.16462311558 .................................................\n",
      "[CV] .................................. C=1.16462311558, total=  12.9s\n",
      "[CV] C=1.2148241206 ..................................................\n",
      "[CV] .................................. C=1.16462311558, total=  12.3s\n",
      "[CV] C=1.2148241206 ..................................................\n",
      "[CV] .................................. C=1.16462311558, total=  12.6s\n",
      "[CV] C=1.2148241206 ..................................................\n",
      "[CV] .................................. C=1.16462311558, total=  12.2s\n",
      "[CV] C=1.2148241206 ..................................................\n",
      "[CV] ................................... C=1.2148241206, total=  11.0s\n",
      "[CV] C=1.2148241206 ..................................................\n",
      "[CV] ................................... C=1.2148241206, total=  12.3s\n",
      "[CV] C=1.26502512563 .................................................\n",
      "[CV] ................................... C=1.2148241206, total=  12.9s\n",
      "[CV] C=1.26502512563 .................................................\n",
      "[CV] ................................... C=1.2148241206, total=  13.4s\n",
      "[CV] C=1.26502512563 .................................................\n",
      "[CV] ................................... C=1.2148241206, total=  12.7s\n",
      "[CV] C=1.26502512563 .................................................\n",
      "[CV] .................................. C=1.26502512563, total=  11.6s\n",
      "[CV] C=1.26502512563 .................................................\n",
      "[CV] .................................. C=1.26502512563, total=  11.2s\n",
      "[CV] C=1.31522613065 .................................................\n",
      "[CV] .................................. C=1.26502512563, total=  10.9s\n",
      "[CV] C=1.31522613065 .................................................\n",
      "[CV] .................................. C=1.26502512563, total=  10.2s\n",
      "[CV] C=1.31522613065 .................................................\n",
      "[CV] .................................. C=1.26502512563, total=  10.2s\n",
      "[CV] C=1.31522613065 .................................................\n",
      "[CV] .................................. C=1.31522613065, total=   9.7s\n",
      "[CV] C=1.31522613065 .................................................\n",
      "[CV] .................................. C=1.31522613065, total=   9.8s\n",
      "[CV] C=1.36542713568 .................................................\n",
      "[CV] .................................. C=1.31522613065, total=  10.1s\n",
      "[CV] C=1.36542713568 .................................................\n",
      "[CV] .................................. C=1.31522613065, total=  10.5s\n",
      "[CV] C=1.36542713568 .................................................\n",
      "[CV] .................................. C=1.31522613065, total=  10.7s\n",
      "[CV] C=1.36542713568 .................................................\n",
      "[CV] .................................. C=1.36542713568, total=  11.4s\n",
      "[CV] C=1.36542713568 .................................................\n",
      "[CV] .................................. C=1.36542713568, total=  10.3s\n",
      "[CV] C=1.4156281407 ..................................................\n",
      "[CV] .................................. C=1.36542713568, total=  10.0s\n",
      "[CV] C=1.4156281407 ..................................................\n",
      "[CV] .................................. C=1.36542713568, total=   9.6s\n",
      "[CV] C=1.4156281407 ..................................................\n",
      "[CV] .................................. C=1.36542713568, total=   9.9s\n",
      "[CV] C=1.4156281407 ..................................................\n",
      "[CV] ................................... C=1.4156281407, total=  10.7s\n",
      "[CV] C=1.4156281407 ..................................................\n",
      "[CV] ................................... C=1.4156281407, total=  10.9s\n",
      "[CV] C=1.46582914573 .................................................\n",
      "[CV] ................................... C=1.4156281407, total=  10.3s\n",
      "[CV] C=1.46582914573 .................................................\n",
      "[CV] ................................... C=1.4156281407, total=  11.4s\n",
      "[CV] C=1.46582914573 .................................................\n",
      "[CV] ................................... C=1.4156281407, total=  12.1s\n",
      "[CV] C=1.46582914573 .................................................\n",
      "[CV] .................................. C=1.46582914573, total=  11.8s\n",
      "[CV] C=1.46582914573 .................................................\n",
      "[CV] .................................. C=1.46582914573, total=  11.8s\n",
      "[CV] C=1.51603015075 .................................................\n",
      "[CV] .................................. C=1.46582914573, total=  10.6s\n",
      "[CV] C=1.51603015075 .................................................\n",
      "[CV] .................................. C=1.46582914573, total=  10.7s\n",
      "[CV] C=1.51603015075 .................................................\n",
      "[CV] .................................. C=1.46582914573, total=  11.0s\n",
      "[CV] C=1.51603015075 .................................................\n",
      "[CV] .................................. C=1.51603015075, total=  11.8s\n",
      "[CV] C=1.51603015075 .................................................\n",
      "[CV] .................................. C=1.51603015075, total=  12.1s\n",
      "[CV] C=1.56623115578 .................................................\n",
      "[CV] .................................. C=1.51603015075, total=  13.9s\n",
      "[CV] C=1.56623115578 .................................................\n",
      "[CV] .................................. C=1.51603015075, total=  13.4s\n",
      "[CV] C=1.56623115578 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  6.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=1.51603015075, total=  13.3s\n",
      "[CV] C=1.56623115578 .................................................\n",
      "[CV] .................................. C=1.56623115578, total=  12.1s\n",
      "[CV] C=1.56623115578 .................................................\n",
      "[CV] .................................. C=1.56623115578, total=  10.7s\n",
      "[CV] C=1.6164321608 ..................................................\n",
      "[CV] .................................. C=1.56623115578, total=  11.1s\n",
      "[CV] C=1.6164321608 ..................................................\n",
      "[CV] .................................. C=1.56623115578, total=  11.1s\n",
      "[CV] C=1.6164321608 ..................................................\n",
      "[CV] .................................. C=1.56623115578, total=  11.0s\n",
      "[CV] C=1.6164321608 ..................................................\n",
      "[CV] ................................... C=1.6164321608, total=  11.4s\n",
      "[CV] C=1.6164321608 ..................................................\n",
      "[CV] ................................... C=1.6164321608, total=  11.7s\n",
      "[CV] C=1.66663316583 .................................................\n",
      "[CV] ................................... C=1.6164321608, total=  11.9s\n",
      "[CV] C=1.66663316583 .................................................\n",
      "[CV] ................................... C=1.6164321608, total=  11.6s\n",
      "[CV] C=1.66663316583 .................................................\n",
      "[CV] ................................... C=1.6164321608, total=  12.6s\n",
      "[CV] C=1.66663316583 .................................................\n",
      "[CV] .................................. C=1.66663316583, total=  12.1s\n",
      "[CV] C=1.66663316583 .................................................\n",
      "[CV] .................................. C=1.66663316583, total=  12.2s\n",
      "[CV] C=1.71683417085 .................................................\n",
      "[CV] .................................. C=1.66663316583, total=  11.8s\n",
      "[CV] C=1.71683417085 .................................................\n",
      "[CV] .................................. C=1.66663316583, total=  11.9s\n",
      "[CV] C=1.71683417085 .................................................\n",
      "[CV] .................................. C=1.66663316583, total=  12.0s\n",
      "[CV] C=1.71683417085 .................................................\n",
      "[CV] .................................. C=1.71683417085, total=  11.8s\n",
      "[CV] C=1.71683417085 .................................................\n",
      "[CV] .................................. C=1.71683417085, total=  11.9s\n",
      "[CV] C=1.76703517588 .................................................\n",
      "[CV] .................................. C=1.71683417085, total=  12.1s\n",
      "[CV] C=1.76703517588 .................................................\n",
      "[CV] .................................. C=1.71683417085, total=  12.7s\n",
      "[CV] C=1.76703517588 .................................................\n",
      "[CV] .................................. C=1.71683417085, total=  12.7s\n",
      "[CV] C=1.76703517588 .................................................\n",
      "[CV] .................................. C=1.76703517588, total=  12.7s\n",
      "[CV] C=1.76703517588 .................................................\n",
      "[CV] .................................. C=1.76703517588, total=  12.7s\n",
      "[CV] C=1.8172361809 ..................................................\n",
      "[CV] .................................. C=1.76703517588, total=  11.8s\n",
      "[CV] C=1.8172361809 ..................................................\n",
      "[CV] .................................. C=1.76703517588, total=  12.3s\n",
      "[CV] C=1.8172361809 ..................................................\n",
      "[CV] .................................. C=1.76703517588, total=  12.6s\n",
      "[CV] C=1.8172361809 ..................................................\n",
      "[CV] ................................... C=1.8172361809, total=  12.2s\n",
      "[CV] C=1.8172361809 ..................................................\n",
      "[CV] ................................... C=1.8172361809, total=  12.1s\n",
      "[CV] C=1.86743718593 .................................................\n",
      "[CV] ................................... C=1.8172361809, total=  11.9s\n",
      "[CV] C=1.86743718593 .................................................\n",
      "[CV] ................................... C=1.8172361809, total=  12.2s\n",
      "[CV] C=1.86743718593 .................................................\n",
      "[CV] ................................... C=1.8172361809, total=  12.5s\n",
      "[CV] C=1.86743718593 .................................................\n",
      "[CV] .................................. C=1.86743718593, total=  12.4s\n",
      "[CV] C=1.86743718593 .................................................\n",
      "[CV] .................................. C=1.86743718593, total=  12.9s\n",
      "[CV] C=1.91763819095 .................................................\n",
      "[CV] .................................. C=1.86743718593, total=  12.4s\n",
      "[CV] C=1.91763819095 .................................................\n",
      "[CV] .................................. C=1.86743718593, total=  12.4s\n",
      "[CV] C=1.91763819095 .................................................\n",
      "[CV] .................................. C=1.86743718593, total=  12.9s\n",
      "[CV] C=1.91763819095 .................................................\n",
      "[CV] .................................. C=1.91763819095, total=  11.9s\n",
      "[CV] C=1.91763819095 .................................................\n",
      "[CV] .................................. C=1.91763819095, total=  12.5s\n",
      "[CV] C=1.96783919598 .................................................\n",
      "[CV] .................................. C=1.91763819095, total=  12.5s\n",
      "[CV] C=1.96783919598 .................................................\n",
      "[CV] .................................. C=1.91763819095, total=  12.5s\n",
      "[CV] C=1.96783919598 .................................................\n",
      "[CV] .................................. C=1.91763819095, total=  12.1s\n",
      "[CV] C=1.96783919598 .................................................\n",
      "[CV] .................................. C=1.96783919598, total=  12.2s\n",
      "[CV] C=1.96783919598 .................................................\n",
      "[CV] .................................. C=1.96783919598, total=  12.2s\n",
      "[CV] C=2.01804020101 .................................................\n",
      "[CV] .................................. C=1.96783919598, total=  12.0s\n",
      "[CV] C=2.01804020101 .................................................\n",
      "[CV] .................................. C=1.96783919598, total=  11.9s\n",
      "[CV] C=2.01804020101 .................................................\n",
      "[CV] .................................. C=1.96783919598, total=  12.2s\n",
      "[CV] C=2.01804020101 .................................................\n",
      "[CV] .................................. C=2.01804020101, total=  12.6s\n",
      "[CV] C=2.01804020101 .................................................\n",
      "[CV] .................................. C=2.01804020101, total=  12.4s\n",
      "[CV] C=2.06824120603 .................................................\n",
      "[CV] .................................. C=2.01804020101, total=  12.3s\n",
      "[CV] C=2.06824120603 .................................................\n",
      "[CV] .................................. C=2.01804020101, total=  12.5s\n",
      "[CV] C=2.06824120603 .................................................\n",
      "[CV] .................................. C=2.01804020101, total=  12.0s\n",
      "[CV] C=2.06824120603 .................................................\n",
      "[CV] .................................. C=2.06824120603, total=  12.1s\n",
      "[CV] C=2.06824120603 .................................................\n",
      "[CV] .................................. C=2.06824120603, total=  12.0s\n",
      "[CV] C=2.11844221106 .................................................\n",
      "[CV] .................................. C=2.06824120603, total=  12.1s\n",
      "[CV] C=2.11844221106 .................................................\n",
      "[CV] .................................. C=2.06824120603, total=  12.4s\n",
      "[CV] C=2.11844221106 .................................................\n",
      "[CV] .................................. C=2.11844221106, total=  11.9s\n",
      "[CV] C=2.11844221106 .................................................\n",
      "[CV] .................................. C=2.06824120603, total=  12.4s\n",
      "[CV] C=2.11844221106 .................................................\n",
      "[CV] .................................. C=2.11844221106, total=  13.1s\n",
      "[CV] C=2.16864321608 .................................................\n",
      "[CV] .................................. C=2.11844221106, total=  13.4s\n",
      "[CV] C=2.16864321608 .................................................\n",
      "[CV] .................................. C=2.11844221106, total=  14.2s\n",
      "[CV] C=2.16864321608 .................................................\n",
      "[CV] .................................. C=2.11844221106, total=  14.3s\n",
      "[CV] C=2.16864321608 .................................................\n",
      "[CV] .................................. C=2.16864321608, total=  13.3s\n",
      "[CV] C=2.16864321608 .................................................\n",
      "[CV] .................................. C=2.16864321608, total=  13.4s\n",
      "[CV] C=2.21884422111 .................................................\n",
      "[CV] .................................. C=2.16864321608, total=  14.8s\n",
      "[CV] C=2.21884422111 .................................................\n",
      "[CV] .................................. C=2.16864321608, total=  14.7s\n",
      "[CV] C=2.21884422111 .................................................\n",
      "[CV] .................................. C=2.16864321608, total=  14.4s\n",
      "[CV] C=2.21884422111 .................................................\n",
      "[CV] .................................. C=2.21884422111, total=  12.5s\n",
      "[CV] C=2.21884422111 .................................................\n",
      "[CV] .................................. C=2.21884422111, total=  12.5s\n",
      "[CV] .................................. C=2.21884422111, total=  12.8s\n",
      "[CV] C=2.26904522613 .................................................\n",
      "[CV] C=2.26904522613 .................................................\n",
      "[CV] .................................. C=2.21884422111, total=  12.6s\n",
      "[CV] C=2.26904522613 .................................................\n",
      "[CV] .................................. C=2.21884422111, total=  13.1s\n",
      "[CV] C=2.26904522613 .................................................\n",
      "[CV] .................................. C=2.26904522613, total=  13.9s\n",
      "[CV] .................................. C=2.26904522613, total=  13.9s\n",
      "[CV] C=2.26904522613 .................................................\n",
      "[CV] C=2.31924623116 .................................................\n",
      "[CV] .................................. C=2.26904522613, total=  14.1s\n",
      "[CV] C=2.31924623116 .................................................\n",
      "[CV] .................................. C=2.26904522613, total=  14.0s\n",
      "[CV] C=2.31924623116 .................................................\n",
      "[CV] .................................. C=2.26904522613, total=  13.3s\n",
      "[CV] C=2.31924623116 .................................................\n",
      "[CV] .................................. C=2.31924623116, total=  13.6s\n",
      "[CV] C=2.31924623116 .................................................\n",
      "[CV] .................................. C=2.31924623116, total=  13.2s\n",
      "[CV] C=2.36944723618 .................................................\n",
      "[CV] .................................. C=2.31924623116, total=  13.4s\n",
      "[CV] C=2.36944723618 .................................................\n",
      "[CV] .................................. C=2.31924623116, total=  13.3s\n",
      "[CV] C=2.36944723618 .................................................\n",
      "[CV] .................................. C=2.31924623116, total=  13.2s\n",
      "[CV] C=2.36944723618 .................................................\n",
      "[CV] .................................. C=2.36944723618, total=  12.8s\n",
      "[CV] C=2.36944723618 .................................................\n",
      "[CV] .................................. C=2.36944723618, total=  12.9s\n",
      "[CV] C=2.41964824121 .................................................\n",
      "[CV] .................................. C=2.36944723618, total=  12.2s\n",
      "[CV] C=2.41964824121 .................................................\n",
      "[CV] .................................. C=2.36944723618, total=  12.2s\n",
      "[CV] C=2.41964824121 .................................................\n",
      "[CV] .................................. C=2.36944723618, total=  12.7s\n",
      "[CV] C=2.41964824121 .................................................\n",
      "[CV] .................................. C=2.41964824121, total=  11.8s\n",
      "[CV] C=2.41964824121 .................................................\n",
      "[CV] .................................. C=2.41964824121, total=  11.9s\n",
      "[CV] C=2.46984924623 .................................................\n",
      "[CV] .................................. C=2.41964824121, total=  11.9s\n",
      "[CV] C=2.46984924623 .................................................\n",
      "[CV] .................................. C=2.41964824121, total=  11.6s\n",
      "[CV] C=2.46984924623 .................................................\n",
      "[CV] .................................. C=2.41964824121, total=  13.1s\n",
      "[CV] C=2.46984924623 .................................................\n",
      "[CV] .................................. C=2.46984924623, total=  13.2s\n",
      "[CV] C=2.46984924623 .................................................\n",
      "[CV] .................................. C=2.46984924623, total=  13.2s\n",
      "[CV] C=2.52005025126 .................................................\n",
      "[CV] .................................. C=2.46984924623, total=  13.1s\n",
      "[CV] C=2.52005025126 .................................................\n",
      "[CV] .................................. C=2.46984924623, total=  12.1s\n",
      "[CV] C=2.52005025126 .................................................\n",
      "[CV] .................................. C=2.46984924623, total=  11.7s\n",
      "[CV] C=2.52005025126 .................................................\n",
      "[CV] .................................. C=2.52005025126, total=  11.8s\n",
      "[CV] C=2.52005025126 .................................................\n",
      "[CV] .................................. C=2.52005025126, total=  11.7s\n",
      "[CV] C=2.57025125628 .................................................\n",
      "[CV] .................................. C=2.52005025126, total=  13.2s\n",
      "[CV] C=2.57025125628 .................................................\n",
      "[CV] .................................. C=2.52005025126, total=  13.1s\n",
      "[CV] C=2.57025125628 .................................................\n",
      "[CV] .................................. C=2.52005025126, total=  13.2s\n",
      "[CV] C=2.57025125628 .................................................\n",
      "[CV] .................................. C=2.57025125628, total=  13.4s\n",
      "[CV] C=2.57025125628 .................................................\n",
      "[CV] .................................. C=2.57025125628, total=  13.0s\n",
      "[CV] C=2.62045226131 .................................................\n",
      "[CV] .................................. C=2.57025125628, total=  12.2s\n",
      "[CV] .................................. C=2.57025125628, total=  12.7s\n",
      "[CV] C=2.62045226131 .................................................\n",
      "[CV] C=2.62045226131 .................................................\n",
      "[CV] .................................. C=2.57025125628, total=  12.4s\n",
      "[CV] C=2.62045226131 .................................................\n",
      "[CV] .................................. C=2.62045226131, total=  15.5s\n",
      "[CV] C=2.62045226131 .................................................\n",
      "[CV] .................................. C=2.62045226131, total=  16.2s\n",
      "[CV] .................................. C=2.62045226131, total=  16.2s\n",
      "[CV] C=2.67065326633 .................................................\n",
      "[CV] C=2.67065326633 .................................................\n",
      "[CV] .................................. C=2.62045226131, total=  16.7s\n",
      "[CV] C=2.67065326633 .................................................\n",
      "[CV] .................................. C=2.62045226131, total=  16.3s\n",
      "[CV] C=2.67065326633 .................................................\n",
      "[CV] .................................. C=2.67065326633, total=  16.3s\n",
      "[CV] C=2.67065326633 .................................................\n",
      "[CV] .................................. C=2.67065326633, total=  16.7s\n",
      "[CV] C=2.72085427136 .................................................\n",
      "[CV] .................................. C=2.67065326633, total=  15.7s\n",
      "[CV] C=2.72085427136 .................................................\n",
      "[CV] .................................. C=2.67065326633, total=  15.6s\n",
      "[CV] C=2.72085427136 .................................................\n",
      "[CV] .................................. C=2.67065326633, total=  15.2s\n",
      "[CV] C=2.72085427136 .................................................\n",
      "[CV] .................................. C=2.72085427136, total=  15.0s\n",
      "[CV] C=2.72085427136 .................................................\n",
      "[CV] .................................. C=2.72085427136, total=  15.3s\n",
      "[CV] C=2.77105527638 .................................................\n",
      "[CV] .................................. C=2.72085427136, total=  16.4s\n",
      "[CV] C=2.77105527638 .................................................\n",
      "[CV] .................................. C=2.72085427136, total=  17.0s\n",
      "[CV] C=2.77105527638 .................................................\n",
      "[CV] .................................. C=2.72085427136, total=  17.4s\n",
      "[CV] C=2.77105527638 .................................................\n",
      "[CV] .................................. C=2.77105527638, total=  17.2s\n",
      "[CV] C=2.77105527638 .................................................\n",
      "[CV] .................................. C=2.77105527638, total=  15.8s\n",
      "[CV] C=2.82125628141 .................................................\n",
      "[CV] .................................. C=2.77105527638, total=  15.7s\n",
      "[CV] C=2.82125628141 .................................................\n",
      "[CV] .................................. C=2.77105527638, total=  15.6s\n",
      "[CV] C=2.82125628141 .................................................\n",
      "[CV] .................................. C=2.77105527638, total=  15.0s\n",
      "[CV] C=2.82125628141 .................................................\n",
      "[CV] .................................. C=2.82125628141, total=  13.7s\n",
      "[CV] C=2.82125628141 .................................................\n",
      "[CV] .................................. C=2.82125628141, total=  13.9s\n",
      "[CV] C=2.87145728643 .................................................\n",
      "[CV] .................................. C=2.82125628141, total=  13.8s\n",
      "[CV] C=2.87145728643 .................................................\n",
      "[CV] .................................. C=2.82125628141, total=  13.3s\n",
      "[CV] C=2.87145728643 .................................................\n",
      "[CV] .................................. C=2.82125628141, total=  12.5s\n",
      "[CV] C=2.87145728643 .................................................\n",
      "[CV] .................................. C=2.87145728643, total=  12.5s\n",
      "[CV] C=2.87145728643 .................................................\n",
      "[CV] .................................. C=2.87145728643, total=  12.8s\n",
      "[CV] C=2.92165829146 .................................................\n",
      "[CV] .................................. C=2.87145728643, total=  12.7s\n",
      "[CV] C=2.92165829146 .................................................\n",
      "[CV] .................................. C=2.87145728643, total=  14.7s\n",
      "[CV] C=2.92165829146 .................................................\n",
      "[CV] .................................. C=2.87145728643, total=  15.1s\n",
      "[CV] C=2.92165829146 .................................................\n",
      "[CV] .................................. C=2.92165829146, total=  14.9s\n",
      "[CV] C=2.92165829146 .................................................\n",
      "[CV] .................................. C=2.92165829146, total=  14.7s\n",
      "[CV] C=2.97185929648 .................................................\n",
      "[CV] .................................. C=2.92165829146, total=  14.4s\n",
      "[CV] C=2.97185929648 .................................................\n",
      "[CV] .................................. C=2.92165829146, total=  14.3s\n",
      "[CV] C=2.97185929648 .................................................\n",
      "[CV] .................................. C=2.92165829146, total=  14.6s\n",
      "[CV] C=2.97185929648 .................................................\n",
      "[CV] .................................. C=2.97185929648, total=  14.2s\n",
      "[CV] C=2.97185929648 .................................................\n",
      "[CV] .................................. C=2.97185929648, total=  16.2s\n",
      "[CV] C=3.02206030151 .................................................\n",
      "[CV] .................................. C=2.97185929648, total=  16.1s\n",
      "[CV] C=3.02206030151 .................................................\n",
      "[CV] .................................. C=2.97185929648, total=  15.7s\n",
      "[CV] C=3.02206030151 .................................................\n",
      "[CV] .................................. C=2.97185929648, total=  16.5s\n",
      "[CV] C=3.02206030151 .................................................\n",
      "[CV] .................................. C=3.02206030151, total=  16.3s\n",
      "[CV] C=3.02206030151 .................................................\n",
      "[CV] .................................. C=3.02206030151, total=  16.2s\n",
      "[CV] .................................. C=3.02206030151, total=  16.1s\n",
      "[CV] C=3.07226130653 .................................................\n",
      "[CV] C=3.07226130653 .................................................\n",
      "[CV] .................................. C=3.02206030151, total=  16.0s\n",
      "[CV] C=3.07226130653 .................................................\n",
      "[CV] .................................. C=3.02206030151, total=  15.6s\n",
      "[CV] C=3.07226130653 .................................................\n",
      "[CV] .................................. C=3.07226130653, total=  14.9s\n",
      "[CV] C=3.07226130653 .................................................\n",
      "[CV] .................................. C=3.07226130653, total=  15.1s\n",
      "[CV] C=3.12246231156 .................................................\n",
      "[CV] .................................. C=3.07226130653, total=  14.6s\n",
      "[CV] C=3.12246231156 .................................................\n",
      "[CV] .................................. C=3.07226130653, total=  16.1s\n",
      "[CV] C=3.12246231156 .................................................\n",
      "[CV] .................................. C=3.12246231156, total=  16.0s\n",
      "[CV] C=3.12246231156 .................................................\n",
      "[CV] .................................. C=3.07226130653, total=  16.6s\n",
      "[CV] C=3.12246231156 .................................................\n",
      "[CV] .................................. C=3.12246231156, total=  16.5s\n",
      "[CV] C=3.17266331658 .................................................\n",
      "[CV] .................................. C=3.12246231156, total=  15.0s\n",
      "[CV] C=3.17266331658 .................................................\n",
      "[CV] .................................. C=3.12246231156, total=  14.9s\n",
      "[CV] C=3.17266331658 .................................................\n",
      "[CV] .................................. C=3.12246231156, total=  15.0s\n",
      "[CV] C=3.17266331658 .................................................\n",
      "[CV] .................................. C=3.17266331658, total=  14.9s\n",
      "[CV] C=3.17266331658 .................................................\n",
      "[CV] .................................. C=3.17266331658, total=  15.1s\n",
      "[CV] C=3.22286432161 .................................................\n",
      "[CV] .................................. C=3.17266331658, total=  14.8s\n",
      "[CV] C=3.22286432161 .................................................\n",
      "[CV] .................................. C=3.17266331658, total=  15.0s\n",
      "[CV] C=3.22286432161 .................................................\n",
      "[CV] .................................. C=3.17266331658, total=  15.4s\n",
      "[CV] C=3.22286432161 .................................................\n",
      "[CV] .................................. C=3.22286432161, total=  16.0s\n",
      "[CV] C=3.22286432161 .................................................\n",
      "[CV] .................................. C=3.22286432161, total=  15.5s\n",
      "[CV] C=3.27306532663 .................................................\n",
      "[CV] .................................. C=3.22286432161, total=  15.0s\n",
      "[CV] C=3.27306532663 .................................................\n",
      "[CV] .................................. C=3.22286432161, total=  15.3s\n",
      "[CV] C=3.27306532663 .................................................\n",
      "[CV] .................................. C=3.22286432161, total=  16.6s\n",
      "[CV] C=3.27306532663 .................................................\n",
      "[CV] .................................. C=3.27306532663, total=  16.5s\n",
      "[CV] C=3.27306532663 .................................................\n",
      "[CV] .................................. C=3.27306532663, total=  16.7s\n",
      "[CV] C=3.32326633166 .................................................\n",
      "[CV] .................................. C=3.27306532663, total=  17.1s\n",
      "[CV] C=3.32326633166 .................................................\n",
      "[CV] .................................. C=3.27306532663, total=  18.0s\n",
      "[CV] C=3.32326633166 .................................................\n",
      "[CV] .................................. C=3.32326633166, total=  17.8s\n",
      "[CV] C=3.32326633166 .................................................\n",
      "[CV] .................................. C=3.27306532663, total=  18.3s\n",
      "[CV] C=3.32326633166 .................................................\n",
      "[CV] .................................. C=3.32326633166, total=  18.0s\n",
      "[CV] C=3.37346733668 .................................................\n",
      "[CV] .................................. C=3.32326633166, total=  18.9s\n",
      "[CV] .................................. C=3.32326633166, total=  19.4s\n",
      "[CV] C=3.37346733668 .................................................\n",
      "[CV] .................................. C=3.32326633166, total=  19.1s\n",
      "[CV] C=3.37346733668 .................................................\n",
      "[CV] C=3.37346733668 .................................................\n",
      "[CV] .................................. C=3.37346733668, total=  18.7s\n",
      "[CV] C=3.37346733668 .................................................\n",
      "[CV] .................................. C=3.37346733668, total=  16.2s\n",
      "[CV] C=3.42366834171 .................................................\n",
      "[CV] .................................. C=3.37346733668, total=  16.7s\n",
      "[CV] C=3.42366834171 .................................................\n",
      "[CV] .................................. C=3.37346733668, total=  16.9s\n",
      "[CV] C=3.42366834171 .................................................\n",
      "[CV] .................................. C=3.37346733668, total=  16.7s\n",
      "[CV] C=3.42366834171 .................................................\n",
      "[CV] .................................. C=3.42366834171, total=  15.9s\n",
      "[CV] C=3.42366834171 .................................................\n",
      "[CV] .................................. C=3.42366834171, total=  17.1s\n",
      "[CV] C=3.47386934673 .................................................\n",
      "[CV] .................................. C=3.42366834171, total=  17.1s\n",
      "[CV] C=3.47386934673 .................................................\n",
      "[CV] .................................. C=3.42366834171, total=  16.9s\n",
      "[CV] C=3.47386934673 .................................................\n",
      "[CV] .................................. C=3.42366834171, total=  17.6s\n",
      "[CV] C=3.47386934673 .................................................\n",
      "[CV] .................................. C=3.47386934673, total=  17.9s\n",
      "[CV] C=3.47386934673 .................................................\n",
      "[CV] .................................. C=3.47386934673, total=  18.3s\n",
      "[CV] C=3.52407035176 .................................................\n",
      "[CV] .................................. C=3.47386934673, total=  18.7s\n",
      "[CV] C=3.52407035176 .................................................\n",
      "[CV] .................................. C=3.47386934673, total=  16.5s\n",
      "[CV] C=3.52407035176 .................................................\n",
      "[CV] .................................. C=3.47386934673, total=  16.2s\n",
      "[CV] C=3.52407035176 .................................................\n",
      "[CV] .................................. C=3.52407035176, total=  16.8s\n",
      "[CV] C=3.52407035176 .................................................\n",
      "[CV] .................................. C=3.52407035176, total=  16.4s\n",
      "[CV] C=3.57427135678 .................................................\n",
      "[CV] .................................. C=3.52407035176, total=  16.8s\n",
      "[CV] C=3.57427135678 .................................................\n",
      "[CV] .................................. C=3.52407035176, total=  17.0s\n",
      "[CV] C=3.57427135678 .................................................\n",
      "[CV] .................................. C=3.52407035176, total=  16.7s\n",
      "[CV] C=3.57427135678 .................................................\n",
      "[CV] .................................. C=3.57427135678, total=  16.8s\n",
      "[CV] C=3.57427135678 .................................................\n",
      "[CV] .................................. C=3.57427135678, total=  17.2s\n",
      "[CV] C=3.62447236181 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 19.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=3.57427135678, total=  17.2s\n",
      "[CV] C=3.62447236181 .................................................\n",
      "[CV] .................................. C=3.57427135678, total=  17.1s\n",
      "[CV] C=3.62447236181 .................................................\n",
      "[CV] .................................. C=3.57427135678, total=  17.1s\n",
      "[CV] C=3.62447236181 .................................................\n",
      "[CV] .................................. C=3.62447236181, total=  18.0s\n",
      "[CV] C=3.62447236181 .................................................\n",
      "[CV] .................................. C=3.62447236181, total=  18.4s\n",
      "[CV] C=3.67467336683 .................................................\n",
      "[CV] .................................. C=3.62447236181, total=  18.1s\n",
      "[CV] C=3.67467336683 .................................................\n",
      "[CV] .................................. C=3.62447236181, total=  17.3s\n",
      "[CV] C=3.67467336683 .................................................\n",
      "[CV] .................................. C=3.62447236181, total=  15.6s\n",
      "[CV] C=3.67467336683 .................................................\n",
      "[CV] .................................. C=3.67467336683, total=  15.3s\n",
      "[CV] C=3.67467336683 .................................................\n",
      "[CV] .................................. C=3.67467336683, total=  15.8s\n",
      "[CV] C=3.72487437186 .................................................\n",
      "[CV] .................................. C=3.67467336683, total=  15.5s\n",
      "[CV] C=3.72487437186 .................................................\n",
      "[CV] .................................. C=3.67467336683, total=  14.6s\n",
      "[CV] C=3.72487437186 .................................................\n",
      "[CV] .................................. C=3.67467336683, total=  15.3s\n",
      "[CV] C=3.72487437186 .................................................\n",
      "[CV] .................................. C=3.72487437186, total=  15.1s\n",
      "[CV] C=3.72487437186 .................................................\n",
      "[CV] .................................. C=3.72487437186, total=  14.9s\n",
      "[CV] C=3.77507537688 .................................................\n",
      "[CV] .................................. C=3.72487437186, total=  15.4s\n",
      "[CV] C=3.77507537688 .................................................\n",
      "[CV] .................................. C=3.72487437186, total=  15.4s\n",
      "[CV] C=3.77507537688 .................................................\n",
      "[CV] .................................. C=3.77507537688, total=  15.0s\n",
      "[CV] .................................. C=3.72487437186, total=  15.5s\n",
      "[CV] C=3.77507537688 .................................................\n",
      "[CV] C=3.77507537688 .................................................\n",
      "[CV] .................................. C=3.77507537688, total=  15.0s\n",
      "[CV] C=3.82527638191 .................................................\n",
      "[CV] .................................. C=3.77507537688, total=  15.9s\n",
      "[CV] C=3.82527638191 .................................................\n",
      "[CV] .................................. C=3.77507537688, total=  15.6s\n",
      "[CV] C=3.82527638191 .................................................\n",
      "[CV] .................................. C=3.77507537688, total=  15.8s\n",
      "[CV] C=3.82527638191 .................................................\n",
      "[CV] .................................. C=3.82527638191, total=  15.8s\n",
      "[CV] C=3.82527638191 .................................................\n",
      "[CV] .................................. C=3.82527638191, total=  15.9s\n",
      "[CV] C=3.87547738693 .................................................\n",
      "[CV] .................................. C=3.82527638191, total=  15.7s\n",
      "[CV] C=3.87547738693 .................................................\n",
      "[CV] .................................. C=3.82527638191, total=  16.5s\n",
      "[CV] C=3.87547738693 .................................................\n",
      "[CV] .................................. C=3.82527638191, total=  19.5s\n",
      "[CV] C=3.87547738693 .................................................\n",
      "[CV] .................................. C=3.87547738693, total=  18.4s\n",
      "[CV] C=3.87547738693 .................................................\n",
      "[CV] .................................. C=3.87547738693, total=  19.3s\n",
      "[CV] C=3.92567839196 .................................................\n",
      "[CV] .................................. C=3.87547738693, total=  19.5s\n",
      "[CV] C=3.92567839196 .................................................\n",
      "[CV] .................................. C=3.87547738693, total=  18.1s\n",
      "[CV] C=3.92567839196 .................................................\n",
      "[CV] .................................. C=3.87547738693, total=  18.3s\n",
      "[CV] C=3.92567839196 .................................................\n",
      "[CV] .................................. C=3.92567839196, total=  18.5s\n",
      "[CV] C=3.92567839196 .................................................\n",
      "[CV] .................................. C=3.92567839196, total=  18.4s\n",
      "[CV] C=3.97587939698 .................................................\n",
      "[CV] .................................. C=3.92567839196, total=  19.3s\n",
      "[CV] C=3.97587939698 .................................................\n",
      "[CV] .................................. C=3.92567839196, total=  19.7s\n",
      "[CV] C=3.97587939698 .................................................\n",
      "[CV] .................................. C=3.92567839196, total=  20.3s\n",
      "[CV] C=3.97587939698 .................................................\n",
      "[CV] .................................. C=3.97587939698, total=  20.6s\n",
      "[CV] C=3.97587939698 .................................................\n",
      "[CV] .................................. C=3.97587939698, total=  18.1s\n",
      "[CV] C=4.02608040201 .................................................\n",
      "[CV] .................................. C=3.97587939698, total=  17.1s\n",
      "[CV] C=4.02608040201 .................................................\n",
      "[CV] .................................. C=3.97587939698, total=  17.2s\n",
      "[CV] C=4.02608040201 .................................................\n",
      "[CV] .................................. C=3.97587939698, total=  17.0s\n",
      "[CV] C=4.02608040201 .................................................\n",
      "[CV] .................................. C=4.02608040201, total=  18.1s\n",
      "[CV] C=4.02608040201 .................................................\n",
      "[CV] .................................. C=4.02608040201, total=  18.8s\n",
      "[CV] C=4.07628140704 .................................................\n",
      "[CV] .................................. C=4.02608040201, total=  18.6s\n",
      "[CV] C=4.07628140704 .................................................\n",
      "[CV] .................................. C=4.02608040201, total=  19.2s\n",
      "[CV] C=4.07628140704 .................................................\n",
      "[CV] .................................. C=4.02608040201, total=  19.5s\n",
      "[CV] C=4.07628140704 .................................................\n",
      "[CV] .................................. C=4.07628140704, total=  18.7s\n",
      "[CV] C=4.07628140704 .................................................\n",
      "[CV] .................................. C=4.07628140704, total=  18.4s\n",
      "[CV] C=4.12648241206 .................................................\n",
      "[CV] .................................. C=4.07628140704, total=  19.8s\n",
      "[CV] C=4.12648241206 .................................................\n",
      "[CV] .................................. C=4.07628140704, total=  17.8s\n",
      "[CV] C=4.12648241206 .................................................\n",
      "[CV] .................................. C=4.07628140704, total=  18.0s\n",
      "[CV] C=4.12648241206 .................................................\n",
      "[CV] .................................. C=4.12648241206, total=  17.7s\n",
      "[CV] C=4.12648241206 .................................................\n",
      "[CV] .................................. C=4.12648241206, total=  17.8s\n",
      "[CV] C=4.17668341709 .................................................\n",
      "[CV] .................................. C=4.12648241206, total=  19.5s\n",
      "[CV] C=4.17668341709 .................................................\n",
      "[CV] .................................. C=4.12648241206, total=  19.4s\n",
      "[CV] C=4.17668341709 .................................................\n",
      "[CV] .................................. C=4.12648241206, total=  19.6s\n",
      "[CV] C=4.17668341709 .................................................\n",
      "[CV] .................................. C=4.17668341709, total=  18.9s\n",
      "[CV] C=4.17668341709 .................................................\n",
      "[CV] .................................. C=4.17668341709, total=  20.2s\n",
      "[CV] C=4.22688442211 .................................................\n",
      "[CV] .................................. C=4.17668341709, total=  19.7s\n",
      "[CV] C=4.22688442211 .................................................\n",
      "[CV] .................................. C=4.17668341709, total=  19.6s\n",
      "[CV] C=4.22688442211 .................................................\n",
      "[CV] .................................. C=4.17668341709, total=  19.8s\n",
      "[CV] C=4.22688442211 .................................................\n",
      "[CV] .................................. C=4.22688442211, total=  18.1s\n",
      "[CV] C=4.22688442211 .................................................\n",
      "[CV] .................................. C=4.22688442211, total=  19.2s\n",
      "[CV] C=4.27708542714 .................................................\n",
      "[CV] .................................. C=4.22688442211, total=  19.8s\n",
      "[CV] C=4.27708542714 .................................................\n",
      "[CV] .................................. C=4.22688442211, total=  19.7s\n",
      "[CV] C=4.27708542714 .................................................\n",
      "[CV] .................................. C=4.22688442211, total=  19.3s\n",
      "[CV] C=4.27708542714 .................................................\n",
      "[CV] .................................. C=4.27708542714, total=  17.9s\n",
      "[CV] C=4.27708542714 .................................................\n",
      "[CV] .................................. C=4.27708542714, total=  18.2s\n",
      "[CV] C=4.32728643216 .................................................\n",
      "[CV] .................................. C=4.27708542714, total=  17.5s\n",
      "[CV] C=4.32728643216 .................................................\n",
      "[CV] .................................. C=4.27708542714, total=  19.2s\n",
      "[CV] C=4.32728643216 .................................................\n",
      "[CV] .................................. C=4.27708542714, total=  18.6s\n",
      "[CV] C=4.32728643216 .................................................\n",
      "[CV] .................................. C=4.32728643216, total=  19.1s\n",
      "[CV] C=4.32728643216 .................................................\n",
      "[CV] .................................. C=4.32728643216, total=  19.8s\n",
      "[CV] C=4.37748743719 .................................................\n",
      "[CV] .................................. C=4.32728643216, total=  20.0s\n",
      "[CV] C=4.37748743719 .................................................\n",
      "[CV] .................................. C=4.32728643216, total=  20.4s\n",
      "[CV] C=4.37748743719 .................................................\n",
      "[CV] .................................. C=4.32728643216, total=  20.2s\n",
      "[CV] C=4.37748743719 .................................................\n",
      "[CV] .................................. C=4.37748743719, total=  20.1s\n",
      "[CV] C=4.37748743719 .................................................\n",
      "[CV] .................................. C=4.37748743719, total=  19.0s\n",
      "[CV] C=4.42768844221 .................................................\n",
      "[CV] .................................. C=4.37748743719, total=  19.8s\n",
      "[CV] C=4.42768844221 .................................................\n",
      "[CV] .................................. C=4.37748743719, total=  19.7s\n",
      "[CV] C=4.42768844221 .................................................\n",
      "[CV] .................................. C=4.37748743719, total=  20.5s\n",
      "[CV] C=4.42768844221 .................................................\n",
      "[CV] .................................. C=4.42768844221, total=  19.2s\n",
      "[CV] .................................. C=4.42768844221, total=  19.3s\n",
      "[CV] C=4.42768844221 .................................................\n",
      "[CV] C=4.47788944724 .................................................\n",
      "[CV] .................................. C=4.42768844221, total=  19.5s\n",
      "[CV] C=4.47788944724 .................................................\n",
      "[CV] .................................. C=4.42768844221, total=  19.2s\n",
      "[CV] C=4.47788944724 .................................................\n",
      "[CV] .................................. C=4.47788944724, total=  19.3s\n",
      "[CV] C=4.47788944724 .................................................\n",
      "[CV] .................................. C=4.42768844221, total=  19.6s\n",
      "[CV] C=4.47788944724 .................................................\n",
      "[CV] .................................. C=4.47788944724, total=  21.2s\n",
      "[CV] C=4.52809045226 .................................................\n",
      "[CV] .................................. C=4.47788944724, total=  21.1s\n",
      "[CV] C=4.52809045226 .................................................\n",
      "[CV] .................................. C=4.47788944724, total=  23.9s\n",
      "[CV] C=4.52809045226 .................................................\n",
      "[CV] .................................. C=4.47788944724, total=  23.9s\n",
      "[CV] C=4.52809045226 .................................................\n",
      "[CV] .................................. C=4.52809045226, total=  21.5s\n",
      "[CV] C=4.52809045226 .................................................\n",
      "[CV] .................................. C=4.52809045226, total=  21.6s\n",
      "[CV] C=4.57829145729 .................................................\n",
      "[CV] .................................. C=4.52809045226, total=  20.1s\n",
      "[CV] .................................. C=4.52809045226, total=  19.6s\n",
      "[CV] C=4.57829145729 .................................................\n",
      "[CV] C=4.57829145729 .................................................\n",
      "[CV] .................................. C=4.52809045226, total=  19.9s\n",
      "[CV] C=4.57829145729 .................................................\n",
      "[CV] .................................. C=4.57829145729, total=  18.6s\n",
      "[CV] C=4.57829145729 .................................................\n",
      "[CV] .................................. C=4.57829145729, total=  19.9s\n",
      "[CV] C=4.62849246231 .................................................\n",
      "[CV] .................................. C=4.57829145729, total=  20.2s\n",
      "[CV] C=4.62849246231 .................................................\n",
      "[CV] .................................. C=4.57829145729, total=  20.0s\n",
      "[CV] C=4.62849246231 .................................................\n",
      "[CV] .................................. C=4.57829145729, total=  20.9s\n",
      "[CV] C=4.62849246231 .................................................\n",
      "[CV] .................................. C=4.62849246231, total=  20.7s\n",
      "[CV] C=4.62849246231 .................................................\n",
      "[CV] .................................. C=4.62849246231, total=  21.2s\n",
      "[CV] C=4.67869346734 .................................................\n",
      "[CV] .................................. C=4.62849246231, total=  21.8s\n",
      "[CV] C=4.67869346734 .................................................\n",
      "[CV] .................................. C=4.62849246231, total=  21.8s\n",
      "[CV] C=4.67869346734 .................................................\n",
      "[CV] .................................. C=4.62849246231, total=  19.5s\n",
      "[CV] C=4.67869346734 .................................................\n",
      "[CV] .................................. C=4.67869346734, total=  19.3s\n",
      "[CV] C=4.67869346734 .................................................\n",
      "[CV] .................................. C=4.67869346734, total=  18.4s\n",
      "[CV] C=4.72889447236 .................................................\n",
      "[CV] .................................. C=4.67869346734, total=  19.5s\n",
      "[CV] C=4.72889447236 .................................................\n",
      "[CV] .................................. C=4.67869346734, total=  20.2s\n",
      "[CV] C=4.72889447236 .................................................\n",
      "[CV] .................................. C=4.67869346734, total=  21.0s\n",
      "[CV] C=4.72889447236 .................................................\n",
      "[CV] .................................. C=4.72889447236, total=  21.1s\n",
      "[CV] C=4.72889447236 .................................................\n",
      "[CV] .................................. C=4.72889447236, total=  21.2s\n",
      "[CV] C=4.77909547739 .................................................\n",
      "[CV] .................................. C=4.72889447236, total=  24.3s\n",
      "[CV] C=4.77909547739 .................................................\n",
      "[CV] .................................. C=4.72889447236, total=  24.5s\n",
      "[CV] C=4.77909547739 .................................................\n",
      "[CV] .................................. C=4.72889447236, total=  23.5s\n",
      "[CV] C=4.77909547739 .................................................\n",
      "[CV] .................................. C=4.77909547739, total=  23.4s\n",
      "[CV] C=4.77909547739 .................................................\n",
      "[CV] .................................. C=4.77909547739, total=  20.2s\n",
      "[CV] C=4.82929648241 .................................................\n",
      "[CV] .................................. C=4.77909547739, total=  20.1s\n",
      "[CV] C=4.82929648241 .................................................\n",
      "[CV] .................................. C=4.77909547739, total=  20.3s\n",
      "[CV] C=4.82929648241 .................................................\n",
      "[CV] .................................. C=4.77909547739, total=  19.3s\n",
      "[CV] C=4.82929648241 .................................................\n",
      "[CV] .................................. C=4.82929648241, total=  16.6s\n",
      "[CV] C=4.82929648241 .................................................\n",
      "[CV] .................................. C=4.82929648241, total=  16.6s\n",
      "[CV] C=4.87949748744 .................................................\n",
      "[CV] .................................. C=4.82929648241, total=  17.4s\n",
      "[CV] C=4.87949748744 .................................................\n",
      "[CV] .................................. C=4.82929648241, total=  17.8s\n",
      "[CV] C=4.87949748744 .................................................\n",
      "[CV] .................................. C=4.82929648241, total=  18.4s\n",
      "[CV] C=4.87949748744 .................................................\n",
      "[CV] .................................. C=4.87949748744, total=  17.4s\n",
      "[CV] C=4.87949748744 .................................................\n",
      "[CV] .................................. C=4.87949748744, total=  19.3s\n",
      "[CV] C=4.92969849246 .................................................\n",
      "[CV] .................................. C=4.87949748744, total=  19.5s\n",
      "[CV] C=4.92969849246 .................................................\n",
      "[CV] .................................. C=4.87949748744, total=  20.2s\n",
      "[CV] C=4.92969849246 .................................................\n",
      "[CV] .................................. C=4.87949748744, total=  19.9s\n",
      "[CV] C=4.92969849246 .................................................\n",
      "[CV] .................................. C=4.92969849246, total=  19.0s\n",
      "[CV] C=4.92969849246 .................................................\n",
      "[CV] .................................. C=4.92969849246, total=  18.4s\n",
      "[CV] C=4.97989949749 .................................................\n",
      "[CV] .................................. C=4.92969849246, total=  17.3s\n",
      "[CV] .................................. C=4.92969849246, total=  17.4s\n",
      "[CV] C=4.97989949749 .................................................\n",
      "[CV] C=4.97989949749 .................................................\n",
      "[CV] .................................. C=4.92969849246, total=  17.5s\n",
      "[CV] C=4.97989949749 .................................................\n",
      "[CV] .................................. C=4.97989949749, total=  17.4s\n",
      "[CV] C=4.97989949749 .................................................\n",
      "[CV] .................................. C=4.97989949749, total=  17.3s\n",
      "[CV] C=5.03010050251 .................................................\n",
      "[CV] .................................. C=4.97989949749, total=  17.7s\n",
      "[CV] C=5.03010050251 .................................................\n",
      "[CV] .................................. C=4.97989949749, total=  17.2s\n",
      "[CV] C=5.03010050251 .................................................\n",
      "[CV] .................................. C=4.97989949749, total=  17.5s\n",
      "[CV] C=5.03010050251 .................................................\n",
      "[CV] .................................. C=5.03010050251, total=  17.4s\n",
      "[CV] C=5.03010050251 .................................................\n",
      "[CV] .................................. C=5.03010050251, total=  17.8s\n",
      "[CV] C=5.08030150754 .................................................\n",
      "[CV] .................................. C=5.03010050251, total=  18.0s\n",
      "[CV] C=5.08030150754 .................................................\n",
      "[CV] .................................. C=5.03010050251, total=  19.5s\n",
      "[CV] C=5.08030150754 .................................................\n",
      "[CV] .................................. C=5.08030150754, total=  22.2s\n",
      "[CV] C=5.08030150754 .................................................\n",
      "[CV] .................................. C=5.03010050251, total=  22.7s\n",
      "[CV] C=5.08030150754 .................................................\n",
      "[CV] .................................. C=5.08030150754, total=  24.3s\n",
      "[CV] C=5.13050251256 .................................................\n",
      "[CV] .................................. C=5.08030150754, total=  23.9s\n",
      "[CV] C=5.13050251256 .................................................\n",
      "[CV] .................................. C=5.08030150754, total=  23.9s\n",
      "[CV] C=5.13050251256 .................................................\n",
      "[CV] .................................. C=5.08030150754, total=  23.6s\n",
      "[CV] C=5.13050251256 .................................................\n",
      "[CV] .................................. C=5.13050251256, total=  21.5s\n",
      "[CV] C=5.13050251256 .................................................\n",
      "[CV] .................................. C=5.13050251256, total=  21.3s\n",
      "[CV] C=5.18070351759 .................................................\n",
      "[CV] .................................. C=5.13050251256, total=  20.2s\n",
      "[CV] C=5.18070351759 .................................................\n",
      "[CV] .................................. C=5.13050251256, total=  20.2s\n",
      "[CV] C=5.18070351759 .................................................\n",
      "[CV] .................................. C=5.13050251256, total=  20.1s\n",
      "[CV] C=5.18070351759 .................................................\n",
      "[CV] .................................. C=5.18070351759, total=  19.8s\n",
      "[CV] C=5.18070351759 .................................................\n",
      "[CV] .................................. C=5.18070351759, total=  18.5s\n",
      "[CV] C=5.23090452261 .................................................\n",
      "[CV] .................................. C=5.18070351759, total=  18.8s\n",
      "[CV] C=5.23090452261 .................................................\n",
      "[CV] .................................. C=5.18070351759, total=  18.5s\n",
      "[CV] C=5.23090452261 .................................................\n",
      "[CV] .................................. C=5.18070351759, total=  20.8s\n",
      "[CV] C=5.23090452261 .................................................\n",
      "[CV] .................................. C=5.23090452261, total=  23.4s\n",
      "[CV] C=5.23090452261 .................................................\n",
      "[CV] .................................. C=5.23090452261, total=  23.7s\n",
      "[CV] C=5.28110552764 .................................................\n",
      "[CV] .................................. C=5.23090452261, total=  22.4s\n",
      "[CV] C=5.28110552764 .................................................\n",
      "[CV] .................................. C=5.23090452261, total=  23.0s\n",
      "[CV] C=5.28110552764 .................................................\n",
      "[CV] .................................. C=5.23090452261, total=  21.2s\n",
      "[CV] C=5.28110552764 .................................................\n",
      "[CV] .................................. C=5.28110552764, total=  21.3s\n",
      "[CV] C=5.28110552764 .................................................\n",
      "[CV] .................................. C=5.28110552764, total=  20.9s\n",
      "[CV] C=5.33130653266 .................................................\n",
      "[CV] .................................. C=5.28110552764, total=  20.3s\n",
      "[CV] C=5.33130653266 .................................................\n",
      "[CV] .................................. C=5.28110552764, total=  19.8s\n",
      "[CV] C=5.33130653266 .................................................\n",
      "[CV] .................................. C=5.28110552764, total=  21.1s\n",
      "[CV] C=5.33130653266 .................................................\n",
      "[CV] .................................. C=5.33130653266, total=  21.4s\n",
      "[CV] C=5.33130653266 .................................................\n",
      "[CV] .................................. C=5.33130653266, total=  21.8s\n",
      "[CV] C=5.38150753769 .................................................\n",
      "[CV] .................................. C=5.33130653266, total=  21.0s\n",
      "[CV] C=5.38150753769 .................................................\n",
      "[CV] .................................. C=5.33130653266, total=  20.6s\n",
      "[CV] C=5.38150753769 .................................................\n",
      "[CV] .................................. C=5.33130653266, total=  20.5s\n",
      "[CV] C=5.38150753769 .................................................\n",
      "[CV] .................................. C=5.38150753769, total=  20.7s\n",
      "[CV] C=5.38150753769 .................................................\n",
      "[CV] .................................. C=5.38150753769, total=  20.3s\n",
      "[CV] C=5.43170854271 .................................................\n",
      "[CV] .................................. C=5.38150753769, total=  20.5s\n",
      "[CV] C=5.43170854271 .................................................\n",
      "[CV] .................................. C=5.38150753769, total=  20.1s\n",
      "[CV] C=5.43170854271 .................................................\n",
      "[CV] .................................. C=5.38150753769, total=  20.3s\n",
      "[CV] C=5.43170854271 .................................................\n",
      "[CV] .................................. C=5.43170854271, total=  20.4s\n",
      "[CV] C=5.43170854271 .................................................\n",
      "[CV] .................................. C=5.43170854271, total=  20.3s\n",
      "[CV] C=5.48190954774 .................................................\n",
      "[CV] .................................. C=5.43170854271, total=  20.9s\n",
      "[CV] C=5.48190954774 .................................................\n",
      "[CV] .................................. C=5.43170854271, total=  19.5s\n",
      "[CV] C=5.48190954774 .................................................\n",
      "[CV] .................................. C=5.43170854271, total=  18.8s\n",
      "[CV] C=5.48190954774 .................................................\n",
      "[CV] .................................. C=5.48190954774, total=  17.4s\n",
      "[CV] C=5.48190954774 .................................................\n",
      "[CV] .................................. C=5.48190954774, total=  18.1s\n",
      "[CV] C=5.53211055276 .................................................\n",
      "[CV] .................................. C=5.48190954774, total=  18.3s\n",
      "[CV] C=5.53211055276 .................................................\n",
      "[CV] .................................. C=5.48190954774, total=  19.0s\n",
      "[CV] .................................. C=5.48190954774, total=  18.8s\n",
      "[CV] C=5.53211055276 .................................................\n",
      "[CV] C=5.53211055276 .................................................\n",
      "[CV] .................................. C=5.53211055276, total=  20.0s\n",
      "[CV] C=5.53211055276 .................................................\n",
      "[CV] .................................. C=5.53211055276, total=  20.8s\n",
      "[CV] C=5.58231155779 .................................................\n",
      "[CV] .................................. C=5.53211055276, total=  20.2s\n",
      "[CV] C=5.58231155779 .................................................\n",
      "[CV] .................................. C=5.53211055276, total=  20.4s\n",
      "[CV] C=5.58231155779 .................................................\n",
      "[CV] .................................. C=5.53211055276, total=  19.0s\n",
      "[CV] C=5.58231155779 .................................................\n",
      "[CV] .................................. C=5.58231155779, total=  21.5s\n",
      "[CV] C=5.58231155779 .................................................\n",
      "[CV] .................................. C=5.58231155779, total=  23.4s\n",
      "[CV] C=5.63251256281 .................................................\n",
      "[CV] .................................. C=5.58231155779, total=  23.8s\n",
      "[CV] C=5.63251256281 .................................................\n",
      "[CV] .................................. C=5.58231155779, total=  24.1s\n",
      "[CV] C=5.63251256281 .................................................\n",
      "[CV] .................................. C=5.58231155779, total=  21.4s\n",
      "[CV] C=5.63251256281 .................................................\n",
      "[CV] .................................. C=5.63251256281, total=  19.7s\n",
      "[CV] C=5.63251256281 .................................................\n",
      "[CV] .................................. C=5.63251256281, total=  19.7s\n",
      "[CV] C=5.68271356784 .................................................\n",
      "[CV] .................................. C=5.63251256281, total=  20.0s\n",
      "[CV] C=5.68271356784 .................................................\n",
      "[CV] .................................. C=5.63251256281, total=  20.4s\n",
      "[CV] C=5.68271356784 .................................................\n",
      "[CV] .................................. C=5.63251256281, total=  21.3s\n",
      "[CV] C=5.68271356784 .................................................\n",
      "[CV] .................................. C=5.68271356784, total=  20.9s\n",
      "[CV] C=5.68271356784 .................................................\n",
      "[CV] .................................. C=5.68271356784, total=  22.4s\n",
      "[CV] C=5.73291457286 .................................................\n",
      "[CV] .................................. C=5.68271356784, total=  22.9s\n",
      "[CV] C=5.73291457286 .................................................\n",
      "[CV] .................................. C=5.68271356784, total=  25.0s\n",
      "[CV] C=5.73291457286 .................................................\n",
      "[CV] .................................. C=5.68271356784, total=  25.3s\n",
      "[CV] C=5.73291457286 .................................................\n",
      "[CV] .................................. C=5.73291457286, total=  23.3s\n",
      "[CV] C=5.73291457286 .................................................\n",
      "[CV] .................................. C=5.73291457286, total=  23.0s\n",
      "[CV] C=5.78311557789 .................................................\n",
      "[CV] .................................. C=5.73291457286, total=  20.9s\n",
      "[CV] C=5.78311557789 .................................................\n",
      "[CV] .................................. C=5.73291457286, total=  20.8s\n",
      "[CV] C=5.78311557789 .................................................\n",
      "[CV] .................................. C=5.73291457286, total=  21.5s\n",
      "[CV] C=5.78311557789 .................................................\n",
      "[CV] .................................. C=5.78311557789, total=  22.8s\n",
      "[CV] C=5.78311557789 .................................................\n",
      "[CV] .................................. C=5.78311557789, total=  22.9s\n",
      "[CV] C=5.83331658291 .................................................\n",
      "[CV] .................................. C=5.78311557789, total=  22.8s\n",
      "[CV] C=5.83331658291 .................................................\n",
      "[CV] .................................. C=5.78311557789, total=  22.2s\n",
      "[CV] C=5.83331658291 .................................................\n",
      "[CV] .................................. C=5.78311557789, total=  21.8s\n",
      "[CV] C=5.83331658291 .................................................\n",
      "[CV] .................................. C=5.83331658291, total=  21.3s\n",
      "[CV] .................................. C=5.83331658291, total=  21.5s\n",
      "[CV] C=5.83331658291 .................................................\n",
      "[CV] C=5.88351758794 .................................................\n",
      "[CV] .................................. C=5.83331658291, total=  22.1s\n",
      "[CV] C=5.88351758794 .................................................\n",
      "[CV] .................................. C=5.83331658291, total=  22.0s\n",
      "[CV] C=5.88351758794 .................................................\n",
      "[CV] .................................. C=5.83331658291, total=  21.2s\n",
      "[CV] C=5.88351758794 .................................................\n",
      "[CV] .................................. C=5.88351758794, total=  21.8s\n",
      "[CV] C=5.88351758794 .................................................\n",
      "[CV] .................................. C=5.88351758794, total=  21.7s\n",
      "[CV] C=5.93371859296 .................................................\n",
      "[CV] .................................. C=5.88351758794, total=  21.5s\n",
      "[CV] C=5.93371859296 .................................................\n",
      "[CV] .................................. C=5.88351758794, total=  21.6s\n",
      "[CV] C=5.93371859296 .................................................\n",
      "[CV] .................................. C=5.88351758794, total=  21.6s\n",
      "[CV] C=5.93371859296 .................................................\n",
      "[CV] .................................. C=5.93371859296, total=  21.9s\n",
      "[CV] C=5.93371859296 .................................................\n",
      "[CV] .................................. C=5.93371859296, total=  22.0s\n",
      "[CV] C=5.98391959799 .................................................\n",
      "[CV] .................................. C=5.93371859296, total=  21.5s\n",
      "[CV] C=5.98391959799 .................................................\n",
      "[CV] .................................. C=5.93371859296, total=  22.3s\n",
      "[CV] C=5.98391959799 .................................................\n",
      "[CV] .................................. C=5.93371859296, total=  22.1s\n",
      "[CV] C=5.98391959799 .................................................\n",
      "[CV] .................................. C=5.98391959799, total=  21.7s\n",
      "[CV] C=5.98391959799 .................................................\n",
      "[CV] .................................. C=5.98391959799, total=  20.2s\n",
      "[CV] C=6.03412060302 .................................................\n",
      "[CV] .................................. C=5.98391959799, total=  21.0s\n",
      "[CV] C=6.03412060302 .................................................\n",
      "[CV] .................................. C=5.98391959799, total=  20.8s\n",
      "[CV] C=6.03412060302 .................................................\n",
      "[CV] .................................. C=5.98391959799, total=  21.6s\n",
      "[CV] C=6.03412060302 .................................................\n",
      "[CV] .................................. C=6.03412060302, total=  21.1s\n",
      "[CV] C=6.03412060302 .................................................\n",
      "[CV] .................................. C=6.03412060302, total=  22.4s\n",
      "[CV] C=6.08432160804 .................................................\n",
      "[CV] .................................. C=6.03412060302, total=  23.0s\n",
      "[CV] C=6.08432160804 .................................................\n",
      "[CV] .................................. C=6.03412060302, total=  22.1s\n",
      "[CV] C=6.08432160804 .................................................\n",
      "[CV] .................................. C=6.03412060302, total=  21.8s\n",
      "[CV] C=6.08432160804 .................................................\n",
      "[CV] .................................. C=6.08432160804, total=  20.8s\n",
      "[CV] C=6.08432160804 .................................................\n",
      "[CV] .................................. C=6.08432160804, total=  22.3s\n",
      "[CV] C=6.13452261307 .................................................\n",
      "[CV] .................................. C=6.08432160804, total=  22.2s\n",
      "[CV] C=6.13452261307 .................................................\n",
      "[CV] .................................. C=6.08432160804, total=  23.0s\n",
      "[CV] C=6.13452261307 .................................................\n",
      "[CV] .................................. C=6.08432160804, total=  23.4s\n",
      "[CV] C=6.13452261307 .................................................\n",
      "[CV] .................................. C=6.13452261307, total=  22.2s\n",
      "[CV] C=6.13452261307 .................................................\n",
      "[CV] .................................. C=6.13452261307, total=  23.8s\n",
      "[CV] C=6.18472361809 .................................................\n",
      "[CV] .................................. C=6.13452261307, total=  25.6s\n",
      "[CV] C=6.18472361809 .................................................\n",
      "[CV] .................................. C=6.13452261307, total=  26.8s\n",
      "[CV] C=6.18472361809 .................................................\n",
      "[CV] .................................. C=6.13452261307, total=  27.6s\n",
      "[CV] C=6.18472361809 .................................................\n",
      "[CV] .................................. C=6.18472361809, total=  24.7s\n",
      "[CV] C=6.18472361809 .................................................\n",
      "[CV] .................................. C=6.18472361809, total=  21.3s\n",
      "[CV] C=6.23492462312 .................................................\n",
      "[CV] .................................. C=6.18472361809, total=  21.3s\n",
      "[CV] C=6.23492462312 .................................................\n",
      "[CV] .................................. C=6.18472361809, total=  20.3s\n",
      "[CV] C=6.23492462312 .................................................\n",
      "[CV] .................................. C=6.18472361809, total=  21.4s\n",
      "[CV] C=6.23492462312 .................................................\n",
      "[CV] .................................. C=6.23492462312, total=  21.2s\n",
      "[CV] C=6.23492462312 .................................................\n",
      "[CV] .................................. C=6.23492462312, total=  21.9s\n",
      "[CV] C=6.28512562814 .................................................\n",
      "[CV] .................................. C=6.23492462312, total=  23.3s\n",
      "[CV] C=6.28512562814 .................................................\n",
      "[CV] .................................. C=6.23492462312, total=  24.0s\n",
      "[CV] C=6.28512562814 .................................................\n",
      "[CV] .................................. C=6.23492462312, total=  25.0s\n",
      "[CV] C=6.28512562814 .................................................\n",
      "[CV] .................................. C=6.28512562814, total=  23.8s\n",
      "[CV] C=6.28512562814 .................................................\n",
      "[CV] .................................. C=6.28512562814, total=  23.4s\n",
      "[CV] C=6.33532663317 .................................................\n",
      "[CV] .................................. C=6.28512562814, total=  22.0s\n",
      "[CV] C=6.33532663317 .................................................\n",
      "[CV] .................................. C=6.28512562814, total=  21.4s\n",
      "[CV] C=6.33532663317 .................................................\n",
      "[CV] .................................. C=6.28512562814, total=  22.2s\n",
      "[CV] C=6.33532663317 .................................................\n",
      "[CV] .................................. C=6.33532663317, total=  22.7s\n",
      "[CV] C=6.33532663317 .................................................\n",
      "[CV] .................................. C=6.33532663317, total=  24.5s\n",
      "[CV] C=6.38552763819 .................................................\n",
      "[CV] .................................. C=6.33532663317, total=  26.2s\n",
      "[CV] C=6.38552763819 .................................................\n",
      "[CV] .................................. C=6.33532663317, total=  25.9s\n",
      "[CV] C=6.38552763819 .................................................\n",
      "[CV] .................................. C=6.33532663317, total=  25.7s\n",
      "[CV] C=6.38552763819 .................................................\n",
      "[CV] .................................. C=6.38552763819, total=  25.5s\n",
      "[CV] C=6.38552763819 .................................................\n",
      "[CV] .................................. C=6.38552763819, total=  25.4s\n",
      "[CV] C=6.43572864322 .................................................\n",
      "[CV] .................................. C=6.38552763819, total=  25.0s\n",
      "[CV] C=6.43572864322 .................................................\n",
      "[CV] .................................. C=6.38552763819, total=  23.2s\n",
      "[CV] C=6.43572864322 .................................................\n",
      "[CV] .................................. C=6.38552763819, total=  23.8s\n",
      "[CV] C=6.43572864322 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 43.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................. C=6.43572864322, total=  22.4s\n",
      "[CV] C=6.43572864322 .................................................\n",
      "[CV] .................................. C=6.43572864322, total=  22.5s\n",
      "[CV] C=6.48592964824 .................................................\n",
      "[CV] .................................. C=6.43572864322, total=  21.9s\n",
      "[CV] C=6.48592964824 .................................................\n",
      "[CV] .................................. C=6.43572864322, total=  22.2s\n",
      "[CV] C=6.48592964824 .................................................\n",
      "[CV] .................................. C=6.43572864322, total=  21.8s\n",
      "[CV] C=6.48592964824 .................................................\n",
      "[CV] .................................. C=6.48592964824, total=  21.7s\n",
      "[CV] C=6.48592964824 .................................................\n",
      "[CV] .................................. C=6.48592964824, total=  21.4s\n",
      "[CV] C=6.53613065327 .................................................\n",
      "[CV] .................................. C=6.48592964824, total=  23.0s\n",
      "[CV] C=6.53613065327 .................................................\n",
      "[CV] .................................. C=6.48592964824, total=  24.8s\n",
      "[CV] C=6.53613065327 .................................................\n",
      "[CV] .................................. C=6.48592964824, total=  25.3s\n",
      "[CV] C=6.53613065327 .................................................\n",
      "[CV] .................................. C=6.53613065327, total=  25.6s\n",
      "[CV] C=6.53613065327 .................................................\n",
      "[CV] .................................. C=6.53613065327, total=  23.7s\n",
      "[CV] C=6.58633165829 .................................................\n",
      "[CV] .................................. C=6.53613065327, total=  23.1s\n",
      "[CV] C=6.58633165829 .................................................\n",
      "[CV] .................................. C=6.53613065327, total=  22.8s\n",
      "[CV] C=6.58633165829 .................................................\n",
      "[CV] .................................. C=6.53613065327, total=  23.5s\n",
      "[CV] C=6.58633165829 .................................................\n",
      "[CV] .................................. C=6.58633165829, total=  24.4s\n",
      "[CV] C=6.58633165829 .................................................\n",
      "[CV] .................................. C=6.58633165829, total=  24.7s\n",
      "[CV] C=6.63653266332 .................................................\n",
      "[CV] .................................. C=6.58633165829, total=  24.1s\n",
      "[CV] C=6.63653266332 .................................................\n",
      "[CV] .................................. C=6.58633165829, total=  22.9s\n",
      "[CV] C=6.63653266332 .................................................\n",
      "[CV] .................................. C=6.58633165829, total=  23.0s\n",
      "[CV] C=6.63653266332 .................................................\n",
      "[CV] .................................. C=6.63653266332, total=  22.1s\n",
      "[CV] C=6.63653266332 .................................................\n",
      "[CV] .................................. C=6.63653266332, total=  21.4s\n",
      "[CV] C=6.68673366834 .................................................\n",
      "[CV] .................................. C=6.63653266332, total=  21.9s\n",
      "[CV] C=6.68673366834 .................................................\n",
      "[CV] .................................. C=6.63653266332, total=  20.3s\n",
      "[CV] C=6.68673366834 .................................................\n",
      "[CV] .................................. C=6.63653266332, total=  21.2s\n",
      "[CV] C=6.68673366834 .................................................\n",
      "[CV] .................................. C=6.68673366834, total=  22.0s\n",
      "[CV] C=6.68673366834 .................................................\n",
      "[CV] .................................. C=6.68673366834, total=  24.1s\n",
      "[CV] C=6.73693467337 .................................................\n",
      "[CV] .................................. C=6.68673366834, total=  24.8s\n",
      "[CV] C=6.73693467337 .................................................\n",
      "[CV] .................................. C=6.68673366834, total=  23.1s\n",
      "[CV] C=6.73693467337 .................................................\n",
      "[CV] .................................. C=6.68673366834, total=  24.2s\n",
      "[CV] C=6.73693467337 .................................................\n",
      "[CV] .................................. C=6.73693467337, total=  24.0s\n",
      "[CV] C=6.73693467337 .................................................\n",
      "[CV] .................................. C=6.73693467337, total=  23.8s\n",
      "[CV] C=6.78713567839 .................................................\n",
      "[CV] .................................. C=6.73693467337, total=  23.1s\n",
      "[CV] C=6.78713567839 .................................................\n",
      "[CV] .................................. C=6.73693467337, total=  23.3s\n",
      "[CV] C=6.78713567839 .................................................\n",
      "[CV] .................................. C=6.73693467337, total=  23.9s\n",
      "[CV] C=6.78713567839 .................................................\n",
      "[CV] .................................. C=6.78713567839, total=  23.7s\n",
      "[CV] C=6.78713567839 .................................................\n",
      "[CV] .................................. C=6.78713567839, total=  24.4s\n",
      "[CV] C=6.83733668342 .................................................\n",
      "[CV] .................................. C=6.78713567839, total=  23.6s\n",
      "[CV] C=6.83733668342 .................................................\n",
      "[CV] .................................. C=6.78713567839, total=  23.1s\n",
      "[CV] C=6.83733668342 .................................................\n",
      "[CV] .................................. C=6.78713567839, total=  22.9s\n",
      "[CV] C=6.83733668342 .................................................\n",
      "[CV] .................................. C=6.83733668342, total=  21.8s\n",
      "[CV] C=6.83733668342 .................................................\n",
      "[CV] .................................. C=6.83733668342, total=  22.3s\n",
      "[CV] C=6.88753768844 .................................................\n",
      "[CV] .................................. C=6.83733668342, total=  22.3s\n",
      "[CV] C=6.88753768844 .................................................\n",
      "[CV] .................................. C=6.83733668342, total=  22.5s\n",
      "[CV] C=6.88753768844 .................................................\n",
      "[CV] .................................. C=6.83733668342, total=  22.0s\n",
      "[CV] C=6.88753768844 .................................................\n",
      "[CV] .................................. C=6.88753768844, total=  21.7s\n",
      "[CV] C=6.88753768844 .................................................\n",
      "[CV] .................................. C=6.88753768844, total=  22.5s\n",
      "[CV] C=6.93773869347 .................................................\n",
      "[CV] .................................. C=6.88753768844, total=  22.5s\n",
      "[CV] C=6.93773869347 .................................................\n",
      "[CV] .................................. C=6.88753768844, total=  22.0s\n",
      "[CV] C=6.93773869347 .................................................\n",
      "[CV] .................................. C=6.88753768844, total=  24.0s\n",
      "[CV] C=6.93773869347 .................................................\n",
      "[CV] .................................. C=6.93773869347, total=  24.0s\n",
      "[CV] C=6.93773869347 .................................................\n",
      "[CV] .................................. C=6.93773869347, total=  24.1s\n",
      "[CV] C=6.98793969849 .................................................\n",
      "[CV] .................................. C=6.93773869347, total=  25.2s\n",
      "[CV] C=6.98793969849 .................................................\n",
      "[CV] .................................. C=6.93773869347, total=  24.6s\n",
      "[CV] C=6.98793969849 .................................................\n",
      "[CV] .................................. C=6.93773869347, total=  23.5s\n",
      "[CV] C=6.98793969849 .................................................\n",
      "[CV] .................................. C=6.98793969849, total=  23.5s\n",
      "[CV] C=6.98793969849 .................................................\n",
      "[CV] .................................. C=6.98793969849, total=  22.7s\n",
      "[CV] C=7.03814070352 .................................................\n",
      "[CV] .................................. C=6.98793969849, total=  22.6s\n",
      "[CV] C=7.03814070352 .................................................\n",
      "[CV] .................................. C=6.98793969849, total=  22.3s\n",
      "[CV] C=7.03814070352 .................................................\n",
      "[CV] .................................. C=6.98793969849, total=  22.0s\n",
      "[CV] C=7.03814070352 .................................................\n",
      "[CV] .................................. C=7.03814070352, total=  22.6s\n",
      "[CV] C=7.03814070352 .................................................\n",
      "[CV] .................................. C=7.03814070352, total=  23.4s\n",
      "[CV] C=7.08834170854 .................................................\n",
      "[CV] .................................. C=7.03814070352, total=  22.8s\n",
      "[CV] C=7.08834170854 .................................................\n",
      "[CV] .................................. C=7.03814070352, total=  22.3s\n",
      "[CV] C=7.08834170854 .................................................\n",
      "[CV] .................................. C=7.03814070352, total=  22.7s\n",
      "[CV] C=7.08834170854 .................................................\n",
      "[CV] .................................. C=7.08834170854, total=  22.4s\n",
      "[CV] C=7.08834170854 .................................................\n",
      "[CV] .................................. C=7.08834170854, total=  22.7s\n",
      "[CV] C=7.13854271357 .................................................\n",
      "[CV] .................................. C=7.08834170854, total=  22.4s\n",
      "[CV] C=7.13854271357 .................................................\n",
      "[CV] .................................. C=7.08834170854, total=  22.8s\n",
      "[CV] C=7.13854271357 .................................................\n",
      "[CV] .................................. C=7.08834170854, total=  23.3s\n",
      "[CV] C=7.13854271357 .................................................\n",
      "[CV] .................................. C=7.13854271357, total=  23.3s\n",
      "[CV] C=7.13854271357 .................................................\n",
      "[CV] .................................. C=7.13854271357, total=  24.5s\n",
      "[CV] C=7.18874371859 .................................................\n",
      "[CV] .................................. C=7.13854271357, total=  23.9s\n",
      "[CV] C=7.18874371859 .................................................\n",
      "[CV] .................................. C=7.13854271357, total=  23.0s\n",
      "[CV] C=7.18874371859 .................................................\n",
      "[CV] .................................. C=7.13854271357, total=  23.3s\n",
      "[CV] C=7.18874371859 .................................................\n",
      "[CV] .................................. C=7.18874371859, total=  23.9s\n",
      "[CV] C=7.18874371859 .................................................\n",
      "[CV] .................................. C=7.18874371859, total=  24.7s\n",
      "[CV] C=7.23894472362 .................................................\n",
      "[CV] .................................. C=7.18874371859, total=  24.6s\n",
      "[CV] C=7.23894472362 .................................................\n",
      "[CV] .................................. C=7.18874371859, total=  23.2s\n",
      "[CV] C=7.23894472362 .................................................\n",
      "[CV] .................................. C=7.18874371859, total=  23.5s\n",
      "[CV] C=7.23894472362 .................................................\n",
      "[CV] .................................. C=7.23894472362, total=  23.4s\n",
      "[CV] C=7.23894472362 .................................................\n",
      "[CV] .................................. C=7.23894472362, total=  27.0s\n",
      "[CV] C=7.28914572864 .................................................\n",
      "[CV] .................................. C=7.23894472362, total=  27.5s\n",
      "[CV] C=7.28914572864 .................................................\n",
      "[CV] .................................. C=7.23894472362, total=  28.4s\n",
      "[CV] C=7.28914572864 .................................................\n",
      "[CV] .................................. C=7.23894472362, total=  27.2s\n",
      "[CV] C=7.28914572864 .................................................\n",
      "[CV] .................................. C=7.28914572864, total=  26.2s\n",
      "[CV] C=7.28914572864 .................................................\n",
      "[CV] .................................. C=7.28914572864, total=  26.4s\n",
      "[CV] C=7.33934673367 .................................................\n",
      "[CV] .................................. C=7.28914572864, total=  26.6s\n",
      "[CV] C=7.33934673367 .................................................\n",
      "[CV] .................................. C=7.28914572864, total=  24.4s\n",
      "[CV] C=7.33934673367 .................................................\n",
      "[CV] .................................. C=7.28914572864, total=  27.0s\n",
      "[CV] C=7.33934673367 .................................................\n",
      "[CV] .................................. C=7.33934673367, total=  25.8s\n",
      "[CV] C=7.33934673367 .................................................\n",
      "[CV] .................................. C=7.33934673367, total=  28.2s\n",
      "[CV] C=7.38954773869 .................................................\n",
      "[CV] .................................. C=7.33934673367, total=  28.8s\n",
      "[CV] C=7.38954773869 .................................................\n",
      "[CV] .................................. C=7.33934673367, total=  27.3s\n",
      "[CV] C=7.38954773869 .................................................\n",
      "[CV] .................................. C=7.33934673367, total=  27.0s\n",
      "[CV] C=7.38954773869 .................................................\n",
      "[CV] .................................. C=7.38954773869, total=  22.3s\n",
      "[CV] C=7.38954773869 .................................................\n",
      "[CV] .................................. C=7.38954773869, total=  22.7s\n",
      "[CV] C=7.43974874372 .................................................\n",
      "[CV] .................................. C=7.38954773869, total=  24.5s\n",
      "[CV] C=7.43974874372 .................................................\n",
      "[CV] .................................. C=7.38954773869, total=  24.7s\n",
      "[CV] C=7.43974874372 .................................................\n",
      "[CV] .................................. C=7.38954773869, total=  25.4s\n",
      "[CV] C=7.43974874372 .................................................\n",
      "[CV] .................................. C=7.43974874372, total=  26.0s\n",
      "[CV] C=7.43974874372 .................................................\n",
      "[CV] .................................. C=7.43974874372, total=  25.7s\n",
      "[CV] C=7.48994974874 .................................................\n",
      "[CV] .................................. C=7.43974874372, total=  24.3s\n",
      "[CV] C=7.48994974874 .................................................\n",
      "[CV] .................................. C=7.43974874372, total=  26.8s\n",
      "[CV] C=7.48994974874 .................................................\n",
      "[CV] .................................. C=7.43974874372, total=  27.7s\n",
      "[CV] C=7.48994974874 .................................................\n",
      "[CV] .................................. C=7.48994974874, total=  26.5s\n",
      "[CV] .................................. C=7.48994974874, total=  27.4s\n",
      "[CV] C=7.48994974874 .................................................\n",
      "[CV] C=7.54015075377 .................................................\n",
      "[CV] .................................. C=7.48994974874, total=  26.7s\n",
      "[CV] C=7.54015075377 .................................................\n",
      "[CV] .................................. C=7.48994974874, total=  26.3s\n",
      "[CV] C=7.54015075377 .................................................\n",
      "[CV] .................................. C=7.54015075377, total=  24.4s\n",
      "[CV] C=7.54015075377 .................................................\n",
      "[CV] .................................. C=7.48994974874, total=  26.4s\n",
      "[CV] C=7.54015075377 .................................................\n",
      "[CV] .................................. C=7.54015075377, total=  24.8s\n",
      "[CV] C=7.59035175879 .................................................\n",
      "[CV] .................................. C=7.54015075377, total=  23.5s\n",
      "[CV] C=7.59035175879 .................................................\n",
      "[CV] .................................. C=7.54015075377, total=  23.5s\n",
      "[CV] C=7.59035175879 .................................................\n",
      "[CV] .................................. C=7.54015075377, total=  22.9s\n",
      "[CV] C=7.59035175879 .................................................\n",
      "[CV] .................................. C=7.59035175879, total=  26.3s\n",
      "[CV] C=7.59035175879 .................................................\n",
      "[CV] .................................. C=7.59035175879, total=  26.3s\n",
      "[CV] C=7.64055276382 .................................................\n",
      "[CV] .................................. C=7.59035175879, total=  26.2s\n",
      "[CV] C=7.64055276382 .................................................\n",
      "[CV] .................................. C=7.59035175879, total=  25.9s\n",
      "[CV] C=7.64055276382 .................................................\n",
      "[CV] .................................. C=7.59035175879, total=  23.4s\n",
      "[CV] C=7.64055276382 .................................................\n",
      "[CV] .................................. C=7.64055276382, total=  24.2s\n",
      "[CV] C=7.64055276382 .................................................\n",
      "[CV] .................................. C=7.64055276382, total=  23.9s\n",
      "[CV] C=7.69075376884 .................................................\n",
      "[CV] .................................. C=7.64055276382, total=  23.9s\n",
      "[CV] C=7.69075376884 .................................................\n",
      "[CV] .................................. C=7.64055276382, total=  21.7s\n",
      "[CV] C=7.69075376884 .................................................\n",
      "[CV] .................................. C=7.64055276382, total=  22.6s\n",
      "[CV] C=7.69075376884 .................................................\n",
      "[CV] .................................. C=7.69075376884, total=  21.6s\n",
      "[CV] C=7.69075376884 .................................................\n",
      "[CV] .................................. C=7.69075376884, total=  22.3s\n",
      "[CV] C=7.74095477387 .................................................\n",
      "[CV] .................................. C=7.69075376884, total=  21.5s\n",
      "[CV] C=7.74095477387 .................................................\n",
      "[CV] .................................. C=7.69075376884, total=  21.6s\n",
      "[CV] C=7.74095477387 .................................................\n",
      "[CV] .................................. C=7.69075376884, total=  21.9s\n",
      "[CV] C=7.74095477387 .................................................\n",
      "[CV] .................................. C=7.74095477387, total=  21.3s\n",
      "[CV] C=7.74095477387 .................................................\n",
      "[CV] .................................. C=7.74095477387, total=  24.5s\n",
      "[CV] C=7.79115577889 .................................................\n",
      "[CV] .................................. C=7.74095477387, total=  25.5s\n",
      "[CV] C=7.79115577889 .................................................\n",
      "[CV] .................................. C=7.74095477387, total=  24.9s\n",
      "[CV] C=7.79115577889 .................................................\n",
      "[CV] .................................. C=7.74095477387, total=  24.8s\n",
      "[CV] C=7.79115577889 .................................................\n",
      "[CV] .................................. C=7.79115577889, total=  23.9s\n",
      "[CV] C=7.79115577889 .................................................\n",
      "[CV] .................................. C=7.79115577889, total=  24.4s\n",
      "[CV] C=7.84135678392 .................................................\n",
      "[CV] .................................. C=7.79115577889, total=  24.5s\n",
      "[CV] C=7.84135678392 .................................................\n",
      "[CV] .................................. C=7.79115577889, total=  24.9s\n",
      "[CV] C=7.84135678392 .................................................\n",
      "[CV] .................................. C=7.79115577889, total=  26.3s\n",
      "[CV] C=7.84135678392 .................................................\n",
      "[CV] .................................. C=7.84135678392, total=  28.1s\n",
      "[CV] C=7.84135678392 .................................................\n",
      "[CV] .................................. C=7.84135678392, total=  30.0s\n",
      "[CV] C=7.89155778894 .................................................\n",
      "[CV] .................................. C=7.84135678392, total=  29.0s\n",
      "[CV] C=7.89155778894 .................................................\n",
      "[CV] .................................. C=7.84135678392, total=  29.9s\n",
      "[CV] C=7.89155778894 .................................................\n",
      "[CV] .................................. C=7.84135678392, total=  28.8s\n",
      "[CV] C=7.89155778894 .................................................\n",
      "[CV] .................................. C=7.89155778894, total=  27.6s\n",
      "[CV] C=7.89155778894 .................................................\n",
      "[CV] .................................. C=7.89155778894, total=  27.6s\n",
      "[CV] C=7.94175879397 .................................................\n",
      "[CV] .................................. C=7.89155778894, total=  27.6s\n",
      "[CV] C=7.94175879397 .................................................\n",
      "[CV] .................................. C=7.89155778894, total=  27.3s\n",
      "[CV] C=7.94175879397 .................................................\n",
      "[CV] .................................. C=7.89155778894, total=  27.9s\n",
      "[CV] C=7.94175879397 .................................................\n",
      "[CV] .................................. C=7.94175879397, total=  27.7s\n",
      "[CV] C=7.94175879397 .................................................\n",
      "[CV] .................................. C=7.94175879397, total=  27.4s\n",
      "[CV] C=7.99195979899 .................................................\n",
      "[CV] .................................. C=7.94175879397, total=  25.9s\n",
      "[CV] C=7.99195979899 .................................................\n",
      "[CV] .................................. C=7.94175879397, total=  26.1s\n",
      "[CV] C=7.99195979899 .................................................\n",
      "[CV] .................................. C=7.94175879397, total=  26.1s\n",
      "[CV] C=7.99195979899 .................................................\n",
      "[CV] .................................. C=7.99195979899, total=  26.5s\n",
      "[CV] C=7.99195979899 .................................................\n",
      "[CV] .................................. C=7.99195979899, total=  27.4s\n",
      "[CV] C=8.04216080402 .................................................\n",
      "[CV] .................................. C=7.99195979899, total=  28.6s\n",
      "[CV] C=8.04216080402 .................................................\n",
      "[CV] .................................. C=7.99195979899, total=  28.0s\n",
      "[CV] C=8.04216080402 .................................................\n",
      "[CV] .................................. C=7.99195979899, total=  30.7s\n",
      "[CV] C=8.04216080402 .................................................\n",
      "[CV] .................................. C=8.04216080402, total=  28.3s\n",
      "[CV] C=8.04216080402 .................................................\n",
      "[CV] .................................. C=8.04216080402, total=  27.0s\n",
      "[CV] C=8.09236180905 .................................................\n",
      "[CV] .................................. C=8.04216080402, total=  27.1s\n",
      "[CV] C=8.09236180905 .................................................\n",
      "[CV] .................................. C=8.04216080402, total=  26.5s\n",
      "[CV] C=8.09236180905 .................................................\n",
      "[CV] .................................. C=8.04216080402, total=  28.1s\n",
      "[CV] C=8.09236180905 .................................................\n",
      "[CV] .................................. C=8.09236180905, total=  29.4s\n",
      "[CV] C=8.09236180905 .................................................\n",
      "[CV] .................................. C=8.09236180905, total=  30.0s\n",
      "[CV] C=8.14256281407 .................................................\n",
      "[CV] .................................. C=8.09236180905, total=  32.5s\n",
      "[CV] C=8.14256281407 .................................................\n",
      "[CV] .................................. C=8.09236180905, total=  31.2s\n",
      "[CV] C=8.14256281407 .................................................\n",
      "[CV] .................................. C=8.09236180905, total=  28.9s\n",
      "[CV] C=8.14256281407 .................................................\n",
      "[CV] .................................. C=8.14256281407, total=  28.9s\n",
      "[CV] C=8.14256281407 .................................................\n",
      "[CV] .................................. C=8.14256281407, total=  24.1s\n",
      "[CV] C=8.1927638191 ..................................................\n",
      "[CV] .................................. C=8.14256281407, total=  22.7s\n",
      "[CV] C=8.1927638191 ..................................................\n",
      "[CV] .................................. C=8.14256281407, total=  23.3s\n",
      "[CV] C=8.1927638191 ..................................................\n",
      "[CV] .................................. C=8.14256281407, total=  23.7s\n",
      "[CV] C=8.1927638191 ..................................................\n",
      "[CV] ................................... C=8.1927638191, total=  26.7s\n",
      "[CV] C=8.1927638191 ..................................................\n",
      "[CV] ................................... C=8.1927638191, total=  28.1s\n",
      "[CV] C=8.24296482412 .................................................\n",
      "[CV] ................................... C=8.1927638191, total=  30.9s\n",
      "[CV] C=8.24296482412 .................................................\n",
      "[CV] ................................... C=8.1927638191, total=  30.9s\n",
      "[CV] C=8.24296482412 .................................................\n",
      "[CV] ................................... C=8.1927638191, total=  29.7s\n",
      "[CV] C=8.24296482412 .................................................\n",
      "[CV] .................................. C=8.24296482412, total=  29.8s\n",
      "[CV] C=8.24296482412 .................................................\n",
      "[CV] .................................. C=8.24296482412, total=  28.9s\n",
      "[CV] C=8.29316582915 .................................................\n",
      "[CV] .................................. C=8.24296482412, total=  29.9s\n",
      "[CV] C=8.29316582915 .................................................\n",
      "[CV] .................................. C=8.24296482412, total=  27.2s\n",
      "[CV] C=8.29316582915 .................................................\n",
      "[CV] .................................. C=8.24296482412, total=  27.7s\n",
      "[CV] C=8.29316582915 .................................................\n",
      "[CV] .................................. C=8.29316582915, total=  26.8s\n",
      "[CV] C=8.29316582915 .................................................\n",
      "[CV] .................................. C=8.29316582915, total=  27.0s\n",
      "[CV] C=8.34336683417 .................................................\n",
      "[CV] .................................. C=8.29316582915, total=  26.8s\n",
      "[CV] C=8.34336683417 .................................................\n",
      "[CV] .................................. C=8.29316582915, total=  27.0s\n",
      "[CV] C=8.34336683417 .................................................\n",
      "[CV] .................................. C=8.29316582915, total=  28.0s\n",
      "[CV] C=8.34336683417 .................................................\n",
      "[CV] .................................. C=8.34336683417, total=  27.1s\n",
      "[CV] C=8.34336683417 .................................................\n",
      "[CV] .................................. C=8.34336683417, total=  26.6s\n",
      "[CV] C=8.3935678392 ..................................................\n",
      "[CV] .................................. C=8.34336683417, total=  27.2s\n",
      "[CV] C=8.3935678392 ..................................................\n",
      "[CV] .................................. C=8.34336683417, total=  27.4s\n",
      "[CV] C=8.3935678392 ..................................................\n",
      "[CV] .................................. C=8.34336683417, total=  28.2s\n",
      "[CV] C=8.3935678392 ..................................................\n",
      "[CV] ................................... C=8.3935678392, total=  30.4s\n",
      "[CV] C=8.3935678392 ..................................................\n",
      "[CV] ................................... C=8.3935678392, total=  29.1s\n",
      "[CV] C=8.44376884422 .................................................\n",
      "[CV] ................................... C=8.3935678392, total=  28.2s\n",
      "[CV] C=8.44376884422 .................................................\n",
      "[CV] ................................... C=8.3935678392, total=  27.1s\n",
      "[CV] C=8.44376884422 .................................................\n",
      "[CV] ................................... C=8.3935678392, total=  28.2s\n",
      "[CV] C=8.44376884422 .................................................\n",
      "[CV] .................................. C=8.44376884422, total=  29.3s\n",
      "[CV] C=8.44376884422 .................................................\n",
      "[CV] .................................. C=8.44376884422, total=  29.8s\n",
      "[CV] C=8.49396984925 .................................................\n",
      "[CV] .................................. C=8.44376884422, total=  29.0s\n",
      "[CV] C=8.49396984925 .................................................\n",
      "[CV] .................................. C=8.44376884422, total=  27.2s\n",
      "[CV] C=8.49396984925 .................................................\n",
      "[CV] .................................. C=8.44376884422, total=  27.2s\n",
      "[CV] C=8.49396984925 .................................................\n",
      "[CV] .................................. C=8.49396984925, total=  26.1s\n",
      "[CV] C=8.49396984925 .................................................\n",
      "[CV] .................................. C=8.49396984925, total=  27.1s\n",
      "[CV] C=8.54417085427 .................................................\n",
      "[CV] .................................. C=8.49396984925, total=  26.9s\n",
      "[CV] C=8.54417085427 .................................................\n",
      "[CV] .................................. C=8.49396984925, total=  26.8s\n",
      "[CV] C=8.54417085427 .................................................\n",
      "[CV] .................................. C=8.49396984925, total=  27.0s\n",
      "[CV] C=8.54417085427 .................................................\n",
      "[CV] .................................. C=8.54417085427, total=  27.4s\n",
      "[CV] C=8.54417085427 .................................................\n",
      "[CV] .................................. C=8.54417085427, total=  28.5s\n",
      "[CV] C=8.5943718593 ..................................................\n",
      "[CV] .................................. C=8.54417085427, total=  27.8s\n",
      "[CV] C=8.5943718593 ..................................................\n",
      "[CV] .................................. C=8.54417085427, total=  26.8s\n",
      "[CV] C=8.5943718593 ..................................................\n",
      "[CV] .................................. C=8.54417085427, total=  26.9s\n",
      "[CV] C=8.5943718593 ..................................................\n",
      "[CV] ................................... C=8.5943718593, total=  26.6s\n",
      "[CV] C=8.5943718593 ..................................................\n",
      "[CV] ................................... C=8.5943718593, total=  26.5s\n",
      "[CV] C=8.64457286432 .................................................\n",
      "[CV] ................................... C=8.5943718593, total=  24.9s\n",
      "[CV] C=8.64457286432 .................................................\n",
      "[CV] ................................... C=8.5943718593, total=  26.0s\n",
      "[CV] C=8.64457286432 .................................................\n",
      "[CV] ................................... C=8.5943718593, total=  25.8s\n",
      "[CV] C=8.64457286432 .................................................\n",
      "[CV] .................................. C=8.64457286432, total=  25.3s\n",
      "[CV] C=8.64457286432 .................................................\n",
      "[CV] .................................. C=8.64457286432, total=  25.3s\n",
      "[CV] C=8.69477386935 .................................................\n",
      "[CV] .................................. C=8.64457286432, total=  25.2s\n",
      "[CV] C=8.69477386935 .................................................\n",
      "[CV] .................................. C=8.64457286432, total=  27.3s\n",
      "[CV] C=8.69477386935 .................................................\n",
      "[CV] .................................. C=8.64457286432, total=  28.4s\n",
      "[CV] C=8.69477386935 .................................................\n",
      "[CV] .................................. C=8.69477386935, total=  30.2s\n",
      "[CV] C=8.69477386935 .................................................\n",
      "[CV] .................................. C=8.69477386935, total=  30.6s\n",
      "[CV] C=8.74497487437 .................................................\n",
      "[CV] .................................. C=8.69477386935, total=  30.6s\n",
      "[CV] C=8.74497487437 .................................................\n",
      "[CV] .................................. C=8.69477386935, total=  29.4s\n",
      "[CV] C=8.74497487437 .................................................\n",
      "[CV] .................................. C=8.69477386935, total=  27.5s\n",
      "[CV] C=8.74497487437 .................................................\n",
      "[CV] .................................. C=8.74497487437, total=  27.4s\n",
      "[CV] C=8.74497487437 .................................................\n",
      "[CV] .................................. C=8.74497487437, total=  29.6s\n",
      "[CV] C=8.7951758794 ..................................................\n",
      "[CV] .................................. C=8.74497487437, total=  30.3s\n",
      "[CV] C=8.7951758794 ..................................................\n",
      "[CV] .................................. C=8.74497487437, total=  29.5s\n",
      "[CV] C=8.7951758794 ..................................................\n",
      "[CV] .................................. C=8.74497487437, total=  29.5s\n",
      "[CV] C=8.7951758794 ..................................................\n",
      "[CV] ................................... C=8.7951758794, total=  28.2s\n",
      "[CV] C=8.7951758794 ..................................................\n",
      "[CV] ................................... C=8.7951758794, total=  26.6s\n",
      "[CV] C=8.84537688442 .................................................\n",
      "[CV] ................................... C=8.7951758794, total=  27.8s\n",
      "[CV] C=8.84537688442 .................................................\n",
      "[CV] ................................... C=8.7951758794, total=  27.6s\n",
      "[CV] C=8.84537688442 .................................................\n",
      "[CV] ................................... C=8.7951758794, total=  26.2s\n",
      "[CV] C=8.84537688442 .................................................\n",
      "[CV] .................................. C=8.84537688442, total=  26.6s\n",
      "[CV] C=8.84537688442 .................................................\n",
      "[CV] .................................. C=8.84537688442, total=  26.8s\n",
      "[CV] C=8.89557788945 .................................................\n",
      "[CV] .................................. C=8.84537688442, total=  26.5s\n",
      "[CV] C=8.89557788945 .................................................\n",
      "[CV] .................................. C=8.84537688442, total=  26.8s\n",
      "[CV] C=8.89557788945 .................................................\n",
      "[CV] .................................. C=8.84537688442, total=  26.2s\n",
      "[CV] C=8.89557788945 .................................................\n",
      "[CV] .................................. C=8.89557788945, total=  28.4s\n",
      "[CV] C=8.89557788945 .................................................\n",
      "[CV] .................................. C=8.89557788945, total=  27.2s\n",
      "[CV] C=8.94577889447 .................................................\n",
      "[CV] .................................. C=8.89557788945, total=  25.5s\n",
      "[CV] C=8.94577889447 .................................................\n",
      "[CV] .................................. C=8.89557788945, total=  24.5s\n",
      "[CV] C=8.94577889447 .................................................\n",
      "[CV] .................................. C=8.89557788945, total=  23.3s\n",
      "[CV] .................................. C=8.94577889447, total=  22.7s\n",
      "[CV] C=8.94577889447 .................................................\n",
      "[CV] C=8.94577889447 .................................................\n",
      "[CV] .................................. C=8.94577889447, total=  22.8s\n",
      "[CV] C=8.9959798995 ..................................................\n",
      "[CV] .................................. C=8.94577889447, total=  22.9s\n",
      "[CV] C=8.9959798995 ..................................................\n",
      "[CV] .................................. C=8.94577889447, total=  22.6s\n",
      "[CV] C=8.9959798995 ..................................................\n",
      "[CV] .................................. C=8.94577889447, total=  22.6s\n",
      "[CV] C=8.9959798995 ..................................................\n",
      "[CV] ................................... C=8.9959798995, total=  22.3s\n",
      "[CV] C=8.9959798995 ..................................................\n",
      "[CV] ................................... C=8.9959798995, total=  22.7s\n",
      "[CV] C=9.04618090452 .................................................\n",
      "[CV] ................................... C=8.9959798995, total=  22.5s\n",
      "[CV] C=9.04618090452 .................................................\n",
      "[CV] ................................... C=8.9959798995, total=  22.8s\n",
      "[CV] C=9.04618090452 .................................................\n",
      "[CV] ................................... C=8.9959798995, total=  24.4s\n",
      "[CV] C=9.04618090452 .................................................\n",
      "[CV] .................................. C=9.04618090452, total=  25.0s\n",
      "[CV] C=9.04618090452 .................................................\n",
      "[CV] .................................. C=9.04618090452, total=  25.6s\n",
      "[CV] C=9.09638190955 .................................................\n",
      "[CV] .................................. C=9.04618090452, total=  25.8s\n",
      "[CV] C=9.09638190955 .................................................\n",
      "[CV] .................................. C=9.04618090452, total=  23.2s\n",
      "[CV] C=9.09638190955 .................................................\n",
      "[CV] .................................. C=9.04618090452, total=  22.9s\n",
      "[CV] C=9.09638190955 .................................................\n",
      "[CV] .................................. C=9.09638190955, total=  23.5s\n",
      "[CV] C=9.09638190955 .................................................\n",
      "[CV] .................................. C=9.09638190955, total=  23.9s\n",
      "[CV] C=9.14658291457 .................................................\n",
      "[CV] .................................. C=9.09638190955, total=  26.7s\n",
      "[CV] C=9.14658291457 .................................................\n",
      "[CV] .................................. C=9.09638190955, total=  25.8s\n",
      "[CV] C=9.14658291457 .................................................\n",
      "[CV] .................................. C=9.09638190955, total=  27.4s\n",
      "[CV] C=9.14658291457 .................................................\n",
      "[CV] .................................. C=9.14658291457, total=  27.5s\n",
      "[CV] C=9.14658291457 .................................................\n",
      "[CV] .................................. C=9.14658291457, total=  27.8s\n",
      "[CV] C=9.1967839196 ..................................................\n",
      "[CV] .................................. C=9.14658291457, total=  27.2s\n",
      "[CV] C=9.1967839196 ..................................................\n",
      "[CV] .................................. C=9.14658291457, total=  29.0s\n",
      "[CV] C=9.1967839196 ..................................................\n",
      "[CV] .................................. C=9.14658291457, total=  28.3s\n",
      "[CV] C=9.1967839196 ..................................................\n",
      "[CV] ................................... C=9.1967839196, total=  27.9s\n",
      "[CV] C=9.1967839196 ..................................................\n",
      "[CV] ................................... C=9.1967839196, total=  28.1s\n",
      "[CV] C=9.24698492462 .................................................\n",
      "[CV] ................................... C=9.1967839196, total=  26.2s\n",
      "[CV] C=9.24698492462 .................................................\n",
      "[CV] ................................... C=9.1967839196, total=  26.4s\n",
      "[CV] C=9.24698492462 .................................................\n",
      "[CV] ................................... C=9.1967839196, total=  23.5s\n",
      "[CV] C=9.24698492462 .................................................\n",
      "[CV] .................................. C=9.24698492462, total=  23.6s\n",
      "[CV] C=9.24698492462 .................................................\n",
      "[CV] .................................. C=9.24698492462, total=  23.3s\n",
      "[CV] C=9.29718592965 .................................................\n",
      "[CV] .................................. C=9.24698492462, total=  23.1s\n",
      "[CV] C=9.29718592965 .................................................\n",
      "[CV] .................................. C=9.24698492462, total=  23.4s\n",
      "[CV] C=9.29718592965 .................................................\n",
      "[CV] .................................. C=9.24698492462, total=  24.1s\n",
      "[CV] C=9.29718592965 .................................................\n",
      "[CV] .................................. C=9.29718592965, total=  23.9s\n",
      "[CV] C=9.29718592965 .................................................\n",
      "[CV] .................................. C=9.29718592965, total=  24.1s\n",
      "[CV] C=9.34738693467 .................................................\n",
      "[CV] .................................. C=9.29718592965, total=  23.9s\n",
      "[CV] C=9.34738693467 .................................................\n",
      "[CV] .................................. C=9.29718592965, total=  23.8s\n",
      "[CV] C=9.34738693467 .................................................\n",
      "[CV] .................................. C=9.29718592965, total=  23.7s\n",
      "[CV] C=9.34738693467 .................................................\n",
      "[CV] .................................. C=9.34738693467, total=  23.5s\n",
      "[CV] C=9.34738693467 .................................................\n",
      "[CV] .................................. C=9.34738693467, total=  25.9s\n",
      "[CV] C=9.3975879397 ..................................................\n",
      "[CV] .................................. C=9.34738693467, total=  26.6s\n",
      "[CV] C=9.3975879397 ..................................................\n",
      "[CV] .................................. C=9.34738693467, total=  27.1s\n",
      "[CV] C=9.3975879397 ..................................................\n",
      "[CV] .................................. C=9.34738693467, total=  27.1s\n",
      "[CV] C=9.3975879397 ..................................................\n",
      "[CV] ................................... C=9.3975879397, total=  24.9s\n",
      "[CV] C=9.3975879397 ..................................................\n",
      "[CV] ................................... C=9.3975879397, total=  25.5s\n",
      "[CV] C=9.44778894472 .................................................\n",
      "[CV] ................................... C=9.3975879397, total=  25.1s\n",
      "[CV] C=9.44778894472 .................................................\n",
      "[CV] ................................... C=9.3975879397, total=  25.7s\n",
      "[CV] C=9.44778894472 .................................................\n",
      "[CV] ................................... C=9.3975879397, total=  27.2s\n",
      "[CV] C=9.44778894472 .................................................\n",
      "[CV] .................................. C=9.44778894472, total=  26.6s\n",
      "[CV] C=9.44778894472 .................................................\n",
      "[CV] .................................. C=9.44778894472, total=  25.6s\n",
      "[CV] C=9.49798994975 .................................................\n",
      "[CV] .................................. C=9.44778894472, total=  26.0s\n",
      "[CV] C=9.49798994975 .................................................\n",
      "[CV] .................................. C=9.44778894472, total=  23.0s\n",
      "[CV] C=9.49798994975 .................................................\n",
      "[CV] .................................. C=9.44778894472, total=  23.7s\n",
      "[CV] C=9.49798994975 .................................................\n",
      "[CV] .................................. C=9.49798994975, total=  23.5s\n",
      "[CV] C=9.49798994975 .................................................\n",
      "[CV] .................................. C=9.49798994975, total=  23.7s\n",
      "[CV] C=9.54819095477 .................................................\n",
      "[CV] .................................. C=9.49798994975, total=  24.3s\n",
      "[CV] C=9.54819095477 .................................................\n",
      "[CV] .................................. C=9.49798994975, total=  23.3s\n",
      "[CV] C=9.54819095477 .................................................\n",
      "[CV] .................................. C=9.49798994975, total=  24.5s\n",
      "[CV] C=9.54819095477 .................................................\n",
      "[CV] .................................. C=9.54819095477, total=  24.4s\n",
      "[CV] C=9.54819095477 .................................................\n",
      "[CV] .................................. C=9.54819095477, total=  23.2s\n",
      "[CV] C=9.5983919598 ..................................................\n",
      "[CV] .................................. C=9.54819095477, total=  23.9s\n",
      "[CV] C=9.5983919598 ..................................................\n",
      "[CV] .................................. C=9.54819095477, total=  23.5s\n",
      "[CV] C=9.5983919598 ..................................................\n",
      "[CV] .................................. C=9.54819095477, total=  23.5s\n",
      "[CV] C=9.5983919598 ..................................................\n",
      "[CV] ................................... C=9.5983919598, total=  28.0s\n",
      "[CV] C=9.5983919598 ..................................................\n",
      "[CV] ................................... C=9.5983919598, total=  28.6s\n",
      "[CV] C=9.64859296482 .................................................\n",
      "[CV] ................................... C=9.5983919598, total=  28.9s\n",
      "[CV] C=9.64859296482 .................................................\n",
      "[CV] ................................... C=9.5983919598, total=  29.3s\n",
      "[CV] C=9.64859296482 .................................................\n",
      "[CV] ................................... C=9.5983919598, total=  25.3s\n",
      "[CV] C=9.64859296482 .................................................\n",
      "[CV] .................................. C=9.64859296482, total=  24.5s\n",
      "[CV] C=9.64859296482 .................................................\n",
      "[CV] .................................. C=9.64859296482, total=  24.9s\n",
      "[CV] C=9.69879396985 .................................................\n",
      "[CV] .................................. C=9.64859296482, total=  25.2s\n",
      "[CV] C=9.69879396985 .................................................\n",
      "[CV] .................................. C=9.64859296482, total=  25.2s\n",
      "[CV] C=9.69879396985 .................................................\n",
      "[CV] .................................. C=9.64859296482, total=  24.6s\n",
      "[CV] C=9.69879396985 .................................................\n",
      "[CV] .................................. C=9.69879396985, total=  25.4s\n",
      "[CV] C=9.69879396985 .................................................\n",
      "[CV] .................................. C=9.69879396985, total=  25.5s\n",
      "[CV] C=9.74899497487 .................................................\n",
      "[CV] .................................. C=9.69879396985, total=  24.2s\n",
      "[CV] C=9.74899497487 .................................................\n",
      "[CV] .................................. C=9.69879396985, total=  23.9s\n",
      "[CV] C=9.74899497487 .................................................\n",
      "[CV] .................................. C=9.74899497487, total=  23.4s\n",
      "[CV] .................................. C=9.69879396985, total=  23.6s\n",
      "[CV] C=9.74899497487 .................................................\n",
      "[CV] C=9.74899497487 .................................................\n",
      "[CV] .................................. C=9.74899497487, total=  24.5s\n",
      "[CV] C=9.7991959799 ..................................................\n",
      "[CV] .................................. C=9.74899497487, total=  24.1s\n",
      "[CV] C=9.7991959799 ..................................................\n",
      "[CV] .................................. C=9.74899497487, total=  25.2s\n",
      "[CV] C=9.7991959799 ..................................................\n",
      "[CV] .................................. C=9.74899497487, total=  25.2s\n",
      "[CV] C=9.7991959799 ..................................................\n",
      "[CV] ................................... C=9.7991959799, total=  24.6s\n",
      "[CV] C=9.7991959799 ..................................................\n",
      "[CV] ................................... C=9.7991959799, total=  25.3s\n",
      "[CV] C=9.84939698492 .................................................\n",
      "[CV] ................................... C=9.7991959799, total=  25.1s\n",
      "[CV] C=9.84939698492 .................................................\n",
      "[CV] ................................... C=9.7991959799, total=  25.2s\n",
      "[CV] C=9.84939698492 .................................................\n",
      "[CV] ................................... C=9.7991959799, total=  25.5s\n",
      "[CV] C=9.84939698492 .................................................\n",
      "[CV] .................................. C=9.84939698492, total=  25.4s\n",
      "[CV] C=9.84939698492 .................................................\n",
      "[CV] .................................. C=9.84939698492, total=  24.0s\n",
      "[CV] C=9.89959798995 .................................................\n",
      "[CV] .................................. C=9.84939698492, total=  24.6s\n",
      "[CV] C=9.89959798995 .................................................\n",
      "[CV] .................................. C=9.84939698492, total=  26.7s\n",
      "[CV] C=9.89959798995 .................................................\n",
      "[CV] .................................. C=9.84939698492, total=  27.8s\n",
      "[CV] C=9.89959798995 .................................................\n",
      "[CV] .................................. C=9.89959798995, total=  28.5s\n",
      "[CV] C=9.89959798995 .................................................\n",
      "[CV] .................................. C=9.89959798995, total=  28.7s\n",
      "[CV] C=9.94979899497 .................................................\n",
      "[CV] .................................. C=9.89959798995, total=  25.6s\n",
      "[CV] C=9.94979899497 .................................................\n",
      "[CV] .................................. C=9.89959798995, total=  23.3s\n",
      "[CV] C=9.94979899497 .................................................\n",
      "[CV] .................................. C=9.89959798995, total=  23.5s\n",
      "[CV] C=9.94979899497 .................................................\n",
      "[CV] .................................. C=9.94979899497, total=  23.9s\n",
      "[CV] C=9.94979899497 .................................................\n",
      "[CV] .................................. C=9.94979899497, total=  23.5s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .................................. C=9.94979899497, total=  24.5s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .................................. C=9.94979899497, total=  24.3s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .................................. C=9.94979899497, total=  24.4s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  24.3s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  24.4s\n",
      "[CV] ........................................... C=10.0, total=  22.5s\n",
      "[CV] ........................................... C=10.0, total=  22.4s\n",
      "[CV] ........................................... C=10.0, total=  17.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed: 82.3min finished\n"
     ]
    }
   ],
   "source": [
    "plot_cv = []\n",
    "param_grid = {'C': np.linspace(0.01, 10, num=200)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l1'),\n",
    "                              param_grid, scoring=score, cv=5, n_jobs=4, verbose=2)\n",
    "better_model.fit(x_train, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_cv_plot'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Fold CV Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = (-1) * better_model.cv_results_['mean_test_score']\n",
    "index = np.linspace(0.01, 10, num=200)\n",
    "table = pd.DataFrame()\n",
    "table['error'] = scores\n",
    "table['index'] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table.to_csv('./config/cv_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21888).\n"
     ]
    }
   ],
   "source": [
    "test = LogisticRegression(C=0.089, penalty='l2')\n",
    "test.fit(x_train, y_train)\n",
    "predict(test, all_mat, x_train.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The code is copied form the sklearn documentation\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\"\"\"\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Rating')\n",
    "    plt.xlabel('Predicted Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n",
      "2446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "cv = KFold(24461, n_folds=10,shuffle=False,random_state=None)\n",
    "\n",
    "ms = []\n",
    "\n",
    "# Make confusion matrix for each fold\n",
    "for train_in, test_in in cv:\n",
    "    x_train_, x_test_ = x_train[train_in,], x_train[test_in,]\n",
    "    y_train_, y_test_ = np.array(y_train)[train_in], np.array(y_train)[test_in]\n",
    "    \n",
    "    test = LogisticRegression(C=2.3877551020408161)\n",
    "    test.fit(x_train_, y_train_)\n",
    "    y_pred=clf.predict(x_test_)\n",
    "    \n",
    "    print(len(y_pred))\n",
    "    \n",
    "    cnfusion_matrix_ = confusion_matrix(y_test_, y_pred)\n",
    "    ms.append(cnfusion_matrix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[204   6   2   1   0]\n",
      " [  9 232  14   8   2]\n",
      " [  4  11 299  41  15]\n",
      " [  1   2  19 632 106]\n",
      " [  0   0   5  71 751]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAGjCAYAAABkC7+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm8VfP+x/HXp04izZrnNA8qTTJlCCEqIVxSiq7hZygu\nrtm9uIZrnnO5hkwhSiVDonCTVEKhUJrrNGkQDZ/fH2ud2h1nqnP2Xqvd+3ke63H2+q7ps/Zee3/W\nd63vWsvcHREREUmeYlEHICIiku6UbEVERJJMyVZERCTJlGxFRESSTMlWREQkyZRsRUREkkzJdg9k\ngf+a2Sozm1yI+RxuZt8XZWxRMbM6ZrbOzIoX8XyL5L3eieU1MbPpZrbWzC7LZ9x+ZvZJHsM/MrPz\niz7K+DGzZ83stvB1ntt14ri7uKx1Zrb/rk6fz7z/ZWZXJGPeOxFDSTP7zswqRxlH3KRNsg1/GFaZ\nWcmoYykqZtbVzCaEP5zLzexjM+teBLM+DDgWqOXuHXd1Ju4+0d2bFEE8SWVmc83smLzGcfdf3L20\nu28p4sXn+V6bWXUzG2lmi8zMzaxetuElzewZM/vVzJaY2eB8lnc1MN7dy7j7Q0W1Ejkxs8Zm9pqZ\nZZrZGjObYWaDi3qHJdWKcrvOaYcl3M5+Kor5Z1tWZeBc4Mmwv5OZvW9mK8Pfj9fMrHoO0+1lZrPM\nbEEu8z033DbPz1beNvx9WmdmS83s8nD9fgeeAa4t6nXcnaVFsg1/oA4HHCiKZJTTMjKSMd88lnca\n8BrwPFALqArcBJxcBLOvC8x19/VFMK/dXpI/2/ze663AWODUXIbfAjQK53MUcLWZHZ/P8r7dtVAL\nzswaAJ8D84ED3L0ccDrQHiiTw/gp/f7sofoBY9z9t7C/AjAEqEewXawF/pvDdH8Dluc0QzOrAFxH\ntm3KzCoRbLdPAvsBDYH3EkZ5CeibTpWfQnP33b4jSEKfAvcBoxLKDwKWAMUTyk4BZoSvixHsff0I\nrACGARXDYfUIkvcA4BdgQlj+WjjPNcAEoEXCvPcD3gZ+Bb4AbgM+SRjeFHgfWAl8D/TOZX0sXObf\n8ljnYsANwDxgGUFSLpct9r7hfDKB68NhA4CNwBZgHXArwZf0k2zzd6Bh+PpEYCbBl3UhcFVYfiSw\nIGGaZsBHwGqCL2f3hGHPAo8Co8P5fA40yGXdsuI/j+DHfBVwIdABmBHO/5GE8RsAH4afYSbwIlA+\nHPYCQUL7LVzfq3P6bBPKMoCKwALg5HAepYE5wLm5xFsDGBl+rnOAC3J7r/P4PDPC5dfLVr4IOC6h\n/5/AK7nM48NwWRvD5TUGyoXbxvJwW7kBKBaOv8PnTlAD/45g234E+Bg4P5dlDQVG57E+f3qPw/Lu\n4baxOtxWmiVMc024fa0l+H50Ccs7AlMIvldLgftyWeYs4KRs7+lyoG0BvrvPArflsl0fCEwN43oV\neCVh3ArAqHA5q8LXtcJht2f7PB7J4buV7+cD/Duc98/ACXm85x8C5+QxvC2wNltZ/fB9OyFxnROG\nPwFcHH5W5yeU3wG8kM/v8mzgiLzG2ZO6yAMokpUIfuAuBtoBm4CqCcN+BI5N6H8NuDZ8fTkwiaDm\nWJJgL+3lcFjWj8XzwL7APmF5f4I995LAA8D0hHm/EnalgOYEieKTcNi+Yf954Y/AgQSJoXkO69M0\nXHb9PNa5f7je+xMkg+FZG39C7E8B+wCtgd8Jf9j484/sDv1hWeIPwmLg8PB1Bbb/eB2Z9QUFSoTx\nXAfsBRxN8OPUJBz+LEEy7Biu/4vknjSy4n8C2Bs4juAH6y2gClCTYAfjiHD8hgSJoiRQmeCH9IGE\n+c0Fjslh/ts+24SyjHCc4wh+mKuE7+PreXwWE4DHwljbEPxwHp3be5vLPP6UbMP32tlxez4N+DqP\n+XzEjj+KzwMjCLbZesAPwIDssQGVws/rtPCzHARsJvdkuwQ4L484cnqPGwPrw8+qBMGOz5xwe2lC\n8P2okTB9g/D1/4A+4evSQKdclnkT8GJCfzdgVrbvTG7f3WfJIdmGsc0L348S4fuzKWHc/QiOSpQK\n5/0a8FZun0cO3638Pp9NwAVAceAigp0vy2X9lwMd8vhMrgAmZSsbRVAB2bbOCcOydnKK5bBdfQg8\nCHxG8F18G6iTbfqRwGX5bft7Shd5AIVegeCc2CagUtj/HTAoYfhtwDPh6zLhl71u2D+LcO857K8e\nziuD7T8W++ex7PLhOOXCL8MmwuSSsOysH7MzgInZpn8SuDmH+R4aznfvPJY9Drg4ob9JDrHXShg+\nGTgzfN2PnUu2vwB/BcpmG2fbF5TgMP4Swr3ysOxl4Jbw9bPAfxKGnQh8l8u6ZcVfM6FsBXBGQv8b\nwBW5TN8TmJbQP5eck+3+OZRlJJQ9DHxNUNvaL5dl1SaovZRJKPsX8Gxu720u88kp2dbOvh0QJKq5\necznI8IfxXCb/IOEHbrwc/woe2wE5/omJYxnBLX73JLtJuD4POLI6T2+ERiW0F8sfG+PJNhhWgYc\nA5TINq8JBEdgKuXzHjYk2GEoFfa/CNyU33c3YfvMKdl2JluCI0gwt+Uy3zbAqpw+j+zfrQJ+PnMS\nhpUKp62Wx2fSNJdhrQiOvByeUHYK8E72dU7YdqYQ7thkXw+CnYLVBEeb9gYeAj7Ntsxc3/89sUuH\nc7Z9gffcPTPsfyksI6G/V3juoBcw1d3nhcPqAm+a2WozW02QfLcQnB/NMj/rhZkVN7M7zexHM/uV\n4EccglpBZYIfzPk5TRsu66CsZYXLOxuolsM6rQj//6kxQ4IaBHvcWeaFy0+MfUnC6w0EtYJdcSpB\ncpwXNtI6OJd45rv71mwx1SxEPEsTXv+WQ39pADOramavmNnC8HMZSvCZ5Gd+PsOHAC0JEueKXMap\nAax097UJZdnXe1etC/+XTSgrS5BQMLN3wsYp68zs7Bymr0RQG8u+neQUWw0S3g8Pfi3zen9WkPf2\nmSVxHjtss+G2Mp9gp2oOQc3rFmBZ+HnWCEcdQFAr/s7MvjCzk3JaUDiPWcDJZlaK4JD1S5Dvdzcv\nNYCF4fuRZds6mFkpM3vSzOaF850AlC9gI7GCfD7bvjPuviF8mdv3ZhU5ny9vCLwDXO7uE8OyfYG7\ngdxarF9McLptUi7DfwPedPcv3H0jwc7QIWZWLmGcMgQJWdjNG0iZ2T5Ab+CIsKXmEoLDPa3NrDWA\nu88k2IBPAP5C+OULzSc4B1I+odvb3RcmjJP4JfsL0INg77scwd47BLWA5QSH3WoljF8727I+zras\n0u5+UQ6r9n04fm6NZiDY266b0F8nXP7SnEfP03qCvWYAzGyHHYDwC9WD4JDqWwTntnOKp7aZJW5T\ndQhqLsl2B8HndIC7lwXOIfhMsniOU+VeTvhjOYTgMN/F4Q9WThYBFc0s8UeuSNbb3VcRHMJvnVDc\nmrCxirufEG5Dpd39xRxmkUlQ28m+neQU22IStlczM3bcfrP7gLy3z22rkfB6h202YRkLAdz9JXc/\nLBzHgbvC8tnufhbB9ncX8HqYLHLyMnAWwfd0ZpiAIe/vbl4WAzXDWLPUSXh9JcFRpYPCba9ztvnm\nuo2xc59PQcwg2CnZxszqEnxW/3T3FxIGNSJ4DyaGv5vDgerh72g9oAtwSsLv6iHAvWb2SMKyEtct\np/VsBny1i+uSdnbrZEtwuHALwfnRNmHXDJhIcFgsy0sE52c7E5xTyfIEcHu4QWJmlc2sRx7LK0Nw\n7nMFQXK6I2uAB5eMDAduCfd2m2aLYRTQ2Mz6mFmJsOtgZs2yLyTcix4M3Ghm55lZWTMrZmaHmdmQ\ncLSXgUFmVt/MSoexvOrum/OIPzdfAS3MrI2Z7U1QuwC2XRZwtpmVc/dNBI1UtuYwj88JaqtXh+t2\nJEHL6Vd2IZ6dVYagFrjGzGoStK5MtJTg3PbOuI7gB6Q/cA/wfE61FXefT3BY8V9mtreZtSKoiQ0t\n6ILC9zyr1WbJsD/L88ANZlYh3KYuIDjkma9wmxxGsI2XCbfzwbnENppgG+gVthy+jJyPumS5maAm\nc0/WzpmZNTSzoWZWPpdphgHdzKyLmZUgSFS/A59ZcH3w0eERqI0ENaet4XzPMbPKYU04q6aU0zYI\nwfZ2HMH5zcQd61y/u/n4H8FO7GXhdt2L4Fxm4nx/A1abWcXwfUmU67a3k59PQYwBjsjqCb8LHxI0\nzHoi27jfEOzoZP1unh/G2oZgR78fwW9p1vApBLXX68Pp/0uQjNuEn+WNBKck1iQsuyJBmxiB3fuc\nLUHT83tzKO9NcPglq7FLHYIv5+hs4xUj2Li/Jzg09yNwRzisHn8+h1eaoDHDWoLa8rnseG6zMsGP\nVlZr5LuAcQnTNwmHLyf40n8ItMlj/Y4n2HFYF07zEdAtIfabCL4Yywm+oBXyiP0jtp/L68efz9Fe\nT7CnPZ+gZph1Xmmv8H1elbBeh4XTHMmO53laELRgXUPQevmUhGHPknCeK/u02WLJKf4FwJEJ/UOB\nGxKW+2X4Pk0n+BFPjKsHwXnn1cBVucx/WxlBQ7tVCZ9rcYLW7tfnEm8tgp2plQTb0IUJw/70Xucw\nvWfvEoaVJLhmMasl7uB85rXtcw77K4Tv1fLws72J3FsjH09wLi7f1sgJ2/NrBNvyGoKdtivC9+tP\n73E4zSnhtrEmnH+LsLwVQbuCteH7OIrtjaWGEpzPXUdQq++Zz3swjiBBVksoy++7+yy5t0ZuD0xj\ne2vkVxPGrRG+5+vC9+6viesNHByWrwIeSvi8G+7s55N92hzWuxLB9ySrMefN4fjrErtcpt1hnfPb\nrsKyiwhq4asIGkjVThj2N3JpNb6ndha+MZIEZnYXwRe+b74ji4gUkpndASxz9wcijKEkwY5XZ3df\nFlUccaNkW4TCw3x7EbRg7UBwWOd8d38r0sBERCRSuqtL0SpDcC61BsEhv3sJDl2JiMgeTDVbERGR\nJNvdWyOLiIjEnpKtiIhIku0x52zLVdjPq9XM6xr9Pcu+JfeYj75A8ruzgYhsN2/eXDIzM1PytSle\ntq775t/yHzEP/tvyd909r6dlJd0e84tbrWZtnnxjXNRhxEbH+hWjDiFWihVTuhUpqEMPap+yZfnm\njZRsemah5rFx2sMFuX1rUukwsoiISJLtMTVbERHZDRlgu/+RJyVbERGJN9v9D8Iq2YqISLylQc12\n999dEBERiTnVbEVEJMZMh5FFRESSLg0OIyvZiohIfBlpUbPd/ddAREQk5lSzFRGRGDMdRhYREUm6\nNDiMrGQrIiLxlgY1291/d0FERCTmVLMVEZEY03W2IiIiyaUHEYiIiKRAGtRsd/81EBERiTklWxER\nibHwnG1huvyWYNbEzKYndL+a2RVmVtHM3jez2eH/CuH4ZmYPmdkcM5thZm3zW4aSrYiIxFsxK1yX\nD3f/3t3buHsboB2wAXgTuBYY5+6NgHFhP8AJQKOwGwg8nu8q7NKKi4iIpELWvZGTWLPNpgvwo7vP\nA3oAz4XlzwE9w9c9gOc9MAkob2bV85qpkq2IiMh2ZwIvh6+ruvvi8PUSoGr4uiYwP2GaBWFZrpRs\nRUQk3swK10ElM5uS0A3MeTG2F9AdeC37MHd3wHd1FXTpj4iIxFiR3NQi093bF2C8E4Cp7r407F9q\nZtXdfXF4mHhZWL4QqJ0wXa2wLFeq2YqISLwVvmZbUGex/RAywEigb/i6LzAiofzcsFVyJ2BNwuHm\nHCnZFqFlixcy6Nwe9Ot2CP1OOpTXn38SgF9Xr+Kq/qdyTtcOXNX/VNauWb3DdN99PZUuLary8diR\nUYQdidWrV3P2madz4AHNaNuqOZ9P+l/UIUVm/vz5dD3mKA5s1Zy2rVvwyEMPRh1S5P56fn/q1KhC\nuzYtow4lFt57dyytWjShRdOG3HP3nVGHk5bMbF/gWGB4QvGdwLFmNhs4JuwHGAP8BMwBngIuzm/+\nSrZFqHjx4lx0zT94dvRnPPbKWEa8+DRz53zPS089SNtOnRn67he07dSZl57a/mO6ZcsWhvz7H3Q4\n9KgII0+9v115Bcce15VpX89i0pTpNGnaLOqQIpORkcGdd9/LtBkz+fiTSTz5xKPMmjkz6rAi1adv\nP0aMGht1GLGwZcsWrrjsEka8/Q7TZszktVde3vO2jxS0Rnb39e6+n7uvSShb4e5d3L2Rux/j7ivD\ncnf3S9y9gbsf4O5T8pu/km0R2q9KNRq3aA1AqdJlqNOgMZlLF/PZuHfo2vMMALr2PINPPxizbZo3\nhz7F4cedTPmKlSKJOQpr1qzh04kT6HveAAD22msvypcvH3FU0alevToHtg2uiS9TpgxNmzZj0aI8\nT/+kvcMO70zFihWjDiMWvpg8mQYNGlJ///3Za6+9OP2MMxn19oj8J0wXhT2EHJP7KivZJsmSBb8w\nZ9bXNGvdjpUrlrNflWoAVKxclZUrlgOwfOliJr4/mh5nnRdlqCk3d+7PVKpcmb9e0J+DO7bl4gvP\nZ/369VGHFQvz5s5l+vRpdOh4UNShSEwsWrSQWrW2t8WpWbMWCxfuYTtjqb3ONimSFoWZPWNmy8zs\nm52c7gozK5WsuFLht/XruOmyflzy99vZt3SZHYaZGRbuaT16x/X89aqbKVYsHhtDqmzZvJnp06Zy\nwcAL+d/kqZQqtS/33qPzUOvWreOs3qdyz70PULZs2ajDEZEilMxLf54FHgGe38nprgCGEtwuq0DM\nrLi7b9nJ5STF5k2buOmy8zjm5NPofNxJAFTcrzIrli1hvyrVWLFsCRXCQ8bffzOdfwy+AIA1q1fy\n+YQPKJ6RwWHHnBhZ/KlQo2Ytataqta32dkqv07j3nrsijipamzZt4qzep3LGWWfT85ReUYcjMVKj\nRk0WLNh+/4SFCxdQs2ae909IPzE5FFwYSatSufsEYGVuw81sXzMbbWZfmdk3ZnaGmV0G1ADGm9n4\ncLzHw4uQvzWzWxOmn2tmd5nZVOD0ZK3HznB37r7hcuo2aEzv87Y3Tjvk6ON5961XAXj3rVc5pMsJ\nALw8biqvfDiNVz6cxhHHncwVN92d9okWoFq1atSqVZsfvv8egI/Gj6Npsz23gZS7c+EFA2jStBmX\nDxocdTgSM+07dGDOnNnM/fln/vjjD1579RW6ndQ96rBSKPkPIkiFKG9qcTywyN27AZhZOXdfY2aD\ngaPcPTMc73p3X2lmxYFxZtbK3WeEw1a4e75PW0iVb6Z+zvsjhrF/4+ac3/NIAM4fdD1nXXA5tw4a\nwJg3hlK1Rm1uvv/paAONgX/f/xD9+53DH3/8Qf36+/PEU89EHVJkPvv0U1568QVatjyAg9q1AeDW\n2+7g+BPSf8crN+eecxYTP/6IzMxMGtSrxY033Uq//gOiDisSGRkZ3P/gI5zcrStbtmyhb7/+NG/R\nIuqwUisNarYW3IEqSTM3qweMcvc/XSxnZo2B94BXw3EmhuVzgfZZydbMLiR4qkIGUB241N1fCcc7\nIrxZdG7LHxhOS9Uatdq98uH0Ilu33V3H+mrpmahYAZ4MIiKBQw9qz5dfTknJl6ZYuTpe8rCrCjWP\njWMu/7KAd5BKmpTVr82sdsKzAi909x+AtsDXwG1mdlMO09QHrgK6uHsrYDSwd8IoeTZhdfch7t7e\n3duXq7Bf0a2MiIikRuqf+pMUKTuM7O7zgTZZ/WZWA1jp7kPNbDVwfjhoLVAGyATKEiTUNWZWleC+\nlR+lKmYREYlakdwbOXJJS7Zm9jJwJMHTFhYAN7t74snKA4B7zGwrsAm4KCwfAow1s0XufpSZTQO+\nI3ic0afJildERGIqDc7ZJi3ZuvtZ+Qx/F3g3h/KHgYcT+vvlMn29wkUoIiKSGnrEnoiIxJsOI4uI\niCSZDiOLiIgkkaVHA6ndfw1ERERiTjVbERGJNx1GFhERSS5TshUREUkeIz2Src7ZioiIJJlqtiIi\nEl8Wdrs5JVsREYkxS4vDyEq2IiISa+mQbHXOVkREJMlUsxURkVhLh5qtkq2IiMSakq2IiEgypUlr\nZJ2zFRERSTLVbEVEJLZMl/6IiIgkn5KtiIhIkqVDstU5WxERkSRTzVZERGItHWq2SrYiIhJfaXLp\nj5KtiIjEWjrUbHXOVkREJMlUsxURkdjSdbYiIiIpkA7JVoeRRUQk3qyQXUEWYVbezF43s+/MbJaZ\nHWxmFc3sfTObHf6vEI5rZvaQmc0xsxlm1ja/+SvZioiIwIPAWHdvCrQGZgHXAuPcvREwLuwHOAFo\nFHYDgcfzm/kecxh535IZdKhfMeowYmPc98uiDiFWjmpcOeoQYqVYGhy2K2rFiuk9iYQl/zCymZUD\nOgP9ANz9D+APM+sBHBmO9hzwEXAN0AN43t0dmBTWiqu7++LclqGarYiIxJqZFaoDKpnZlIRuYLZF\n1AeWA/81s2lm9h8z2xeompBAlwBVw9c1gfkJ0y8Iy3K1x9RsRURk91QENdtMd2+fx/AMoC1wqbt/\nbmYPsv2QMQDu7mbmuxqAarYiIrKnWwAscPfPw/7XCZLvUjOrDhD+zzr/thConTB9rbAsV0q2IiIS\nW1nX2RbyMHKe3H0JMN/MmoRFXYCZwEigb1jWFxgRvh4JnBu2Su4ErMnrfC3oMLKIiMRdatqmXQq8\naGZ7AT8B5xFUSIeZ2QBgHtA7HHcMcCIwB9gQjpsnJVsREYmvFLRGBnD36UBO53W75DCuA5fszPx1\nGFlERCTJVLMVEZFYS4fbNSrZiohIrCnZioiIJNvun2t1zlZERCTZVLMVEZFY02FkERGRJCrojSni\nTslWRERiTclWREQkydIh2aqBlIiISJKpZisiIvG2+1dslWxFRCTe0uEwspKtiIjEV4oeRJBsOmcr\nIiKSZKrZiohIbBmQBhVbJVsREYkz3dRCREQk6dIg1+qcrYiISLKpZisiIrGmw8giIiLJZDqMLDvh\n0YcfpMOBB9C+TUsefeiBqMNJieVLFnL9gF5c0vNwLjmlMyOHPgXA0Efu4tJTj+Ly07tw01/PYMWy\nJQB8NPoNLj31KC7tdSRX9zmJn7//Nsrwk+6igQOoX7saHdu2+tOwhx64jzJ7FyczMzOCyKL38IP3\n075NS9ofeAB9+/yFjRs3Rh1SZObPn0/XY47iwFbNadu6BY889GDUIaWUAcWKWaG6OFCyTYFvv/2G\nZ5/5Dx9/+jmTpkznnTGj+XHOnKjDSrrixTPof+UtPPrWRO4ZOoYxr/6XX378nl79LubhN8bz4Gvj\n6ND5WF598j4Aqtasw7/++yYPD/+IMwYO4tFbr4p4DZLr7D59eXPkmD+VL5g/nw8/eI/atetEEFX0\nFi1cyOOPPszE/33BlGlfs3XLFl4b9krUYUUmIyODO+++l2kzZvLxJ5N48olHmTVzZtRhyU5Ssk2B\n77+bRYeOHSlVqhQZGRkc1rkzI98aHnVYSVexclUaNA9qbaX2LU2t+o1YsWwJpUqX2TbOxt82bHvd\nrE0HSpctD0CT1u3IXLY4tQGn2GGHd6ZChYp/Kr/26sH884670uI81a7avGUzv/32G5s3b2bDhg1U\nr14j6pAiU716dQ5s2xaAMmXK0LRpMxYtWhhxVKllVrguDpRsU6B585Z89sknrFixgg0bNvDe2HdY\nsGB+1GGl1NKFv/DTd9/Q5IDgR+OFh/5F/2Pb8vHoNzj7kqv/NP77w1+i3aFHpzrMyI16ewQ1atTk\ngFatow4lMjVq1uTyK66kacO6NKhbg7LlynHMscdFHVYszJs7l+nTp9Gh40FRh5JSWQ+Q39UuDpKW\nbM2stpmNN7OZZvatmV2+E9NeYWalkhVbqjVt1oxBV11Nj25d6XnyCRzQqjXFixePOqyU+W3Deu4c\nfD7nX/2PbbXaPpf9nWfen8oR3U5l9MvP7DD+jMmf8P6bL9N30A1RhBuZDRs2cO/dd3L9TbdGHUqk\nVq1axahRI/n2+5+YM3chG9av5+WXhkYdVuTWrVvHWb1P5Z57H6Bs2bJRh5M6hazVxiTXJrVmuxm4\n0t2bA52AS8yseQGnvQLYqWRrZrHOXn3PG8Ank6bw3riPqVChAg0bNY46pJTYvGkTdw4ewBHdenHI\nMd3+NPzIbr347IPR2/p//mEmj9xyJdc/+Cxly//5EGs6+/mnH5k792cO6XAgLRrvz8KFCzi8U3uW\nLlkSdWgpNf7DD6hXrx6VK1emRIkSdO95Cp//77Oow4rUpk2bOKv3qZxx1tn0PKVX1OHILkjapT/u\nvhhYHL5ea2azgJrAtjP7ZrYvMAyoBRQH/glUBWoA480s092PMrPHgQ7APsDr7n5zOP1c4FXgWOBu\nILatKJYtW0aVKlWY/8svjHjrTcZP/F/UISWdu/PwzYOoVb8RPc+9cFv5onk/UaPu/gB8Pn4steo3\nBGD54gX8a1B/Bt3xCDXrNYgk5ii1aHkAP8/fnlhbNN6fjz+bTKVKlSKMKvVq167DF59/zoYNG9hn\nn334aPyHtG3bLuqwIuPuXHjBAJo0bcblgwZHHU7KBfdGjkn1tBBScp2tmdUDDgQ+zzboeGCRu3cL\nxyvn7mvMbDBwlLtnXfdwvbuvDGuv48yslbvPCIetcPe2yV+Lwjn7zNNYuWIFJUqU4L4HH6F8+fJR\nh5R0s6ZNZvyo16nbqBmXn94FCA4fvz/8ZRbOnYMVK0aV6rW4+Ma7AXjliftYu3oVT9x+LQDFixfn\nvlfeiyz+ZDuvz1+YOPFjVmRm0qRBHa674Wb6njcg6rAi16HjQfTsdSqHHtSO4hkZtG5zIP3PHxh1\nWJH57NNPeenFF2jZ8gAOatcGgFtvu4PjTzgx4shSJT7nXQvD3D25CzArDXwM3O7uw7MNawy8R1A7\nHeXuE8PyuUD7rGRrZhcCAwl2DqoDl7r7K+F4R7j7vFyWPTCcjtp16rSbNXtuka/f7urD75dFHUKs\nHNW4ctQhxEqxNPhxK2pxuV4zDg49qD1ffjklJW9IqRpNvPHAxwo1j69uPeZLd29fRCHtkqS2Rjaz\nEsAbwIvuPjxsNDU97C509x+AtsDXwG1mdlMO86gPXAV0cfdWwGhg74RR1ue2fHcf4u7t3b19pUr6\nMRURkWhmzvHVAAAgAElEQVQk7TCyBfX+p4FZ7n4fgLvPB9okjFMDWOnuQ81sNXB+OGgtUAbIBMoS\nJNQ1ZlYVOAH4KFlxi4hIvKTDYeRknrM9FOgDfG1m08Oy69w98ZY5BwD3mNlWYBNwUVg+BBhrZovC\nBlLTgO+A+cCnSYxZRETiJEaX7xRGMlsjf0LQkCyvcd4F3s2h/GHg4YT+frlMX69QQYqISKylS2tk\n3UFKREQkyfSIPRERibU0qNgq2YqISLzpMLKIiEiSpeLeyGY218y+Di9NnRKWVTSz981sdvi/Qlhu\nZvaQmc0xsxlmlu+NlZRsRUREAke5e5uEG2BcC4xz90bAuLAfgktQG4XdQODx/GasZCsiIvFlkT5i\nrwfwXPj6OaBnQvnzHpgElDez6nnNSMlWRERiK7j0p9CHkSuZ2ZSELqebbTvwnpl9mTC8avhQHYAl\nBA/KgeChOokPJV8QluVKDaRERCTGiuRBBJkFuDfyYe6+0MyqAO+b2XeJA93dzWyXHyagmq2IiOzx\n3H1h+H8Z8CbQEViadXg4/J/1BJeFQO2EyWuFZblSshURkVhLdmtkM9vXzMpkvQaOA74BRgJ9w9H6\nAiPC1yOBc8NWyZ2ANQmHm3Okw8giIhJrKbjOtirwZricDOAldx9rZl8Aw8xsADAP6B2OPwY4EZgD\nbADOy28BSrYiIhJfKXgQgbv/BLTOoXwF0CWHcgcu2Zll6DCyiIhIkqlmKyIisZUuT/1RshURkVhT\nshUREUmyNMi1OmcrIiKSbKrZiohIrOkwsoiISDKl4NKfVFCyFRGR2LKiuTdy5HTOVkREJMlUsxUR\nkVhLg4qtkq2IiMRbsTTItkq2IiISa2mQa3XOVkREJNlUsxURkdgKnkm7+1dtlWxFRCTWiu3+uVbJ\nVkRE4k01291MOuwdFZWjm1SJOoRYeW7KvKhDiJUzWteKOoTYKZmhJi5ZPOoAdkN7VLIVEZHdTxpU\nbJVsRUQkvozglo27OyVbERGJtXQ4BaiTECIiIkmmmq2IiMSXpcdTf5RsRUQk1tIg1yrZiohIfBl7\nyIMIzKx7DsVrgG/cfUXRhyQiIpJeClKzvQg4GPg47O8MTAXqmtlN7v5SsoITERFJg4ptgZJtMaCZ\nuy8GMLPqwDNAJ+AjQMlWRESSZk9pIFU7K9ECuPtiM6vr7plmtjmJsYmIyB4ueOpP1FEUXkGS7QQz\nGwEMC/tPAyaa2b7Ar0mLTEREJE0UJNleDPQGDg37XwWGuftWgvO3IiIiSbNHtEYOk+orYSciIpJS\nu3+qLcDtGs2sh5nNMrM1Zvarma01Mx0+FhGRlLDwLlK72sVBQQ4j3wuc4u5fJzsYERGRdFSQZLtU\niVZERKIQ3EEq6igKryDJ9gszexF4C/g9q9DdRyYtKhEREdijHkSwH7AVSLxtowNKtiIiknRpkGsL\n1Bq5TyoCERERiZKZFQemAAvd/SQzq09wJc5+wJdAH3f/w8xKAs8D7YAVwBnuPjeveeeabM3sSne/\n18zuJ6jJ7sDdB+/qComIiBRUCg8jXw7MAsqG/XcB97v7K2b2BDAAeDz8v8rdG5rZmeF4Z+Q147wu\n/fkx/P8N8G0OnYiISFJlNZAqTFeg5ZjVAroB/wn7DTgaeD0c5TmgZ/i6R9hPOLyL5bNHkGvN1t3f\nCl+ucvfh2YLqVbDwRURECidFNdsHgKuBMmH/fsBqd896BsACoGb4uiYwH8DdN5vZmnD8zNxmnu9N\nLYAbcii7vgDTiYiIxEElM5uS0A1MHGhmJwHL3P3LZAWQ1znbrsDxQE0zuy9hUFmC1skiIiJJVwT1\n2kx3b5/H8EOB7mZ2IrA3QZ57EChvZhlh7bYWsDAcfyFQG1hgZhlAOYKGUrnKq2a7jOB87UZ2PFf7\nHnBCPismIiJSaGbBgwgK0+XH3f/u7rXcvR5wJvChu58NjCd40h1AX2BE+Hpk2E84/EN3/1ND4kS5\nJlt3n+buTwNN3P3phG6Yu+d6XFpyt2XLFjp1aEuvnidHHUrKXTSwP/VqVaXDgQdsKxv+xmu0b9OS\nMnsXZ+qXUyKMLjVWLV3EA/93Fv88+1j+efZxjB/2XwAWzJ7Jvwf24vY+x/P41QP4bf1aADZv+oMX\nbv8bt/c5njv6nsAPUydFGX5KbNmyhaMOac9Zp/UA4D9PPEqHVk2pVLoEKzL3rJ+diwYOoH7tanRs\n22pb2R3/vJXG+9fmkI5tOaRjW94dOybCCFMn65m2u9oVwjXAYDObQ3BO9umw/Glgv7B8MHBtfjMq\nyDnbmmb2ipnNMLMfsrpdjXxP9ujDD9K0abOow4jE2X368dbb7+xQ1rx5S1569Q0OPXzPeFJjseIZ\n9Lr0em588X3+NmQ4E4Y/z+KfZ/PinX+nx0VXc/0LY2nduSsfvDgEgE9HBg/auv6FsVz6wAsMf+R2\ntm5N7zM4Tz72EI2abP+OdDz4EN54eyy169SNMKponN2nL2+O/HMyveTSK/hs8lQ+mzyVrsefGEFk\n6c3dP3L3k8LXP7l7R3dv6O6nu/vvYfnGsL9hOPyn/OZbkGT7LPBfgsPmJxA8RP7VXV6TPdSCBQsY\n+84Y+vUfEHUokTjs8M5UqFBxh7KmzZrRuEmTiCJKvXKVqlCnSUsA9t63NFXrNmT18iUsm/8zDdsc\nBECzDocx/eOxACyZO5vG7Q4GoEyFSuxTuiy/fDcjmuBTYNHCBbw/9h3O6dt/W1mr1gdSp2696IKK\nUE7fmT1VOjz1pyDJtpS7vwvg7j+6+w3onO1Ou/rKQdz2r7soVqwgb7mkuxWLF7Bg9kzqtWhD9fqN\nmDHxfQCmjh/DqqWLAajZsBlff/IBWzZvJnPRfOZ///W2Yeno+quv5Obb/qXvSD6GPP4ondq34aKB\nA1i1alXU4aREhIeRi0xBturfzawY8KOZXWhmJ7P9OqRcmdneZjbZzL4ys2/N7NaCBmVm1xV03N3B\nmNGjqFylMm3btos6FImBjRvW89T1F3HaZTeyz75lOOe6u5kw/AXu7H8yGzesJ6NECQAO7tab8pWr\nc9eA7rz+4D+o37IdxYoXjzj65Hj3ndFUqlyZNgfqO5KX8wdeyIxZs/ls8lSqVavOdddcFXVISWcU\nrnFUQRpIpUJBHkQwCNgXuAy4naCJc/88pwj8Dhzt7uvMrATwiZm94+4FaeVxHXBHAcbbxsyKu/uW\nnZkmVSZ99imjR73Nu2PfYePGjaz99Vf69+3DM8+9EHVokmJbNm/iP9dfRIfjetDmyOMBqFa3AZc+\nEGwLS3/5iW8/+xCA4hkZnHb5jdum/fdfT6VK7fqpDzoFJk/6jLFjRvHBe2P5feNG1q79lQsHnMsT\nTz8fdWixUqVq1W2v+/U/n9N7dc9jbImTfGu27v65u69191/cvY+7dwfmFmA6d/d1YW+JsNuhabSZ\nVTezCWY23cy+MbPDzexOYJ+w7MVwvLfM7MuwhjwwYfp1ZnavmX0FHFzgtU6xf9z+L+b8PJ/vZv/M\n80Nf5oijjlai3QO5O0P/dQ3V6jaky5nnbytfuypoZbt161bGPvcIh/U8G4A/Nv7G779tAGDW5IkU\nK16c6vUbpT7wFLjx1tv5+oe5TJs5hyHPvshhRxylRJuDJYu3n0Z4e+RbNG/RIsJoUqSQh5BjUrHN\nu2ZrZh0Ibkv1ibtnmlkLgqbQRxNc4Jun8AkKXwINgUfd/fNso/wFeNfdbw/HLeXuE83s/9y9TcJ4\n/d19pZntQ/B83TfcfQVBjftzd7+ygOsrEenX5y9MnPARKzIzabx/ba6/8RYqVKzIVYMuI3P5ck7t\neRKtWrVhxOixUYeaND/OmMLksW9So0ET7ugbtCLt/te/sXzBXCYMDxJL6yOO5+BupwOwdtUKHhl0\nLlasGOUrV6PvTfflOu90NeSxh3n4gXtZtnQJnTu15Ziux/Pgo0OiDislzuvzFyZO/JgVmZk0aVCH\n6264mU8mfMyMGV9hZtSpW5eHHnki6jBTIi6NnArDcrsO18z+BZwKfAXUB0YBFxM83eBxd99Q4IWY\nlQfeBC51928SyjsDzwBDgbfcfXpYvs7dSyeMdwtwSthbD+jq7pPMbDNQMrfDx2EteCBA7Tp12n0/\nZ25BQ057W/O8/HrP89yUeVGHECtntM53X3qPUzJDDbeydD6kI1O/nJKSDFilYUs/457XCjWPR3o1\n/zKfO0glXV412x5Aa3f/zcwqEtx0+YCCXE+UnbuvNrPxQDczGxoW3+TuI8OE2w141szuc/cdjh2Z\n2ZHAMcDB7r7BzD4iuJ0WwMa8ztO6+xBgCEDbdu2VXkREJBJ5JduN7v4bQHgI94edSbRmVhnYFCba\nfYBjgbsSDw+bWV1ggbs/FT6Mty3BA3k3mVkJd99E0CBrVZhomwKddnotRURkt2Skx2HkvJLt/maW\n9Wg9A+on9OPu+T1mrzrwXHguthgwzN1HZRvnSOBvZrYJWAecG5YPAWaY2VSCls8Xmtks4Hsg/e9Z\nJyIi2xT0mbRxlleyPTVb/yM7M2N3nwEcmM84z7H9AbyJ5dcQNMTKkuNNNBLP64qISHpK62Tr7uNS\nGYiIiEi6KshNLURERCIRXCu7+1dtlWxFRCTW0vowcnZmVjLr8UIiIiKpkgYV2/xv12hmHc3sa2B2\n2N/azB5OemQiIiJpoiC3RHkIOAlYAeDuXwFHJTMoERERCK473VOe+lPM3edlO0Edy6friIhI+kmH\nG2UWJNnON7OOgIc3qLgU+CG5YYmIiARiUjktlILsMFwEDAbqAEsJbpd4UTKDEhERSSf51mzdfRlw\nZgpiERER2YHF6LxrYeSbbM3sKbI99B3A3QfmMLqIiEiRSoNcW6Bzth8kvN6b4Lmy85MTjoiIyI72\niJtauPurif1m9gLwSdIiEhERSTO7crvG+kDVog5EREQku6zrbHd3BTlnu4rt52yLASuBa5MZlIiI\nSJY0yLV5J1sL7mTRGlgYFm119z81lhIREUkKS49ztnleZxsm1jHuviXslGhFRER2UkFuajHdzA5M\neiQiIiI5sEL+xUGuh5HNLMPdNwMHAl+Y2Y/AeoLz1e7ubVMUo4iI7KGCBlJRR1F4eZ2znQy0Bbqn\nKBYREZE/SfdkawDu/mOKYhEREUlLeSXbymY2OLeB7n5fEuIRERHZgaXBtT95JdviQGmIydllERHZ\n4+wJ52wXu/s/UhaJiIhIdpYeN7XI69KfNFg9ERGR6OVVs+2SsihERERykQ73Rs61ZuvuK1MZiIiI\nSHZZ52wL0+W7DLO9zWyymX1lZt+a2a1heX0z+9zM5pjZq2a2V1heMuyfEw6vl98yCnIHKRERkciY\nFa4rgN+Bo929NdAGON7MOgF3Afe7e0NgFTAgHH8AsCosvz8cL0+78oi93ZKRHs3Hi0pxvRU76NO2\nTtQhxEqt/i9GHULsTLn/1KhDiI1Nm7emcGlGsSQ3IQrv+78u7C0Rdg4cDfwlLH8OuAV4HOgRvgZ4\nHXjEzCyv5weoZisiIumukplNSegGZh/BzIqb2XRgGfA+8COwOrxtMcACoGb4uiYwHyAcvgbYL68A\n9piarYiI7H6Co5KFnk2mu7fPawR33wK0MbPywJtA00IvNYGSrYiIxFeKn2fr7qvNbDxwMFA+4aE8\ntdj+bPeFQG1ggZllAOWAFXnNV4eRRUQk1oqZFarLj5lVDmu0mNk+wLHALGA8cFo4Wl9gRPh6ZNhP\nOPzD/J73rpqtiIjs6aoDz5lZcYJK6DB3H2VmM4FXzOw2YBrwdDj+08ALZjYHWAmcmd8ClGxFRCS2\niuicbZ7cfQbBs9uzl/8EdMyhfCNw+s4sQ8lWRERiLR3uIKVkKyIisZYGuVYNpERERJJNNVsREYkt\nIz1qhUq2IiISX5Yet9pVshURkVjb/VNtetTORUREYk01WxERia3geba7f91WyVZERGJt90+1SrYi\nIhJzaVCx1TlbERGRZFPNVkREYsx06Y+IiEgy6aYWIiIiKZAONdt02GEQERGJNdVsRUQk1nb/eq2S\nrYiIxJnujSwiIpJc6dJAKh3WQUREJNZUsxURkVhLh8PIqtmmyF/P70+dGlVo16Zl1KFEbv78+XQ9\n5igObNWctq1b8MhDD0YdUiQu/usA9q9TjYPatdpW9vWMr+hyxKF0at+a3qd259dff40wwuQrV6oE\nz1/emS/+3Z3J93SnQ6NKXH96az698yQm3tGNN6/tQrXy+wBw+qH1+fTOk/jszpN475autKxTIeLo\ni97fr7iQTi3q0u2I9tvKVq9aSb/eJ3Hswa3o1/sk1qxetW3Y559OoHuXTpzYuT1n9+waRcgpYYXs\n4kDJNkX69O3HiFFjow4jFjIyMrjz7nuZNmMmH38yiSefeJRZM2dGHVbKnd2nL8NHjNmh7P8uGsit\nt93BpClfcXL3njx4/78jii417jy3Ax98tYgOV43k0GtH8cPCNTw0aiaHXjuKw68bzdhpC7mmV7Az\nMm/ZOrr98z0OuXYUd7/5NQ+e3yni6IterzPO4emX39qhbMjD93Lw4Ufy/v9mcPDhRzLk4XsB+HXN\nam65dhBPPPcaYyZM4aGnXogi5JQwK1wXB0q2KXLY4Z2pWLFi1GHEQvXq1TmwbVsAypQpQ9OmzVi0\naGHEUaXeoYd1pkK2beLHOT9w6GGdATjq6GMZ+dbwKEJLibL7lODQplV5/qM5AGzaspU1Gzax9rdN\n28bZt2QGjgMwefZyVq//A4ApczKpUbFU6oNOsg4HH0a58jtuE+PeHc0pvc8G4JTeZ/PB2FEAvD18\nGMd1606NWrUB2K9yldQGKztFyVYiNW/uXKZPn0aHjgdFHUosNG3WgtFvjwDgreGvs3DB/IgjSp66\nVUqTuXYjj/31ECbe0Y2HL+hEqZJBM5Ibe7fh24d7cfqh9bn9ta/+NG2fIxvywVd7xg5a5vJlVKla\nHYDKVaqRuXwZAHN/ms2a1as555TjOeW4Q3lz2ItRhpk0QWtkK1QXB0lPtmZW3MymmdmonZjmumTG\nJPGwbt06zup9Kvfc+wBly5aNOpxYeOzJ//DUkMfpfEgH1q5bS4m99oo6pKTJKGa0rleRpz/4gcOv\nG8363zczqHsLAP45bDotLh3Oa5/+zMDjmuww3eHNq9LnyIbc9PLUKMKOlNn2m/Jv3ryFb2dMY8jQ\nN3j65RE8dv9d/Pzj7IgjTA4dRi6Yy4FZOznNTidbMyu+s9NIdDZt2sRZvU/ljLPOpucpvaIOJzYa\nN2nKiFHvMuGzLzit95nUr98g6pCSZuHKDSxcuYEvf8wEYMTnv9C63o6HUId9+hPdO9bd1t+idnke\nvuBgzrp3PKvW/ZHSeKNSqXIVli1dDMCypYvZr1JlAKrVqMFhRx5DqX33peJ+lejQ6VC++/brKENN\nEiv0XxwkNdmaWS2gG/CfXIZXN7MJZjbdzL4xs8PN7E5gn7DsxXC8t8zsSzP71swGJky/zszuNbOv\ngIOTuS5SdNydCy8YQJOmzbh80OCow4mV5cuCQ4Rbt27lnjtvZ8AFA/OZYve1bM1GFq5YT8PqwVGN\nI1pW4/uFa9i/Wplt45zYrjazF60BoNZ+pRg66AgGPvYpPy5ZG0nMUTj6uBO3HSJ+c9iLdOnaDYAu\nXU/iy8mfsXnzZn7bsIGvpn5Bg0ZN8pqVRCjZ19k+AFwNlMll+F+Ad9399rBmWsrdJ5rZ/7l7m4Tx\n+rv7SjPbB/jCzN5w9xXAvsDn7n5lUteiCJx7zllM/PgjMjMzaVCvFjfedCv9+g+IOqxIfPbpp7z0\n4gu0bHkAB7ULPuZbb7uD4084MeLIUuu8c//CJxM/ZkVmJk0b1OG6G29m3br1PPXkYwB073EK55x7\nXsRRJtfVz33Bfy45jBIZxZi7bB2XPPkZD1/QiYbVy7HVnfmZ6xn09CQArunVioplSnLveR0B2LLV\nOfKGMXnNfrcz6MK+TP5sIqtWruDwAxtx2d9uYOClV3L5wD68/tLz1KhVmweHBK2OGzZuSuejjuXk\now6iWDHj9LP70bhZi4jXIDnicii4MMzdkzNjs5OAE939YjM7ErjK3U/KNk5n4BlgKPCWu08Py9e5\ne+mE8W4BTgl76wFd3X2SmW0GSrr7llxiGAgMBKhdp067H36cV4RrKOlk0+atUYcQK7X6p2djm8KY\ncv+pUYcQG72OO4yvv5qakhTYuEUbf2jY+4Waxwktq3zp7u3zHzN5knkY+VCgu5nNBV4Bjjazd8LD\nw9PNrLu7TwA6AwuBZ83s3OwzCRP1McDB7t4amAbsHQ7emFuiBXD3Ie7e3t3bVw7Pc4iIyG6kkI2j\n4lIrTtphZHf/O/B32JYwc6rZ1gUWuPtTZlYSaAs8D2wysxLuvgkoB6xy9w1m1hRIvyvZRUQkrUV9\nb+Qjgb+Z2SZgHZBVsx0CzDCzqUB/4EIzmwV8D0yKIlAREYlGXGqnhZGSZOvuHwEf5VD+HPBcDuXX\nANckFJ2Qy3xL51QuIiLpIy6X7xRG1DVbERGRXBlQbPfPtbpdo4iISLKpZisiIrGWDoeRVbMVEZFY\nS/alP2ZW28zGm9nM8E6Fl4flFc3sfTObHf6vEJabmT1kZnPMbIaZtc1vGUq2IiISaym4N/Jm4Ep3\nb05weeklZtYcuBYY5+6NgHFhPwSNdhuF3UDg8fwWoGQrIiJ7NHdf7O5Tw9drCR6eUxPowfYrZp4D\neoavewDPe2ASUN7Mque1DJ2zFRGR2Cqi1siVzGxKQv8Qdx+S4/LM6gEHAp8DVd19cThoCVA1fF0T\nSHzY9IKwbDG5ULIVEZEYK5LH5GUW5N7IZlYaeAO4wt1/tYQTvu7uZrbLDxNQshURkfhK0f2NzawE\nQaJ90d2Hh8VLzay6uy8ODxMvC8sXArUTJq8VluVK52xFRGSPZkEV9mlglrvflzBoJNA3fN0XGJFQ\nfm7YKrkTsCbhcHOOVLMVEZFYS0HF9lCgD/C1mU0Py64D7gSGmdkAYB7QOxw2BjgRmANsAPJ98LSS\nrYiIxFbQQCq56dbdPyH3nN4lh/EduGRnlqFkKyIisbb73z9K52xFRESSTjVbERGJtzSo2irZiohI\nrKXDgwiUbEVEJNZScZ1tsumcrYiISJKpZisiIrGWBhVbJVsREYm5NMi2SrYiIhJbRno0kNI5WxER\nkSRTzVZEROIrRU/9STYlWxERibU0yLVKtiIiEnNpkG11zlZERCTJVLMVEZEYs7RojaxkKyIisaYG\nUiIiIklkpMUpWyVbEYCM4unwdS46Mx/tHXUIsdPw6CujDiE2fp+9IOoQdjtKtiIiEm9psC+sZCsi\nIrGmBlIiIiJJlg4NpHSdrYiISJKpZisiIrGWBhVbJVsREYmxNLn2R8lWRERiLR0aSOmcrYiISJKp\nZisiIrFlpEdrZCVbERGJtTTItUq2IiISc2mQbXXOVkREJMlUsxURkVhLh9bISrYiIhJraiAlIiKS\nZGmQa3XOVkREJNlUsxURkXhLg6qtkq2IiMRWcGvk3T/b6jCyiIjElwUNpArTFWgxZs+Y2TIz+yah\nrKKZvW9ms8P/FcJyM7OHzGyOmc0ws7b5zV/JVkREBJ4Fjs9Wdi0wzt0bAePCfoATgEZhNxB4PL+Z\nK9mKiEisWSG7gnD3CcDKbMU9gOfC188BPRPKn/fAJKC8mVXPa/5KtiIiEm+pyLY5q+rui8PXS4Cq\n4euawPyE8RaEZblSAykREYkxK4oGUpXMbEpC/xB3H7IzM3B3NzPf1QCUbEVEJN1lunv7XZhuqZlV\nd/fF4WHiZWH5QqB2wni1wrJc6TCyiIjEWipaI+diJNA3fN0XGJFQfm7YKrkTsCbhcHOOVLMVEZHY\nKvxp1wIux+xl4EiCQ84LgJuBO4FhZjYAmAf0DkcfA5wIzAE2AOflN38l2xR5792xXDX4crZs2UK/\n/ufzt6uvzX+iNKb3Y0dNG9WnTOkyFCtenIyMDD6d9EXUIaXUj7N/4KIB52zr/2Xuz1z195uoVr0G\n9911G7N/+I5RH3xC6wPbRRhlcjWqW4UX7uq/rb9+zf345+OjKVemFP17HcLyVesAuPmRkbz7yUwq\nltuXl+4ZQLsWdRk6chKD7notqtCTLwXZ1t3PymVQlxzGdeCSnZm/km0KbNmyhSsuu4TR77xPzVq1\nOKxTB046qTvNmjePOrRI6P3I2Tvvf0ilSpWiDiMSDRo15r0Jk4Fg+2jfYn+OP6k7v234jaeef5Vr\nBu/U79puafa8ZXQ6804AihUzfnz3dkaO/4o+3Q/m4aHjeeCFcTuMv/H3TfzjsVE0b1iDFg3yvOpE\nYkDnbFPgi8mTadCgIfX335+99tqL0884k1Fvj8h/wjSl90Py8snHH1K3Xn1q1a5LoyZNadCocdQh\npdxRHZvw84Ll/LJ4Va7jbNj4B59N/4mNv29KYWTRsEL+xYGSbQosWrSQWrW2N1yrWbMWCxfm2XAt\nren9+DMz4+QTu3LIQe15+j87dUVC2hk5/DV6nHpG1GFE6vSu7Rg29stt/Ree2ZnJr/6dJ24+m/Jl\n9okwsmhE2ECqyCQ12ZrZXDP72symZ7vGKb/prjCzUsmMTSROPhg/kf9N/pK33h7DkMcf45OJE6IO\nKRJ//PEH740dzUk9ekUdSmRKZBSn2xEHMPz9aQA89dpEmp98CwedeSdLMn/lzsF73nsT3T0tik4q\narZHuXubnbzG6Qpgp5KtmRXfubBSp0aNmixYsP1mIwsXLqBmzTxvNpLW9H78Wdb6V6lShZN79GTK\nF5Mjjiga4z94lwNataFylar5j5ymuh7WnOnfzWfZyrUALFu5lq1bHXfnmeGf0r5l3YgjlF0R6WFk\nM9vXzEab2Vdm9o2ZnWFmlwE1gPFmNj4c73Ezm2Jm35rZrQnTzzWzu8xsKnB6RKuRr/YdOjBnzmzm\n/vwzf/zxB6+9+grdTuoedViR0fuxo/Xr17N27dptr8d98D7NW7SMOKpojHhjGD1O7Z3/iGms9/Ht\ndy4lyZUAABEOSURBVDiEXK1S2W2vexzdmpk/5nk5Z/pJ0VN/ki3ZrZEdeC+8xdWTOdwe63hgkbt3\nAzCzcu6+xswGE9SIM8Pxrnf3lWHtdZyZtXL3GeGwFe6e4+ONzGwgwRMZqF2nThGvWsFlZGRw/4OP\ncHK3rmzZsoW+/frTvEWLyOKJmt6PHS1bupQzTw8ODW7evJneZ57FcV2zP3wk/W1Yv54JH43jzvsf\n2Vb2zqgR3HjNYFauWE7fM0+hRctWvPjGqAijTK5Se+/F0Qc15f9ue3lb2e2X96RVk1q4O/MWr+TS\n/2/vzqPlqso0Dv9eIBDAKCohMglKQEUFhGAjbcsgplEBg4iSxgFEBsEJBJvV3dqC80KXbaOtgrCw\ntREQZRlBhoioiIAhYYaAitASDIShgTCIkLf/2Pti1TWEhNyqU6nzPmvdlRpOTn33W/ecr/bZ++zd\n8d7cc45hwprjWXXcKuy+0xbsdujXmHvL/CZC77EBqZjLQeV2oR7tXFrf9jxJ6wAzgQ/WlRVG3t8M\nuAA4HTjb9sX19VuBKSPFVtIhlKK5CrBu3c9pdbsdbN/2dLFss80UX3L5UncbR8v08jhYEd278LGm\nQxg4k3f+aNMhDIw/33QGix6+qy8VcMtXbeOfXHTpcu1jg+euNvsZTtc4Znp6Gdn2vPrvXcBZwA51\nsNRVkg6xfTOwNXAt8GlJnxi9D0kvAo4EXm97C+AcYHzHJg/18neIiIhYXj0rtrU/dsLIY2AqMKsO\nltrK9jckrQc8bPu7wHGUwgvwIDChPn42paDeL2kSZdHeiIhoiWEYjdzLPttJwFkqvdOrAKfaPm/U\nNq8EjpO0CPgL8P76+gnAeZLusL2TpCuBuZT1Ay/pYcwRETFgBmWQ0/LoWbG1fQuw5dNscz5w/mJe\nPx44vuP5fk/x/zderiAjImLgDcosUMsjM0hFRET0WBYiiIiIwbbiN2xTbCMiYrANQa1NsY2IiME1\nSLNALY/02UZERPRYWrYRETHQhmE0coptREQMthW/1qbYRkTEYBuCWps+24iIiF5LyzYiIgbaMIxG\nTrGNiIgBpgyQioiI6CUxHC3b9NlGRET0WIptREREj+UyckREDLRhuIycYhsREQMtA6QiIiJ6KQsR\nRERExNJIyzYiIgaWGI7pGlNsIyJisA1BtU2xjYiIgTYMA6TSZxsREdFjadlGRMRAG4bRyCm2EREx\n0Iag1qbYRkTEgBuCaps+24iIaD1Ju0q6SdLvJB091vtPyzYiIgZar0cjS1oZ+BrwBuB2YJakGbZv\nGKvPSMs2IiIG1sh6tsvzsxReDfzO9i22HwNOA94ylr9Ha1q2c+bMvnv1cbqt6TiAtYG7mw5igCQf\n3ZKPbslHt0HJx0b9+qA5c2afv/o4rb2cuxkv6YqO5yfYPqHj+frAHzue3w783XJ+ZpfWFFvbE5uO\nAUDSFbanNB3HoEg+uiUf3ZKPbm3Mh+1dm45hLOQyckREtN08YMOO5xvU18ZMim1ERLTdLGBTSS+S\ntCqwDzBjLD+gNZeRB8gJT79JqyQf3ZKPbslHt+SjB2w/LukDwPnAysDJtq8fy8+Q7bHcX0RERIyS\ny8gRERE9lmIbERHRYym2ERERPZZi2zBpGBaPGjud+ZC0VpOxDIJR+VityVgGQfLRLcfLiiPFtmGu\nI9QkvVTS+KbjaZIkdeTjEGB/SeMaDqsxklYalY+3SmrtMZt8dMvxsmJp7R/qIJG0L3AsZch5a3Wc\nOHYBpgCn2f5Ls1E1x/YiAElvArYFfjnyWhslH91yvKxYUmwbVgvta4Av2H6o6XiaJGklSZOAU4EX\nAg/U1ThaqebjBcDZwPNsz5M0rq1dD8lHtxwvK5YU2z4bOTF0nCC2Bd4BTBz1eiuM+n1t+07gzZSp\n06bbfqKZyJqxmHzMB3YBdpU0faTl0pa/k+SjW46XFVdmkOqjzj4WyuodC2x/RNKDwLGSrrF9x6jt\nhtaoPqfpwGRJl9j+maR3AadLWmT75GYj7Y9R+dgTmCjp8pqPNwI/qtuc2myk/ZF8dMvxsmJLy7aP\nOg6UDwFflXS8pC1sfxz4GXCmpA3aUGihKx+HAR+gTPz9LUkfA64G9ga+VE8kQ29UPj4GrAGcJ+mf\nbP8c2A34rqS9m4uyf5KPbjleVmwptn0m6UBgL+BgYGfgs5J2tX00MBv4dpv6XSS9mJKHqcB44D5g\nK+Bo4EpgB+DSxgLsM0mvBN5GuVT6GHAPcLCkA2xfDGwPXNNgiH2VfHTL8bICs52fHv4AK3U8FvBx\nYD3gw8AF9fmvgDfXbSY2HXOP8zEJmFwfTwNWpVxS3wG4sL6+NzAfOKzpePuQj3WBDevjXShfgCcC\nu3fk40PAA8Bbm443+eh7PnK8DMlP+mx7SNLzgDdRLnUdDCwAPktZK/EfbU+t2+0D7Cjp57YXNBZw\nf6wNnCjpGsrgsEtt3ynp+cDI4I7HKF9AftBQjP00idLXdh7wCuBq2wskrQ3cXre5HbgQuKyhGPsp\n+eiW42VIpNj2kO17Jb1G0qeAO4Fptp+Q9CiwkaS3AIuA/wW+4iG+9WdkcIft6yXNBP4ZOLieOEQ5\neb5f0s8pLZm3uYw8HUod+bhK0gXAoZTRpAtqN8IcYJqkcygjTfeyfUeTMfdS8tEtx8vwyRJ7PTBq\n1OAWwCnA/bZ36thmOvA+YC1gP9vXNhFrP4zKxyspLftJwL8AR9g+u763DrA5cJvtPzQVb6+NysfG\nwKuA9YFPAXu6DP4ZydXmwJW2b24k2D5IPrrleBlOadmOsVEHypuBv1AmrThZ0rmUb+QPA7Ntf0/S\n823f02DIPdeRjyMpfU2H2T5X0iPA8ZIWApOBrW0f2mCofTEqH9sBH7A9X9LDlNtZXktpvU2xfWyD\nofZF8tEtx8twSrEdYx0HyoeAAyiXd/4M7Cvp28D3Jf2UMqJyu2EvtCPq7Rl7ArvYfkTShpQ+pgWU\nkZSrAYc3GGJfSXoPJR+72b5P0kTbJ0t6ADidMgDowEaD7KPko1uOl+GTy8g9IGlb4OvAjrYXStoZ\nWMP22ZI+SrksdJLt6xoNtI/qyeN1wCXAy4CdgEeBdwOPA4/ZfqC5CPur3gK2FjCXMhBod+Baykjb\ndYEH2/JFDJKP0XK8DJ/cZ9sbvweuoNxw/h+UG/IPkHSg7S8BH2tLoa2DOQBupIyaPISSm0Mo9wWu\nZ/vutpw4OvJxO7ApcBTwW+CTlPysa/vWNhQWda/Y0/p8jJLjZcikZTsGJK3sOidpPZmuSRmmvwdw\nMnADZcaX8ba/0FigfSBpMqWFcp3tR0e9t4rtx+vjvSgn1N1t39rvOPtF0sspt2/caPuuUe89B3jA\ntiXtARxDycfti9nVUKj9ry+y/Z36vPNvoo352B14se2v1OedYz5ad7wMs/TZLgdJm9m+ud7OM1Jw\nV6qXjq+wfVHd7t3AuyiXgIaWpN0o9xHfA8yX9JmRFrykKcAUSWcAr6WcOKYP84lDZf7eLwC3AOMk\nHWR7Xn3vVZRBP7+QtCtlcpN9hrWw1FbsGsA3y1OtafsbHcWkVfkAkDSVMuL6qJHXOgrttsA2bTpe\nhl0uIz9DtbBcJelUgFpwV6n//gPwRUkb1JPI7sD+tm9oMuZekrQ9cBzwnnqL033AEfW9KcAM4Cbb\n9wLXAVOH+VK6pB2BrwDvsz2NcknwZfW9VwM/orTi7qcU4zcOcz5sL7K9EPg2cBKwvaSPwJN/H2dS\nbo9rRT7q8fId4CDbMyU9R9JGklaTtB1lUNhv23K8tEEuIz8DktakjAz8IWVu1lVsv7O+92JgJnC4\n7RmSxtf3FzYWcB/Uk8dmtk+pzycCJwJvB7YEnm37wuYi7C9JLwNeYPsilTVY5wC/ofRN3km59esn\nTcbYBElHUNZe/TFltP484CXA8bZnNhlbP0l6CWViisMosz+dCTwC/B9lzMevbZ/bXIQx1tKyfQZc\nZnp6L2XR5iOB8ZK+W98b+VY+oz5/dNgLbXU55csHKjP+rAZsBKxlexYwW1Jrui1s3zjSjUApKv9V\nW7hXUgYC/Qb+ZpBQG/wImF+/eM0GPgjcOlJoOwaQDTXbN1HWof0yZcWeUymrGF1EOW4ug/bkow3a\ndqCPGdt32F5o+27KCj6rS/qf+vaatWXTGraf6BghKco39Htt3yVpX+BzlEnUW8f2Z2x/uj4+CXg+\npXWH7UVNxtaAR4CX1Ft93k/p499YZe7wJ/ss28D21ZQC+3nbJ9ZL7SdSpl/cqG7TmnwMu9a0NHrJ\n9j31ZHGcpLnAypT74lqpDnpZKOmPkj5HWQ5sP5eZs1qlc3Rpfb4X8AJgaOf1XRLbd0j6I2UA1GG2\nfyxpJ+B3DYfWiDqO48mxHPXvYx3gT40FFT2RPtsxJOlwyoThb/AQz3X8dOqlr3GUewXHAa+3/dtm\no2qWpNWAd1IGjb2jzYNd6mxI69ieXZ+v1MIWfpd6zOxP6Zba2/b1DYcUYyzFdoxIei5wBvBR261Z\nzHpJJO0HzMqJAySNA94A/L7217Xe6FZ/m9ViuwOlP3tu0/HE2EuxHUOSxo+eyKHNcjKNiChSbCMi\nInoso5EjIiJ6LMU2IiKix1JsIyIieizFNlpD0hOSrpJ0naTvS1pjOfa1o6Sz6+M9JB29hG3XknTo\nM/iMT0o68ilen1d/lxskTV+KfU2TtHnH82Ml7bKsMUXEM5NiG23yiO2tbL+Cv64V+iQVy3xM2J5h\n+/NL2GQtYJmL7dP4su2tgLcA36y3Fi3JNODJYmv7E7Z/OsYxRcRTSLGNtroYmCxpY0k3Sfpvyuoq\nG0qaKulSSXNqC/hZAJJ2lTRX0hzgrSM7krSfpK/Wx5MknSXp6vqzPfB5YJPaEj2ubneUpFmSrpF0\nTMe+/lXSzZJ+RZmgf4nqZCEPA8+t///Aut+rJf1A0ho1hj0oM5xdJWkTSadIelv9P7dKOqb+vtdK\neml9faKkmZKul/QtSbdJWnu5Mx/RQim20Tp1QYQ3AiOzfG1KWSjg5cBDwL8Bu9jeGrgCOKKu3nQi\nZbnEbShTLi7OfwK/sL0lsDVwPXA0ZTKLrWwfpbKO6abAq4GtKOuWvk7SNsA+9bU3Adsuxe+yNWUp\ntpGF6X9oe9v6+TcCB9j+NWWJw6NqDL9fzK7urr/v1ymzGAH8O/CzmpczqfM5R8Syy9zI0SarS7qq\nPr6Ysq7qesBtti+rr29Hudx6SV1wZVXgUuClwB9Gpp2sqzwdtJjP2Bl4N5TFGYD76+xinabWnyvr\n82dRiu8E4KyROaQlzVjC73K4pP2BzShfAEa8QtKnKZeunwWcv4R9dPph/Xc2f221vxbYs/4u50m6\nbyn3FRGjpNhGmzxS+zmfVAvqQ50vATNtTx+1Xdf/W04CPmf7m6M+4yPLsI8v2/6ipD2AkyRtUmcv\nOwWYZvvqOl3mjku5vz/Xf58g54WIMZfLyBHdLgP+XtJkAElrStoMmEtZCm6Tut1TjQC+kLJ0HJJW\nlvQc4EFKq3XE+cB7O/qC15e0DvBLYJqk1SVNoLvFulh13eQrgPfUlyYAf6oDpvbt2HR0DEvjEuDt\nNcap1H7hiFh2KbYRHWwvAPYDvifpGuol5NpqPAg4pw6QuuspdvFhYCdJ11IuyW5u+x7KZenrJB1n\n+wLKYuGX1u3OBCbYngOcTllM/Fxg1lKGfSylX3klytJ1l1MKZeeE9qcBR0m6suMLw9M5Bpgq6Tpg\nb2A+pWhHxDLK3MgRsVgqywI+YftxSa8Bvj76MnxELJ30zUTEU3khcEZtMT8GHNhwPBErrLRsIyIi\neix9thERET2WYhsREdFjKbYRERE9lmIbERHRYym2ERERPZZiGxER0WP/DwoE8C7yqEFjAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1105eb898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_matrix = sum(ms) / 10.0\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(avg_matrix.astype(int), classes=[\"1-star\",\"2-star\",\"3-star\",\"4-star\",\"5-star\"],\n",
    "                      title='Average Confusion matrix of 10-fold Cross validation (2446)')\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "plt.savefig('./plot/confusion_matrix.png', dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi 2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi2, pval = chi2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.27e+02,   1.56e+00,   3.95e+01,   1.19e+01,   5.02e+00,\n",
       "         5.00e+00,   1.98e+00,        nan,   1.55e+00,   5.92e-01,\n",
       "         7.21e-01,   3.09e-01,   7.68e-01,   1.29e+00,   3.07e+01,\n",
       "         1.96e+00,   1.44e+00,   6.57e-01,   4.11e+00,   1.61e+00,\n",
       "         1.32e+00,   2.99e-01,   1.31e+01,   9.03e+01,   6.53e-01,\n",
       "         9.39e+00,   9.26e+00,   2.67e+00,   5.68e+00,        nan,\n",
       "         1.69e+00,   2.11e+00,   1.27e+00,   4.76e-01,   1.17e+00,\n",
       "              nan,   1.96e-01,   6.31e-01,   3.37e-01,   7.29e-01,\n",
       "              nan,   5.90e-01,   1.62e+00,   2.28e+01,   6.11e+00,\n",
       "         5.64e+00,   9.55e-01,   1.19e+00,   7.98e-01,   2.12e+00,\n",
       "         1.31e+00,   2.12e-01,   2.58e+00,   1.32e+00,   1.55e+00,\n",
       "         2.04e+00,   5.03e-01,   6.25e-01,   8.21e-01,   2.19e-01,\n",
       "              nan,        nan,   3.62e-01,   1.20e+00,   5.66e-01,\n",
       "         5.09e-01,   5.38e-01,   3.21e-01,   4.26e-01,   3.04e-01,\n",
       "         2.13e+00,   1.04e+00,   9.99e-01,   9.17e-01,   1.78e-01,\n",
       "         2.45e+00,   3.26e-01,   4.31e-01,   8.46e-01,        nan,\n",
       "         6.31e-01,   3.39e-01,   1.39e+00,   1.70e+00,   2.49e+00,\n",
       "         5.50e-01,   3.55e-01,   1.62e+00,   7.74e-01,   1.16e+00,\n",
       "         6.14e-01,   4.04e-01,   1.06e+00,   1.56e+00,   2.89e-01,\n",
       "         2.21e+00,   6.94e-01,        nan,   9.06e-01,        nan])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=2.3877551020408161, penalty='l1')\n",
    "test.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_coef = []\n",
    "for i in range(len(test.coef_[0])):\n",
    "    if test.coef_[0][i] != 0:\n",
    "        index_coef.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1394"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.67e-91,   8.16e-01,   5.43e-08, ...,   6.86e-06,   8.80e-07,\n",
       "         4.23e-12])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval[index_coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for i in pval[index_coef]:\n",
    "    if i > 0.05:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-b90218f62d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpval_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_coef\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef'"
     ]
    }
   ],
   "source": [
    "index_coef = np.argpartition(test.coef_[4], -10)[-10:]\n",
    "total = 0\n",
    "for i in pval_[index_coef]:\n",
    "    if i > 0.05:\n",
    "        total += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceed\n",
      "superb\n",
      "sophia\n",
      "favorit\n",
      "masterpiec\n",
      "best\n",
      "hue\n",
      "amaz\n",
      "mmmmmmm\n",
      "banzo\n",
      "21888\n"
     ]
    }
   ],
   "source": [
    "for i in index_coef:\n",
    "    for k, v in tf.vocabulary_.items():\n",
    "        if i == v:\n",
    "            print(k)\n",
    "print(len(tf.vocabulary_.items())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 55778).\n"
     ]
    }
   ],
   "source": [
    "tf, all_mat_c, x_train_c = vectorize_text_count(TRAIN_TEXT, VALI_TEXT, TEST_TEXT, \n",
    "                                      vector='../../static/count_vector.pickle', \n",
    "                                      matrix='../../static/count_matrix.pickle', re_load=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi2_, pval_ = chi2(x_train_c, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 26088)\t1\n",
      "  (0, 46926)\t1\n",
      "  (0, 46062)\t1\n",
      "  (0, 43848)\t1\n",
      "  (0, 40223)\t1\n",
      "  (0, 10618)\t1\n",
      "  (0, 10839)\t1\n",
      "  (0, 40734)\t1\n",
      "  (0, 42553)\t1\n",
      "  (0, 41859)\t1\n",
      "  (0, 40894)\t1\n",
      "  (0, 47686)\t1\n",
      "  (0, 17034)\t1\n",
      "  (0, 23440)\t1\n",
      "  (0, 33276)\t1\n",
      "  (0, 31903)\t1\n",
      "  (0, 42271)\t1\n",
      "  (0, 39325)\t1\n",
      "  (0, 8295)\t1\n",
      "  (0, 42914)\t1\n",
      "  (0, 18244)\t1\n",
      "  (0, 37959)\t1\n",
      "  (0, 29715)\t1\n",
      "  (0, 42807)\t1\n",
      "  (0, 23933)\t1\n",
      "  :\t:\n",
      "  (0, 21205)\t1\n",
      "  (0, 36524)\t1\n",
      "  (0, 40442)\t1\n",
      "  (0, 47080)\t1\n",
      "  (0, 45157)\t1\n",
      "  (0, 1243)\t3\n",
      "  (0, 39672)\t1\n",
      "  (0, 41756)\t1\n",
      "  (0, 22001)\t1\n",
      "  (0, 26856)\t1\n",
      "  (0, 12619)\t1\n",
      "  (0, 15378)\t2\n",
      "  (0, 9418)\t1\n",
      "  (0, 19668)\t2\n",
      "  (0, 9670)\t1\n",
      "  (0, 16395)\t1\n",
      "  (0, 8084)\t1\n",
      "  (0, 623)\t8\n",
      "  (0, 17377)\t2\n",
      "  (0, 19664)\t1\n",
      "  (0, 24)\t2\n",
      "  (0, 55202)\t1\n",
      "  (0, 34128)\t1\n",
      "  (0, 0)\t4\n",
      "  (0, 46446)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_train_c[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_no_stop(text):\n",
    "    \"\"\" Helper function for TFIDF vector from sklearn. We use nltk's tokenize\n",
    "        function here. Also use snowball as stemmer (the middle agressive\n",
    "        one).\n",
    "    \"\"\"\n",
    "    # Filter out stop words, tokenize the text\n",
    "    useful_token = [w.lower() for w in word_tokenize(text)]\n",
    "\n",
    "    # Stemming the tokens\n",
    "    stemmed_token = [STEMMER.stem(t) for t in useful_token]\n",
    "\n",
    "    return stemmed_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text_no(train_txt, vali_txt, test_txt, vector, matrix, re_load,\n",
    "                   min_df=1, max_df=1.0, max_feature=None, min_n=1, max_n=1):\n",
    "    \"\"\" Feature engineering from the raw text input. \"\"\"\n",
    "    # If there is saved model, then just use it\n",
    "    if exists(vector) and exists(matrix) and not re_load:\n",
    "        # Get train length\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "\n",
    "        # Load stored data\n",
    "        all_mat = load(open(matrix, 'rb'))\n",
    "        x_train = all_mat[:table_train.shape[0]]\n",
    "        tf = load(open(vector, 'rb'))\n",
    "\n",
    "    else:\n",
    "        # Read all files\n",
    "        table_train = pd.read_csv(train_txt)\n",
    "        table_test = pd.read_csv(vali_txt)\n",
    "        table_vali = pd.read_csv(test_txt)\n",
    "\n",
    "        text_train = table_train['clean'].tolist()\n",
    "        text_test = table_test['clean'].tolist()\n",
    "        text_vali = table_vali['clean'].tolist()\n",
    "\n",
    "        # We want to have a overall vocabulary bank as `np.py`, so we combine\n",
    "        # all the text first\n",
    "        all_text = text_train + text_test + text_vali\n",
    "\n",
    "        # Record the length so we can recover the training set\n",
    "        train_length = len(text_train)\n",
    "\n",
    "        # Initialize TFID arguments\n",
    "        # Only work for English, discard all Chinese\n",
    "        tf = TfidfVectorizer(min_df=min_df, max_features=max_feature,\n",
    "                             strip_accents='ascii', analyzer='word',\n",
    "                             tokenizer=tokenize_no_stop, ngram_range=(min_n, max_n))\n",
    "\n",
    "        # Vectorize all, and transform (more efficient than fit + transform)\n",
    "        all_mat = tf.fit_transform(all_text)\n",
    "\n",
    "        # Recover the training data\n",
    "        x_train = all_mat[:train_length]\n",
    "\n",
    "        # Store the fitted matrix and tf_vectorizor\n",
    "        dump(all_mat, open(matrix, 'wb'))\n",
    "        dump(tf, open(vector, 'wb'))\n",
    "\n",
    "    print(\"Successfully load TF-IDF matrix, with shape {}.\".format(\n",
    "        x_train.shape))\n",
    "\n",
    "    return tf, all_mat, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 21974).\n"
     ]
    }
   ],
   "source": [
    "tf_no, all_mat_no, x_train_no = vectorize_text(TRAIN_TEXT, TEST_TEXT, VALI_TEXT,\n",
    "                                      \"./config/tf_nostop.pickle\", \n",
    "                                      \"./config/matrix_nostop.pickle\", False,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=MIN_N, max_n=MAX_N)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = LogisticRegression(C=2.3877551020408161, penalty='l1')\n",
    "test.fit(x_train_no, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.72518967618208174"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(test, x_train_no, y_train, cv=10,\n",
    "                                scoring=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21974).\n"
     ]
    }
   ],
   "source": [
    "predict(test, all_mat_no, x_train_no.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r = LogisticRegression(C=6, penalty='l2')\n",
    "test_r.fit(x_train_no, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21974).\n"
     ]
    }
   ],
   "source": [
    "predict(test_r, all_mat_no, x_train_no.shape[0], './config/prediction_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'has',\n",
       " 'hasn',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " 'she',\n",
       " 'should',\n",
       " 'shouldn',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'y',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36692, 4838)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no = SelectFromModel(test)\n",
    "model_no.fit(x_train_no, y_train)\n",
    "all_mat_no_s = model_no.transform(all_mat_no)\n",
    "x_train_no_s = model_no.transform(x_train_no)\n",
    "x_train_no_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test.coef_[0])):\n",
    "    if test.coef_[0][i] != 0 or test.coef_[1][i] != 0 or test.coef_[2][i] != 0 or \n",
    "        test.coef_[3][i] != 0 or test.coef_[4][i] != 0:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = LogisticRegression(C=2.3877551020408161, penalty='l1')\n",
    "tt.fit(x_train_no, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36692, 5288)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no = SelectFromModel(tt)\n",
    "model_no.fit(x_train, y_train)\n",
    "\n",
    "x_train_s = model_no.transform(x_train)\n",
    "x_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = LogisticRegression(C=2.3877551020408161, penalty='l1')\n",
    "final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21888).\n"
     ]
    }
   ],
   "source": [
    "predict(final, all_mat, x_train.shape[0], './config/prediction_final_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse Dictionary for no_stop\n",
    "tf_no_re = {}\n",
    "for k, v in tf_no.vocabulary_.items():\n",
    "    tf_no_re[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.387755102040816, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "about\n",
      "after\n",
      "again\n",
      "against\n",
      "ain\n",
      "all\n",
      "am\n",
      "an\n",
      "and\n",
      "are\n",
      "aren\n",
      "as\n",
      "at\n",
      "be\n",
      "been\n",
      "below\n",
      "between\n",
      "both\n",
      "but\n",
      "by\n",
      "can\n",
      "couldn\n",
      "did\n",
      "didn\n",
      "do\n",
      "doesn\n",
      "don\n",
      "down\n",
      "each\n",
      "few\n",
      "for\n",
      "from\n",
      "further\n",
      "had\n",
      "hadn\n",
      "has\n",
      "hasn\n",
      "have\n",
      "haven\n",
      "he\n",
      "her\n",
      "here\n",
      "herself\n",
      "him\n",
      "his\n",
      "how\n",
      "i\n",
      "if\n",
      "in\n",
      "into\n",
      "is\n",
      "isn\n",
      "it\n",
      "itself\n",
      "just\n",
      "ll\n",
      "m\n",
      "ma\n",
      "me\n",
      "more\n",
      "most\n",
      "my\n",
      "myself\n",
      "no\n",
      "nor\n",
      "not\n",
      "now\n",
      "o\n",
      "of\n",
      "off\n",
      "on\n",
      "or\n",
      "other\n",
      "our\n",
      "out\n",
      "over\n",
      "own\n",
      "re\n",
      "s\n",
      "same\n",
      "she\n",
      "should\n",
      "shouldn\n",
      "so\n",
      "some\n",
      "such\n",
      "t\n",
      "than\n",
      "that\n",
      "the\n",
      "their\n",
      "them\n",
      "then\n",
      "there\n",
      "these\n",
      "they\n",
      "this\n",
      "those\n",
      "through\n",
      "to\n",
      "too\n",
      "under\n",
      "until\n",
      "up\n",
      "ve\n",
      "was\n",
      "wasn\n",
      "we\n",
      "were\n",
      "weren\n",
      "what\n",
      "when\n",
      "where\n",
      "which\n",
      "while\n",
      "who\n",
      "whom\n",
      "will\n",
      "with\n",
      "won\n",
      "wouldn\n",
      "you\n",
      "your\n",
      "yourself\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test.coef_[0])):\n",
    "    if test.coef_[0][i] != 0 or test.coef_[1][i] != 0 or test.coef_[2][i] != 0 or \\\n",
    "        test.coef_[3][i] != 0 or test.coef_[4][i] != 0:\n",
    "            if tf_no_re[i] in STOP:\n",
    "                print(tf_no_re[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a less aggressive stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "STEMMER = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load TF-IDF matrix, with shape (36692, 21974).\n"
     ]
    }
   ],
   "source": [
    "tf_no_porter, all_mat_no_porter, x_train_no_porter = vectorize_text_no(TRAIN_TEXT, TEST_TEXT, VALI_TEXT,\n",
    "                                      \"./config/tf_nostop_p.pickle\", \n",
    "                                      \"./config/matrix_nostop_p.pickle\", True,\n",
    "                                      min_df=MIN_DF, max_df=MAX_DF,\n",
    "                                      max_feature=MAX_FEATURE,\n",
    "                                      min_n=MIN_N, max_n=MAX_N)\n",
    "\n",
    "# Make label for train_v\n",
    "table_train = pd.read_csv(TRAIN_TEXT)\n",
    "\n",
    "# Use string to represent the categories\n",
    "y_train = list(map(str, table_train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_r_p = LogisticRegression(C=6, penalty='l2')\n",
    "test_r_p.fit(x_train_no_porter, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   8.1s\n",
      "[CV] C=1.0 ...........................................................\n",
      "[CV] ............................................ C=1.0, total=   8.1s\n",
      "[CV] C=3.25 ..........................................................\n",
      "[CV] ............................................ C=1.0, total=   8.4s\n",
      "[CV] C=3.25 ..........................................................\n",
      "[CV] ............................................ C=1.0, total=   8.5s\n",
      "[CV] C=3.25 ..........................................................\n",
      "[CV] ............................................ C=1.0, total=   9.5s\n",
      "[CV] C=3.25 ..........................................................\n",
      "[CV] ........................................... C=3.25, total=  12.3s\n",
      "[CV] C=3.25 ..........................................................\n",
      "[CV] ........................................... C=3.25, total=  12.2s\n",
      "[CV] C=5.5 ...........................................................\n",
      "[CV] ........................................... C=3.25, total=  12.9s\n",
      "[CV] C=5.5 ...........................................................\n",
      "[CV] ........................................... C=3.25, total=  11.6s\n",
      "[CV] C=5.5 ...........................................................\n",
      "[CV] ........................................... C=3.25, total=  11.8s\n",
      "[CV] C=5.5 ...........................................................\n",
      "[CV] ............................................ C=5.5, total=  12.8s\n",
      "[CV] C=5.5 ...........................................................\n",
      "[CV] ............................................ C=5.5, total=  13.3s\n",
      "[CV] C=7.75 ..........................................................\n",
      "[CV] ............................................ C=5.5, total=  12.9s\n",
      "[CV] C=7.75 ..........................................................\n",
      "[CV] ............................................ C=5.5, total=  13.4s\n",
      "[CV] C=7.75 ..........................................................\n",
      "[CV] ............................................ C=5.5, total=  13.0s\n",
      "[CV] C=7.75 ..........................................................\n",
      "[CV] ........................................... C=7.75, total=  14.9s\n",
      "[CV] C=7.75 ..........................................................\n",
      "[CV] ........................................... C=7.75, total=  14.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=7.75, total=  14.3s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=7.75, total=  14.4s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=7.75, total=  13.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  15.4s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] ........................................... C=10.0, total=  16.0s\n",
      "[CV] ........................................... C=10.0, total=  16.0s\n",
      "[CV] ........................................... C=10.0, total=  15.5s\n",
      "[CV] ........................................... C=10.0, total=  10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.linspace(1,10,5)}\n",
    "better_model = GridSearchCV(LogisticRegression(penalty='l2', dual=False),\n",
    "                          param_grid, scoring=score, cv=5, n_jobs=4, verbose=2)\n",
    "\n",
    "better_model.fit(x_train_no_porter, y_train)\n",
    "dump(better_model, open('./config/model{}.pickle'.format('_ridge_nostop_p'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load predicting text, with shape (24461, 21974).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>-0.700748</td>\n",
       "      <td>-0.614704</td>\n",
       "      <td>-0.576698</td>\n",
       "      <td>-0.55137</td>\n",
       "      <td>-0.532244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>8.40018</td>\n",
       "      <td>12.0758</td>\n",
       "      <td>12.9925</td>\n",
       "      <td>14.0881</td>\n",
       "      <td>14.5749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.512284</td>\n",
       "      <td>0.473757</td>\n",
       "      <td>0.209709</td>\n",
       "      <td>0.599084</td>\n",
       "      <td>2.23651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.75</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>-0.700088</td>\n",
       "      <td>-0.614027</td>\n",
       "      <td>-0.576014</td>\n",
       "      <td>-0.550676</td>\n",
       "      <td>-0.531548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>-0.756408</td>\n",
       "      <td>-0.723055</td>\n",
       "      <td>-0.719313</td>\n",
       "      <td>-0.720335</td>\n",
       "      <td>-0.722827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00227796</td>\n",
       "      <td>0.00462168</td>\n",
       "      <td>0.00563095</td>\n",
       "      <td>0.00622247</td>\n",
       "      <td>0.00662464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>-0.698732</td>\n",
       "      <td>-0.612468</td>\n",
       "      <td>-0.574731</td>\n",
       "      <td>-0.54964</td>\n",
       "      <td>-0.53069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>-0.76154</td>\n",
       "      <td>-0.730361</td>\n",
       "      <td>-0.726943</td>\n",
       "      <td>-0.727804</td>\n",
       "      <td>-0.729941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>-0.700257</td>\n",
       "      <td>-0.614287</td>\n",
       "      <td>-0.576277</td>\n",
       "      <td>-0.550936</td>\n",
       "      <td>-0.531802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>-0.761895</td>\n",
       "      <td>-0.732829</td>\n",
       "      <td>-0.730682</td>\n",
       "      <td>-0.732444</td>\n",
       "      <td>-0.735268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000969649</td>\n",
       "      <td>0.00135506</td>\n",
       "      <td>0.00140846</td>\n",
       "      <td>0.00141722</td>\n",
       "      <td>0.00142556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>-0.759785</td>\n",
       "      <td>-0.727025</td>\n",
       "      <td>-0.722944</td>\n",
       "      <td>-0.723426</td>\n",
       "      <td>-0.725386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>{'C': 3.25}</td>\n",
       "      <td>{'C': 5.5}</td>\n",
       "      <td>{'C': 7.75}</td>\n",
       "      <td>{'C': 10.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.0186305</td>\n",
       "      <td>0.00470835</td>\n",
       "      <td>0.0055412</td>\n",
       "      <td>0.00203278</td>\n",
       "      <td>0.0225318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>-0.760501</td>\n",
       "      <td>-0.729943</td>\n",
       "      <td>-0.727042</td>\n",
       "      <td>-0.728347</td>\n",
       "      <td>-0.730901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.0897335</td>\n",
       "      <td>0.0873832</td>\n",
       "      <td>0.0885273</td>\n",
       "      <td>0.0879104</td>\n",
       "      <td>0.0671673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>-0.701414</td>\n",
       "      <td>-0.616074</td>\n",
       "      <td>-0.578141</td>\n",
       "      <td>-0.552768</td>\n",
       "      <td>-0.533608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>-0.762878</td>\n",
       "      <td>-0.736448</td>\n",
       "      <td>-0.735332</td>\n",
       "      <td>-0.737733</td>\n",
       "      <td>-0.74109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>-0.699289</td>\n",
       "      <td>-0.6126</td>\n",
       "      <td>-0.574222</td>\n",
       "      <td>-0.548665</td>\n",
       "      <td>-0.529395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0            1           2            3  \\\n",
       "split1_train_score    -0.700748    -0.614704   -0.576698     -0.55137   \n",
       "rank_test_score               5            3           1            2   \n",
       "mean_fit_time           8.40018      12.0758     12.9925      14.0881   \n",
       "std_fit_time           0.512284     0.473757    0.209709     0.599084   \n",
       "param_C                       1         3.25         5.5         7.75   \n",
       "mean_train_score      -0.700088    -0.614027   -0.576014    -0.550676   \n",
       "split0_test_score     -0.756408    -0.723055   -0.719313    -0.720335   \n",
       "std_test_score       0.00227796   0.00462168  0.00563095   0.00622247   \n",
       "split2_train_score    -0.698732    -0.612468   -0.574731     -0.54964   \n",
       "split4_test_score      -0.76154    -0.730361   -0.726943    -0.727804   \n",
       "split4_train_score    -0.700257    -0.614287   -0.576277    -0.550936   \n",
       "split3_test_score     -0.761895    -0.732829   -0.730682    -0.732444   \n",
       "std_train_score     0.000969649   0.00135506  0.00140846   0.00141722   \n",
       "split1_test_score     -0.759785    -0.727025   -0.722944    -0.723426   \n",
       "params               {'C': 1.0}  {'C': 3.25}  {'C': 5.5}  {'C': 7.75}   \n",
       "std_score_time        0.0186305   0.00470835   0.0055412   0.00203278   \n",
       "mean_test_score       -0.760501    -0.729943   -0.727042    -0.728347   \n",
       "mean_score_time       0.0897335    0.0873832   0.0885273    0.0879104   \n",
       "split0_train_score    -0.701414    -0.616074   -0.578141    -0.552768   \n",
       "split2_test_score     -0.762878    -0.736448   -0.735332    -0.737733   \n",
       "split3_train_score    -0.699289      -0.6126   -0.574222    -0.548665   \n",
       "\n",
       "                              4  \n",
       "split1_train_score    -0.532244  \n",
       "rank_test_score               4  \n",
       "mean_fit_time           14.5749  \n",
       "std_fit_time            2.23651  \n",
       "param_C                      10  \n",
       "mean_train_score      -0.531548  \n",
       "split0_test_score     -0.722827  \n",
       "std_test_score       0.00662464  \n",
       "split2_train_score     -0.53069  \n",
       "split4_test_score     -0.729941  \n",
       "split4_train_score    -0.531802  \n",
       "split3_test_score     -0.735268  \n",
       "std_train_score      0.00142556  \n",
       "split1_test_score     -0.725386  \n",
       "params              {'C': 10.0}  \n",
       "std_score_time        0.0225318  \n",
       "mean_test_score       -0.730901  \n",
       "mean_score_time       0.0671673  \n",
       "split0_train_score    -0.533608  \n",
       "split2_test_score      -0.74109  \n",
       "split3_train_score    -0.529395  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_better = pd.DataFrame.from_dict(better_model.cv_results_, orient='index')\n",
    "predict_mlr(better_model, all_mat_no_porter, x_train_no_porter.shape[0], './config/prediction_test.csv')\n",
    "cv_result_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat333_project2",
   "language": "python",
   "name": "stat333_project2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
